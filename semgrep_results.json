{"version":"1.134.0","results":[{"check_id":"yaml.github-actions.security.run-shell-injection.run-shell-injection","path":".github\\workflows\\setup-branch-protection.yml","start":{"line":206,"col":7,"offset":7160},"end":{"line":219,"col":57,"offset":7777},"extra":{"message":"Using variable interpolation `${{...}}` with `github` context data in a `run:` step could allow an attacker to inject their own code into the runner. This would allow them to steal secrets and code. `github` context data can have arbitrary user input and should be treated as untrusted. Instead, use an intermediate environment variable with `env:` to store the data and use the environment variable in the `run:` script. Be sure to use double-quotes the environment variable, like this: \"$ENVVAR\".","metadata":{"category":"security","cwe":["CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')"],"owasp":["A01:2017 - Injection","A03:2021 - Injection"],"references":["https://docs.github.com/en/actions/learn-github-actions/security-hardening-for-github-actions#understanding-the-risk-of-script-injections","https://securitylab.github.com/research/github-actions-untrusted-input/"],"technology":["github-actions"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["vuln"],"likelihood":"HIGH","impact":"HIGH","confidence":"HIGH","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Command Injection"],"source":"https://semgrep.dev/r/yaml.github-actions.security.run-shell-injection.run-shell-injection","shortlink":"https://sg.run/pkzk"},"severity":"ERROR","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"yaml.github-actions.security.run-shell-injection.run-shell-injection","path":".github\\workflows\\validate-artifacts.yml","start":{"line":93,"col":9,"offset":2626},"end":{"line":105,"col":2,"offset":3440},"extra":{"message":"Using variable interpolation `${{...}}` with `github` context data in a `run:` step could allow an attacker to inject their own code into the runner. This would allow them to steal secrets and code. `github` context data can have arbitrary user input and should be treated as untrusted. Instead, use an intermediate environment variable with `env:` to store the data and use the environment variable in the `run:` script. Be sure to use double-quotes the environment variable, like this: \"$ENVVAR\".","metadata":{"category":"security","cwe":["CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')"],"owasp":["A01:2017 - Injection","A03:2021 - Injection"],"references":["https://docs.github.com/en/actions/learn-github-actions/security-hardening-for-github-actions#understanding-the-risk-of-script-injections","https://securitylab.github.com/research/github-actions-untrusted-input/"],"technology":["github-actions"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["vuln"],"likelihood":"HIGH","impact":"HIGH","confidence":"HIGH","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Command Injection"],"source":"https://semgrep.dev/r/yaml.github-actions.security.run-shell-injection.run-shell-injection","shortlink":"https://sg.run/pkzk"},"severity":"ERROR","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"yaml.github-actions.security.run-shell-injection.run-shell-injection","path":".github\\workflows\\validate-artifacts.yml","start":{"line":108,"col":9,"offset":3507},"end":{"line":114,"col":2,"offset":3796},"extra":{"message":"Using variable interpolation `${{...}}` with `github` context data in a `run:` step could allow an attacker to inject their own code into the runner. This would allow them to steal secrets and code. `github` context data can have arbitrary user input and should be treated as untrusted. Instead, use an intermediate environment variable with `env:` to store the data and use the environment variable in the `run:` script. Be sure to use double-quotes the environment variable, like this: \"$ENVVAR\".","metadata":{"category":"security","cwe":["CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')"],"owasp":["A01:2017 - Injection","A03:2021 - Injection"],"references":["https://docs.github.com/en/actions/learn-github-actions/security-hardening-for-github-actions#understanding-the-risk-of-script-injections","https://securitylab.github.com/research/github-actions-untrusted-input/"],"technology":["github-actions"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["vuln"],"likelihood":"HIGH","impact":"HIGH","confidence":"HIGH","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Command Injection"],"source":"https://semgrep.dev/r/yaml.github-actions.security.run-shell-injection.run-shell-injection","shortlink":"https://sg.run/pkzk"},"severity":"ERROR","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"yaml.github-actions.security.run-shell-injection.run-shell-injection","path":".github\\workflows\\validate-artifacts.yml","start":{"line":172,"col":9,"offset":5946},"end":{"line":200,"col":2,"offset":7197},"extra":{"message":"Using variable interpolation `${{...}}` with `github` context data in a `run:` step could allow an attacker to inject their own code into the runner. This would allow them to steal secrets and code. `github` context data can have arbitrary user input and should be treated as untrusted. Instead, use an intermediate environment variable with `env:` to store the data and use the environment variable in the `run:` script. Be sure to use double-quotes the environment variable, like this: \"$ENVVAR\".","metadata":{"category":"security","cwe":["CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')"],"owasp":["A01:2017 - Injection","A03:2021 - Injection"],"references":["https://docs.github.com/en/actions/learn-github-actions/security-hardening-for-github-actions#understanding-the-risk-of-script-injections","https://securitylab.github.com/research/github-actions-untrusted-input/"],"technology":["github-actions"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["vuln"],"likelihood":"HIGH","impact":"HIGH","confidence":"HIGH","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Command Injection"],"source":"https://semgrep.dev/r/yaml.github-actions.security.run-shell-injection.run-shell-injection","shortlink":"https://sg.run/pkzk"},"severity":"ERROR","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"python.lang.security.deserialization.pickle.avoid-pickle","path":"analyzer\\caching\\ast_cache.py","start":{"line":376,"col":30,"offset":13268},"end":{"line":376,"col":54,"offset":13292},"extra":{"message":"Avoid using `pickle`, which is known to lead to code execution vulnerabilities. When unpickling, the serialized data could be manipulated to run arbitrary code. Instead, consider serializing the relevant data as JSON or a similar text-based serialization format.","metadata":{"owasp":["A08:2017 - Insecure Deserialization","A08:2021 - Software and Data Integrity Failures"],"cwe":["CWE-502: Deserialization of Untrusted Data"],"references":["https://docs.python.org/3/library/pickle.html"],"category":"security","technology":["python"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"MEDIUM","confidence":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Insecure Deserialization "],"source":"https://semgrep.dev/r/python.lang.security.deserialization.pickle.avoid-pickle","shortlink":"https://sg.run/OPwB"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"python.lang.security.deserialization.pickle.avoid-pickle","path":"analyzer\\caching\\ast_cache.py","start":{"line":395,"col":34,"offset":13849},"end":{"line":395,"col":58,"offset":13873},"extra":{"message":"Avoid using `pickle`, which is known to lead to code execution vulnerabilities. When unpickling, the serialized data could be manipulated to run arbitrary code. Instead, consider serializing the relevant data as JSON or a similar text-based serialization format.","metadata":{"owasp":["A08:2017 - Insecure Deserialization","A08:2021 - Software and Data Integrity Failures"],"cwe":["CWE-502: Deserialization of Untrusted Data"],"references":["https://docs.python.org/3/library/pickle.html"],"category":"security","technology":["python"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"MEDIUM","confidence":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Insecure Deserialization "],"source":"https://semgrep.dev/r/python.lang.security.deserialization.pickle.avoid-pickle","shortlink":"https://sg.run/OPwB"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"python.lang.security.deserialization.pickle.avoid-pickle","path":"analyzer\\caching\\ast_cache.py","start":{"line":446,"col":25,"offset":15905},"end":{"line":446,"col":47,"offset":15927},"extra":{"message":"Avoid using `pickle`, which is known to lead to code execution vulnerabilities. When unpickling, the serialized data could be manipulated to run arbitrary code. Instead, consider serializing the relevant data as JSON or a similar text-based serialization format.","metadata":{"owasp":["A08:2017 - Insecure Deserialization","A08:2021 - Software and Data Integrity Failures"],"cwe":["CWE-502: Deserialization of Untrusted Data"],"references":["https://docs.python.org/3/library/pickle.html"],"category":"security","technology":["python"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"MEDIUM","confidence":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Insecure Deserialization "],"source":"https://semgrep.dev/r/python.lang.security.deserialization.pickle.avoid-pickle","shortlink":"https://sg.run/OPwB"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"python.lang.security.deserialization.pickle.avoid-pickle","path":"analyzer\\caching\\ast_cache.py","start":{"line":448,"col":21,"offset":15972},"end":{"line":448,"col":42,"offset":15993},"extra":{"message":"Avoid using `pickle`, which is known to lead to code execution vulnerabilities. When unpickling, the serialized data could be manipulated to run arbitrary code. Instead, consider serializing the relevant data as JSON or a similar text-based serialization format.","metadata":{"owasp":["A08:2017 - Insecure Deserialization","A08:2021 - Software and Data Integrity Failures"],"cwe":["CWE-502: Deserialization of Untrusted Data"],"references":["https://docs.python.org/3/library/pickle.html"],"category":"security","technology":["python"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"MEDIUM","confidence":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Insecure Deserialization "],"source":"https://semgrep.dev/r/python.lang.security.deserialization.pickle.avoid-pickle","shortlink":"https://sg.run/OPwB"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"python.lang.security.deserialization.pickle.avoid-pickle","path":"analyzer\\caching\\ast_cache.py","start":{"line":471,"col":37,"offset":16651},"end":{"line":471,"col":52,"offset":16666},"extra":{"message":"Avoid using `pickle`, which is known to lead to code execution vulnerabilities. When unpickling, the serialized data could be manipulated to run arbitrary code. Instead, consider serializing the relevant data as JSON or a similar text-based serialization format.","metadata":{"owasp":["A08:2017 - Insecure Deserialization","A08:2021 - Software and Data Integrity Failures"],"cwe":["CWE-502: Deserialization of Untrusted Data"],"references":["https://docs.python.org/3/library/pickle.html"],"category":"security","technology":["python"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"MEDIUM","confidence":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Insecure Deserialization "],"source":"https://semgrep.dev/r/python.lang.security.deserialization.pickle.avoid-pickle","shortlink":"https://sg.run/OPwB"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"python.lang.security.deserialization.pickle.avoid-pickle","path":"analyzer\\caching\\ast_cache.py","start":{"line":473,"col":33,"offset":16727},"end":{"line":473,"col":47,"offset":16741},"extra":{"message":"Avoid using `pickle`, which is known to lead to code execution vulnerabilities. When unpickling, the serialized data could be manipulated to run arbitrary code. Instead, consider serializing the relevant data as JSON or a similar text-based serialization format.","metadata":{"owasp":["A08:2017 - Insecure Deserialization","A08:2021 - Software and Data Integrity Failures"],"cwe":["CWE-502: Deserialization of Untrusted Data"],"references":["https://docs.python.org/3/library/pickle.html"],"category":"security","technology":["python"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"MEDIUM","confidence":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Insecure Deserialization "],"source":"https://semgrep.dev/r/python.lang.security.deserialization.pickle.avoid-pickle","shortlink":"https://sg.run/OPwB"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"bash.lang.security.ifs-tampering.ifs-tampering","path":"scripts\\lib\\cleanup-commons.sh","start":{"line":3,"col":21,"offset":131},"end":{"line":3,"col":32,"offset":142},"extra":{"message":"The special variable IFS affects how splitting takes place when expanding unquoted variables. Don't set it globally. Prefer a dedicated utility such as 'cut' or 'awk' if you need to split input data. If you must use 'read', set IFS locally using e.g. 'IFS=\",\" read -a my_array'.","metadata":{"cwe":["CWE-20: Improper Input Validation"],"category":"security","technology":["bash"],"confidence":"LOW","owasp":["A03:2021 - Injection"],"references":["https://owasp.org/Top10/A03_2021-Injection"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Improper Validation"],"source":"https://semgrep.dev/r/bash.lang.security.ifs-tampering.ifs-tampering","shortlink":"https://sg.run/Q9pq"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}},{"check_id":"bash.lang.security.ifs-tampering.ifs-tampering","path":"scripts\\mcp-auto-init-enhanced.sh","start":{"line":678,"col":25,"offset":23102},"end":{"line":678,"col":32,"offset":23109},"extra":{"message":"The special variable IFS affects how splitting takes place when expanding unquoted variables. Don't set it globally. Prefer a dedicated utility such as 'cut' or 'awk' if you need to split input data. If you must use 'read', set IFS locally using e.g. 'IFS=\",\" read -a my_array'.","metadata":{"cwe":["CWE-20: Improper Input Validation"],"category":"security","technology":["bash"],"confidence":"LOW","owasp":["A03:2021 - Injection"],"references":["https://owasp.org/Top10/A03_2021-Injection"],"cwe2022-top25":true,"cwe2021-top25":true,"subcategory":["audit"],"likelihood":"LOW","impact":"LOW","license":"Semgrep Rules License v1.0. For more details, visit semgrep.dev/legal/rules-license","vulnerability_class":["Improper Validation"],"source":"https://semgrep.dev/r/bash.lang.security.ifs-tampering.ifs-tampering","shortlink":"https://sg.run/Q9pq"},"severity":"WARNING","fingerprint":"requires login","lines":"requires login","validation_state":"NO_VALIDATOR","engine_kind":"OSS"}}],"errors":[{"code":3,"level":"warn","type":"Syntax error","message":"Syntax error at line scripts\\create-new-feature.sh:1:\n `#!/usr/bin/env bash\n# Create a new feature with branch, directory structure, and template\n# Usage: ./create-new-feature.sh \"feature description\"\n#        ./create-new-feature.sh --json \"feature description\"\n\nset -e\n\nJSON_MODE=false\n\n# Collect non-flag args\nARGS=()\nfor arg in \"$@\"; do\n    case \"$arg\" in\n        --json)\n            JSON_MODE=true\n            ;;\n        --help|-h)\n            echo \"Usage: $0 [--json] <feature_description>\"; exit 0 ;;\n        *)\n            ARGS+=(\"$arg\") ;;\n    esac\ndone\n\nFEATURE_DESCRIPTION=\"${ARGS[*]}\"\nif [ -z \"$FEATURE_DESCRIPTION\" ]; then\n        echo \"Usage: $0 [--json] <feature_description>\" >&2\n        exit 1\nfi\n\n# Get repository root\nREPO_ROOT=$(git rev-parse --show-toplevel)\nSPECS_DIR=\"$REPO_ROOT/specs\"\n\n# Create specs directory if it doesn't exist\nmkdir -p \"$SPECS_DIR\"\n\n# Find the highest numbered feature directory\nHIGHEST=0\nif [ -d \"$SPECS_DIR\" ]; then\n    for dir in \"$SPECS_DIR\"/*; do\n        if [ -d \"$dir\" ]; then\n            dirname=$(basename \"$dir\")\n            number=$(echo \"$dirname\" | grep -o '^[0-9]\\+' || echo \"0\")\n            number=$((10#$number))\n            if [ \"$number\" -gt \"$HIGHEST\" ]; then\n                HIGHEST=$number\n            fi\n        fi\n    done\nfi\n\n# Generate next feature number with zero padding\nNEXT=$((HIGHEST + 1))\nFEATURE_NUM=$(printf \"%03d\" \"$NEXT\")\n\n# Create branch name from description\nBRANCH_NAME=$(echo \"$FEATURE_DESCRIPTION\" | \\\n    tr '[:upper:]' '[:lower:]' | \\\n    sed 's/[^a-z0-9]/-/g' | \\\n    sed 's/-\\+/-/g' | \\\n    sed 's/^-//' | \\\n    sed 's/-$//')\n\n# Extract 2-3 meaningful words\nWORDS=$(echo \"$BRANCH_NAME\" | tr '-' '\\n' | grep -v '^$' | head -3 | tr '\\n' '-' | sed 's/-$//')\n\n# Final branch name\nBRANCH_NAME=\"${FEATURE_NUM}-${WORDS}\"\n\n# Create and switch to new branch\ngit checkout -b \"$BRANCH_NAME\"\n\n# Create feature directory\nFEATURE_DIR=\"$SPECS_DIR/$BRANCH_NAME\"\nmkdir -p \"$FEATURE_DIR\"\n\n# Copy template if it exists\nTEMPLATE=\"$REPO_ROOT/templates/spec-template.md\"\nSPEC_FILE=\"$FEATURE_DIR/spec.md\"\n\nif [ -f \"$TEMPLATE\" ]; then\n   ... (truncated 459 more characters)","path":"scripts\\create-new-feature.sh"},{"code":2,"level":"warn","type":"Other syntax error","message":"Other syntax error at line .github\\workflows\\connascence-analysis.yml:134:\n (approximate error location; error nearby after) error calling parser: could not find expected ':' character 0 position 0 returned: 0","path":".github\\workflows\\connascence-analysis.yml"},{"code":2,"level":"warn","type":"Other syntax error","message":"Other syntax error at line .github\\workflows\\enhanced-quality-gates.yml:1507:\n (approximate error location; error nearby after) error calling parser: could not find expected ':' character 0 position 0 returned: 0","path":".github\\workflows\\enhanced-quality-gates.yml"},{"code":2,"level":"warn","type":"Other syntax error","message":"Other syntax error at line flow\\workflows\\spec-to-pr.yaml:50:\n (approximate error location; error nearby after) error calling parser: could not find expected ':' character 0 position 0 returned: 0","path":"flow\\workflows\\spec-to-pr.yaml"},{"code":2,"level":"warn","type":"Other syntax error","message":"Other syntax error at line flow\\workflows\\swarm-audit-cycle.yaml:345:\n (approximate error location; error nearby after) error calling parser: could not find expected ':' character 0 position 0 returned: 0","path":"flow\\workflows\\swarm-audit-cycle.yaml"},{"code":2,"level":"warn","type":"Other syntax error","message":"Other syntax error at line .github\\workflows\\nasa-compliance-check.yml:218:\n (approximate error location; error nearby after) error calling parser: did not find expected key character 0 position 0 returned: 0","path":".github\\workflows\\nasa-compliance-check.yml"},{"code":2,"level":"warn","type":"Internal matching error","rule_id":"yaml.github-actions.security.curl-eval.curl-eval","message":"Internal matching error when running yaml.github-actions.security.curl-eval.curl-eval on .github\\workflows\\validate-artifacts.yml:\n An error occurred while invoking the Semgrep engine. Please help us fix this by creating an issue at https://github.com/semgrep/semgrep\n\nrule yaml.github-actions.security.curl-eval.curl-eval: metavariable-pattern failed when parsing $SHELL's content as Bash: echo \"R`S  Generating comprehensive memory coordination report...\"\n\n# Create comprehensive memory report\npython -c \"\nimport json\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\n\n# Collect all memory coordination data with MCP Flow-Nexus integration\nmemory_data = {\n    'coordination_system': 'github-actions-comprehensive-memory',\n    'version': '1.0.0', \n    'session_id': '${{ needs.setup-validation.outputs.validation-session-id }}',\n    'mcp_integration': {\n        'flow_nexus_compatible': True,\n        'swarm_coordination': 'enabled',\n        'memory_persistence': 'cross-session'\n    },\n    'workflow_info': {\n        'workflow': '${{ github.workflow }}',\n        'run_id': '${{ github.run_id }}',\n        'run_number': '${{ github.run_number }}',\n        'sha': '${{ github.sha }}',\n        'ref': '${{ github.ref }}',\n        'timestamp': datetime.now().isoformat()\n    },\n    'analyzer_integration': {\n        'consolidated_structure': True,\n        'commands_validated': ['core.py', 'mece_analyzer', 'nasa_policy'],\n        'unicode_safety': 'enabled'\n    },\n    'validation_results': {},\n    'performance_data': {},\n    'badge_data': {},\n    'coordination_summary': {}\n}\n\n# Collect validation results\nfor root, dirs, files in os.walk('all-artifacts'):\n    for file in files:\n        file_path = os.path.join(root, file)\n        try:\n            if file.endswith('validation-results.json'):\n                with open(file_path, 'r') as f:\n                    data = json.load(f)\n                matrix_name = data.get('matrix_name', 'unknown')\n                memory_data['validation_results'][matrix_name] = data\n            elif file.endswith('performance-benchmark.json'):\n                with open(file_path, 'r') as f:\n                    memory_data['per... (truncated 1556 more characters)","path":".github\\workflows\\validate-artifacts.yml"},{"code":2,"level":"warn","type":"Internal matching error","rule_id":"yaml.github-actions.security.curl-eval.curl-eval","message":"Internal matching error when running yaml.github-actions.security.curl-eval.curl-eval on .github\\workflows\\cache-optimization.yml:\n An error occurred while invoking the Semgrep engine. Please help us fix this by creating an issue at https://github.com/semgrep/semgrep\n\nrule yaml.github-actions.security.curl-eval.curl-eval: metavariable-pattern failed when parsing $SHELL's content as Bash: echo \"R`UE Running cache optimization analysis...\"\ncd analyzer\npython -c \"import sys; sys.path.insert(0, '.'); exec(\\\"\\\"\\\"try:\\n    from analyzer.optimization.file_cache import FileContentCache as IncrementalCache\\n    import json\\n    from datetime import datetime\\n    cache = IncrementalCache()\\n    cache_result = cache.get_cache_health()\\n    cache_optimization_result = {'cache_health': {'health_score': 0.85, 'hit_rate': 0.78, 'optimization_potential': 0.22}, 'performance_metrics': {'cache_efficiency': 0.82, 'memory_utilization': 0.68}, 'recommendations': ['Increase cache size for better hit rates', 'Implement cache warming strategies'], 'timestamp': datetime.now().isoformat()}\\n    with open('../.claude/.artifacts/cache_optimization.json', 'w') as f:\\n        json.dump(cache_optimization_result, f, indent=2)\\n    print('SUCCESS: Cache optimization analysis completed')\\n    print(f'Cache Health Score: {cache_optimization_result[\\\\\\\"cache_health\\\\\\\"][\\\\\\\"health_score\\\\\\\"]:.2%}')\\n    print(f'Hit Rate: {cache_optimization_result[\\\\\\\"cache_health\\\\\\\"][\\\\\\\"hit_rate\\\\\\\"]:.2%}')\\n    print(f'Cache Efficiency: {cache_optimization_result[\\\\\\\"performance_metrics\\\\\\\"][\\\\\\\"cache_efficiency\\\\\\\"]:.2%}')\\nexcept Exception as e:\\n    print(f'WARNING: Cache optimization analysis failed: {e}')\\n    from datetime import datetime\\n    import json\\n    cache_fallback = {'cache_health': {'health_score': 0.80, 'hit_rate': 0.70, 'optimization_potential': 0.30}, 'performance_metrics': {'cache_efficiency': 0.75, 'memory_utilization': 0.60}, 'recommendations': ['Cache optimization analysis unavailable'], 'timestamp': datetime.now().isoformat(), 'fallback': True, 'error': str(e)}\\n    with open('../.claude/.artifacts/cache_optimization.json', 'w') as f:\\n        json.dump(cache_fall... (truncated 27 more characters)","path":".github\\workflows\\cache-optimization.yml"},{"code":2,"level":"warn","type":"Internal matching error","rule_id":"yaml.github-actions.security.curl-eval.curl-eval","message":"Internal matching error when running yaml.github-actions.security.curl-eval.curl-eval on .github\\workflows\\vscode-extension-ci.yml:\n An error occurred while invoking the Semgrep engine. Please help us fix this by creating an issue at https://github.com/semgrep/semgrep\n\nrule yaml.github-actions.security.curl-eval.curl-eval: metavariable-pattern failed when parsing $SHELL's content as Bash: if [ -d \"out\" ] && [ \"$(ls -A out 2>/dev/null || echo)\" != \"\" ]; then\n  echo \"D]F Extension already compiled (out/ directory exists with files)\"\n  echo \"File count: $(find out -type f 2>/dev/null | wc -l || echo \"0\")\"\n  echo \"Total size: $(du -sh out 2>/dev/null | cut -f1 || echo \"unknown\")\"\nelse\n  echo \"D[aQyP No pre-compiled files found, attempting compilation...\"\n  if npm run --silent 2>/dev/null | grep -E '^\\s*compile\\s' >/dev/null 2>&1; then\n    echo \"R`T^ Found compile script, running compilation...\"\n    if npm run compile; then\n      echo \"D]F Compilation successful\"\n    else\n      echo \"D[aQyP Compilation failed - this may be acceptable for pre-packaged extensions\"\n    fi\n  else\n    echo \"DEzQyP No compile script configured - using existing files\"\n    echo \"This is normal for pre-compiled extensions\"\n  fi\nfi\n","path":".github\\workflows\\vscode-extension-ci.yml"},{"code":2,"level":"warn","type":"Internal matching error","rule_id":"yaml.github-actions.security.curl-eval.curl-eval","message":"Internal matching error when running yaml.github-actions.security.curl-eval.curl-eval on flow\\workflows\\after-edit.yaml:\n An error occurred while invoking the Semgrep engine. Please help us fix this by creating an issue at https://github.com/semgrep/semgrep\n\nrule yaml.github-actions.security.curl-eval.curl-eval: metavariable-pattern failed when parsing $SHELL's content as Bash: npx claude-flow@alpha swarm init --topology hierarchical --burst-control --max-attempts \"$MAX_ATTEMPTS\"\nnpx claude-flow@alpha swarm status --session \"$SESSION_ID\" > swarm_status.json || echo '{\"attempts\": 0}' > swarm_status.json\nCURRENT_ATTEMPTS=\"$(jq -r '.attempts // 0' swarm_status.json)\"\nif [[ $CURRENT_ATTEMPTS -ge $MAX_ATTEMPTS ]]; then\n  echo \"R`[i Max attempts ($MAX_ATTEMPTS) exceeded - escalating to planner\"\n  npx claude-flow@alpha task orchestrate --escalate planner --reason \"auto-repair-limit\"\n  exit 1\nfi\n","path":"flow\\workflows\\after-edit.yaml"},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\auto-repair.yml","start":{"line":54,"col":26,"offset":1426},"end":{"line":54,"col":64,"offset":1464}}]],"message":"Syntax error at line .github\\workflows\\auto-repair.yml:54:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.event.workflow_run.conclusion` was unexpected","path":".github\\workflows\\auto-repair.yml","spans":[{"file":".github\\workflows\\auto-repair.yml","start":{"line":54,"col":26,"offset":1426},"end":{"line":54,"col":64,"offset":1464}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\codeql-analysis.yml","start":{"line":54,"col":29,"offset":1230},"end":{"line":54,"col":32,"offset":1233}}]],"message":"Syntax error at line .github\\workflows\\codeql-analysis.yml:54:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `${{` was unexpected","path":".github\\workflows\\codeql-analysis.yml","spans":[{"file":".github\\workflows\\codeql-analysis.yml","start":{"line":54,"col":29,"offset":1230},"end":{"line":54,"col":32,"offset":1233}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\connascence-core-analysis.yml","start":{"line":55,"col":18,"offset":1220},"end":{"line":57,"col":1249,"offset":2550}}]],"message":"Syntax error at line .github\\workflows\\connascence-core-analysis.yml:55:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`UN Running core connascence analysis with all 8 detector types...\"\ncd analyzer\npython -c \"import sys; sys.path.insert(0, '.'); exec(\\\"\\\"\\\"try:\\n    from analyzer.connascence_analyzer import ConnascenceAnalyzer\\n    import json\\n    from datetime import datetime\\n    analyzer = ConnascenceAnalyzer()\\n    core_result = analyzer.analyze_path('..', policy='nasa_jpl_pot10')\\n    with open('../.claude/.artifacts/connascence_full.json', 'w') as f:\\n        json.dump(core_result, f, indent=2, default=str)\\n    print('SUCCESS: Core connascence analysis completed')\\n    print(f'Found {len(core_result.get(\\\\\\\"violations\\\\\\\", []))} violations')\\n    print(f'NASA compliance: {core_result.get(\\\\\\\"nasa_compliance\\\\\\\", {}).get(\\\\\\\"score\\\\\\\", 0):.2%}')\\nexcept Exception as e:\\n    print(f'WARNING: Core analysis failed: {e}')\\n    from datetime import datetime\\n    import json\\n    fallback_result = {'success': False, 'error': str(e), 'violations': [], 'summary': {'total_violations': 0, 'critical_violations': 0, 'overall_quality_score': 0.75}, 'nasa_compliance': {'score': 0.92, 'violations': [], 'reason': 'typescript_project_baseline'}, 'god_objects': [], 'timestamp': datetime.now().isoformat()}\\n    with open('../.claude/.artifacts/connascence_full.json', 'w') as f:\\n        json.dump(fallback_result, f, indent=2)\\\"\\\"\\\")\"\n` was unexpected","path":".github\\workflows\\connascence-core-analysis.yml","spans":[{"file":".github\\workflows\\connascence-core-analysis.yml","start":{"line":55,"col":18,"offset":1220},"end":{"line":57,"col":1249,"offset":2550}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\connascence-core-analysis.yml","start":{"line":91,"col":11,"offset":3862},"end":{"line":140,"col":2,"offset":5369}}]],"message":"Syntax error at line .github\\workflows\\connascence-core-analysis.yml:91:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"\nimport json\nimport sys\n\nwith open('.claude/.artifacts/connascence_full.json', 'r') as f:\n    data = json.load(f)\n\n# Quality thresholds\nmax_critical = 5\nmin_nasa_compliance = 0.85\nmin_quality_score = 0.70\nmax_god_objects = 3\n\ncritical_violations = data.get('summary', {}).get('critical_violations', 0)\nnasa_score = data.get('nasa_compliance', {}).get('score', 0)\nquality_score = data.get('summary', {}).get('overall_quality_score', 0)\ngod_objects = len(data.get('god_objects', []))\n\nfailed = False\n\nif critical_violations > max_critical:\n    print(f'D^M Critical violations: {critical_violations} > {max_critical}')\n    failed = True\nelse:\n    print(f'D]F Critical violations: {critical_violations} <= {max_critical}')\n    \nif nasa_score < min_nasa_compliance:\n    print(f'D^M NASA compliance: {nasa_score:.2%} < {min_nasa_compliance:.2%}')\n    failed = True\nelse:\n    print(f'D]F NASA compliance: {nasa_score:.2%} >= {min_nasa_compliance:.2%}')\n    \nif quality_score < min_quality_score:\n    print(f'D^M Quality score: {quality_score:.2%} < {min_quality_score:.2%}')\n    failed = True\nelse:\n    print(f'D]F Quality score: {quality_score:.2%} >= {min_quality_score:.2%}')\n    \nif god_objects > max_god_objects:\n    print(f'D^M God objects: {god_objects} > {max_god_objects}')\n    failed = True\nelse:\n    print(f'D]F God objects: {god_objects} <= {max_god_objects}')\n\nif failed:\n    print('\\\\nR`[i Connascence quality gate FAILED')\n    sys.exit(1)\nelse:\n    print('\\\\nD]F Connascence quality gate PASSED')\n\"` was unexpected","path":".github\\workflows\\connascence-core-analysis.yml","spans":[{"file":".github\\workflows\\connascence-core-analysis.yml","start":{"line":91,"col":11,"offset":3862},"end":{"line":140,"col":2,"offset":5369}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":118,"col":21,"offset":6265},"end":{"line":118,"col":40,"offset":6284}},{"path":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":119,"col":17,"offset":6265},"end":{"line":119,"col":34,"offset":6282}},{"path":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":120,"col":17,"offset":6265},"end":{"line":120,"col":29,"offset":6277}},{"path":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":121,"col":16,"offset":6265},"end":{"line":121,"col":35,"offset":6284}}]],"message":"Syntax error at line .github\\workflows\\quality-gate-enforcer.yml:118:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.repository` was unexpected","path":".github\\workflows\\quality-gate-enforcer.yml","spans":[{"file":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":118,"col":21,"offset":6265},"end":{"line":118,"col":40,"offset":6284}},{"file":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":119,"col":17,"offset":6265},"end":{"line":119,"col":34,"offset":6282}},{"file":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":120,"col":17,"offset":6265},"end":{"line":120,"col":29,"offset":6277}},{"file":".github\\workflows\\quality-gate-enforcer.yml","start":{"line":121,"col":16,"offset":6265},"end":{"line":121,"col":35,"offset":6284}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":80,"col":18,"offset":2013},"end":{"line":86,"col":44,"offset":2316}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:80:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`Tg Installing analysis dependencies for ${{ matrix.analysis.name }}...\"\npip install --upgrade pip\nif [ -f requirements.txt ]; then\n  pip install -r requirements.txt\nfi\npip install -e ./analyzer || echo \"D[aQyP Analyzer installation failed, using fallbacks\"\necho \"D]F Analysis dependencies installed\"\n` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":80,"col":18,"offset":2013},"end":{"line":86,"col":44,"offset":2316}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":109,"col":27,"offset":2487},"end":{"line":109,"col":51,"offset":2511}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":128,"col":27,"offset":2487},"end":{"line":128,"col":51,"offset":2511}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":142,"col":33,"offset":2487},"end":{"line":142,"col":55,"offset":2509}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:109:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.runner` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":109,"col":27,"offset":2487},"end":{"line":109,"col":51,"offset":2511}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":128,"col":27,"offset":2487},"end":{"line":128,"col":51,"offset":2511}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":142,"col":33,"offset":2487},"end":{"line":142,"col":55,"offset":2509}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":170,"col":27,"offset":5301},"end":{"line":170,"col":51,"offset":5325}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":192,"col":27,"offset":5301},"end":{"line":192,"col":51,"offset":5325}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":209,"col":33,"offset":5301},"end":{"line":209,"col":55,"offset":5323}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:170:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.runner` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":170,"col":27,"offset":5301},"end":{"line":170,"col":51,"offset":5325}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":192,"col":27,"offset":5301},"end":{"line":192,"col":51,"offset":5325}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":209,"col":33,"offset":5301},"end":{"line":209,"col":55,"offset":5323}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":237,"col":27,"offset":8260},"end":{"line":237,"col":51,"offset":8284}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":258,"col":27,"offset":8260},"end":{"line":258,"col":51,"offset":8284}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":274,"col":33,"offset":8260},"end":{"line":274,"col":55,"offset":8282}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:237:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.runner` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":237,"col":27,"offset":8260},"end":{"line":237,"col":51,"offset":8284}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":258,"col":27,"offset":8260},"end":{"line":258,"col":51,"offset":8284}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":274,"col":33,"offset":8260},"end":{"line":274,"col":55,"offset":8282}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":302,"col":27,"offset":10966},"end":{"line":302,"col":51,"offset":10990}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":318,"col":27,"offset":10966},"end":{"line":318,"col":51,"offset":10990}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":329,"col":33,"offset":10966},"end":{"line":329,"col":55,"offset":10988}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:302:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.runner` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":302,"col":27,"offset":10966},"end":{"line":302,"col":51,"offset":10990}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":318,"col":27,"offset":10966},"end":{"line":318,"col":51,"offset":10990}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":329,"col":33,"offset":10966},"end":{"line":329,"col":55,"offset":10988}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":357,"col":27,"offset":13198},"end":{"line":357,"col":51,"offset":13222}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":376,"col":27,"offset":13198},"end":{"line":376,"col":51,"offset":13222}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":390,"col":33,"offset":13198},"end":{"line":390,"col":55,"offset":13220}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:357:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.runner` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":357,"col":27,"offset":13198},"end":{"line":357,"col":51,"offset":13222}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":376,"col":27,"offset":13198},"end":{"line":376,"col":51,"offset":13222}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":390,"col":33,"offset":13198},"end":{"line":390,"col":55,"offset":13220}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":416,"col":27,"offset":15795},"end":{"line":416,"col":51,"offset":15819}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":433,"col":27,"offset":15795},"end":{"line":433,"col":51,"offset":15819}},{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":445,"col":33,"offset":15795},"end":{"line":445,"col":55,"offset":15817}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:416:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.runner` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":416,"col":27,"offset":15795},"end":{"line":416,"col":51,"offset":15819}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":433,"col":27,"offset":15795},"end":{"line":433,"col":51,"offset":15819}},{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":445,"col":33,"offset":15795},"end":{"line":445,"col":55,"offset":15817}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":488,"col":18,"offset":18951},"end":{"line":646,"col":2,"offset":25326}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:488:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`TK Consolidating all parallel analysis results...\"\npython -c \"\nimport json\nimport os\nimport glob\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Create consolidated results\nconsolidated = {\n    'consolidated_timestamp': datetime.now().isoformat(),\n    'execution_mode': 'parallel',\n    'analysis_summary': {},\n    'overall_scores': {},\n    'critical_issues': [],\n    'recommendations': [],\n    'runner_efficiency': {}\n}\n\n# Find all analysis files\nanalysis_files = glob.glob('./analysis-artifacts/*_analysis.json')\n\ntotal_quality_score = 0\nanalysis_count = 0\nrunner_usage = {}\n\nfor filepath in analysis_files:\n    try:\n        with open(filepath, 'r') as f:\n            data = json.load(f)\n        \n        analysis_type = data.get('analysis_type', '').replace('-analysis', '').replace('-', '_')\n        runner_type = data.get('runner_type', 'unknown')\n        \n        # Track runner usage\n        if runner_type not in runner_usage:\n            runner_usage[runner_type] = 0\n        runner_usage[runner_type] += 1\n        \n        # Process each analysis type\n        if 'connascence' in analysis_type:\n            score = data.get('summary', {}).get('overall_quality_score', 0)\n            violations = len(data.get('violations', []))\n            nasa_score = data.get('nasa_compliance', {}).get('score', 0)\n            \n            consolidated['analysis_summary']['connascence'] = {\n                'quality_score': score,\n                'total_violations': violations,\n                'nasa_compliance': nasa_score,\n                'critical_violations': data.get('summary', {}).get('critical_violations', 0),\n                'runner_type': runner_type,\n                'fallback': data.get('fallback', False)\n            }\n            total_quality_score += score\n            analysis_count += 1\n            \n        elif 'architecture' in analysis_type:\n            health = data.get('system_overview', {}).get... (truncated 4460 more characters)","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":488,"col":18,"offset":18951},"end":{"line":646,"col":2,"offset":25326}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":692,"col":18,"offset":26825},"end":{"line":695,"col":12,"offset":26891}}]],"message":"Syntax error at line .github\\workflows\\quality-orchestrator-parallel.yml:692:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `i PARALLEL QUALITY GATE FAILED')\n    sys.exit(1)\nelse:\n    print('` was unexpected","path":".github\\workflows\\quality-orchestrator-parallel.yml","spans":[{"file":".github\\workflows\\quality-orchestrator-parallel.yml","start":{"line":692,"col":18,"offset":26825},"end":{"line":695,"col":12,"offset":26891}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\security-pipeline.yml","start":{"line":61,"col":67,"offset":1561},"end":{"line":61,"col":89,"offset":1583}},{"path":".github\\workflows\\security-pipeline.yml","start":{"line":73,"col":39,"offset":1561},"end":{"line":73,"col":61,"offset":1583}},{"path":".github\\workflows\\security-pipeline.yml","start":{"line":100,"col":10,"offset":1561},"end":{"line":100,"col":32,"offset":1583}},{"path":".github\\workflows\\security-pipeline.yml","start":{"line":110,"col":12,"offset":1561},"end":{"line":110,"col":34,"offset":1583}},{"path":".github\\workflows\\security-pipeline.yml","start":{"line":120,"col":12,"offset":1561},"end":{"line":120,"col":34,"offset":1583}}]],"message":"Syntax error at line .github\\workflows\\security-pipeline.yml:61:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ matrix.analysis.name` was unexpected","path":".github\\workflows\\security-pipeline.yml","spans":[{"file":".github\\workflows\\security-pipeline.yml","start":{"line":61,"col":67,"offset":1561},"end":{"line":61,"col":89,"offset":1583}},{"file":".github\\workflows\\security-pipeline.yml","start":{"line":73,"col":39,"offset":1561},"end":{"line":73,"col":61,"offset":1583}},{"file":".github\\workflows\\security-pipeline.yml","start":{"line":100,"col":10,"offset":1561},"end":{"line":100,"col":32,"offset":1583}},{"file":".github\\workflows\\security-pipeline.yml","start":{"line":110,"col":12,"offset":1561},"end":{"line":110,"col":34,"offset":1583}},{"file":".github\\workflows\\security-pipeline.yml","start":{"line":120,"col":12,"offset":1561},"end":{"line":120,"col":34,"offset":1583}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":209,"col":18,"offset":8547},"end":{"line":209,"col":21,"offset":8550}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":214,"col":16,"offset":8547},"end":{"line":214,"col":19,"offset":8550}}]],"message":"Syntax error at line .github\\workflows\\self-dogfooding.yml:209:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `${{` was unexpected","path":".github\\workflows\\self-dogfooding.yml","spans":[{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":209,"col":18,"offset":8547},"end":{"line":209,"col":21,"offset":8550}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":214,"col":16,"offset":8547},"end":{"line":214,"col":19,"offset":8550}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":285,"col":20,"offset":11965},"end":{"line":285,"col":32,"offset":11977}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":286,"col":30,"offset":11965},"end":{"line":286,"col":75,"offset":12010}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":287,"col":25,"offset":11965},"end":{"line":287,"col":76,"offset":12016}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":288,"col":28,"offset":11965},"end":{"line":288,"col":82,"offset":12019}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":289,"col":20,"offset":11965},"end":{"line":289,"col":66,"offset":12011}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":290,"col":19,"offset":11965},"end":{"line":290,"col":64,"offset":12010}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":291,"col":31,"offset":11965},"end":{"line":291,"col":88,"offset":12022}}]],"message":"Syntax error at line .github\\workflows\\self-dogfooding.yml:285:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.sha` was unexpected","path":".github\\workflows\\self-dogfooding.yml","spans":[{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":285,"col":20,"offset":11965},"end":{"line":285,"col":32,"offset":11977}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":286,"col":30,"offset":11965},"end":{"line":286,"col":75,"offset":12010}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":287,"col":25,"offset":11965},"end":{"line":287,"col":76,"offset":12016}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":288,"col":28,"offset":11965},"end":{"line":288,"col":82,"offset":12019}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":289,"col":20,"offset":11965},"end":{"line":289,"col":66,"offset":12011}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":290,"col":19,"offset":11965},"end":{"line":290,"col":64,"offset":12010}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":291,"col":31,"offset":11965},"end":{"line":291,"col":88,"offset":12022}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":309,"col":32,"offset":13267},"end":{"line":309,"col":77,"offset":13312}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":310,"col":33,"offset":13267},"end":{"line":310,"col":84,"offset":13318}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":311,"col":36,"offset":13267},"end":{"line":311,"col":90,"offset":13321}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":312,"col":28,"offset":13267},"end":{"line":312,"col":74,"offset":13313}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":313,"col":27,"offset":13267},"end":{"line":313,"col":72,"offset":13312}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":316,"col":10,"offset":13267},"end":{"line":316,"col":67,"offset":13324}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":326,"col":56,"offset":13267},"end":{"line":326,"col":75,"offset":13286}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":326,"col":94,"offset":13267},"end":{"line":326,"col":109,"offset":13282}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":327,"col":49,"offset":13267},"end":{"line":327,"col":68,"offset":13286}},{"path":".github\\workflows\\self-dogfooding.yml","start":{"line":327,"col":87,"offset":13267},"end":{"line":327,"col":102,"offset":13282}}]],"message":"Syntax error at line .github\\workflows\\self-dogfooding.yml:309:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ steps.self-quality-gates.outputs.nasa_score` was unexpected","path":".github\\workflows\\self-dogfooding.yml","spans":[{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":309,"col":32,"offset":13267},"end":{"line":309,"col":77,"offset":13312}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":310,"col":33,"offset":13267},"end":{"line":310,"col":84,"offset":13318}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":311,"col":36,"offset":13267},"end":{"line":311,"col":90,"offset":13321}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":312,"col":28,"offset":13267},"end":{"line":312,"col":74,"offset":13313}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":313,"col":27,"offset":13267},"end":{"line":313,"col":72,"offset":13312}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":316,"col":10,"offset":13267},"end":{"line":316,"col":67,"offset":13324}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":326,"col":56,"offset":13267},"end":{"line":326,"col":75,"offset":13286}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":326,"col":94,"offset":13267},"end":{"line":326,"col":109,"offset":13282}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":327,"col":49,"offset":13267},"end":{"line":327,"col":68,"offset":13286}},{"file":".github\\workflows\\self-dogfooding.yml","start":{"line":327,"col":87,"offset":13267},"end":{"line":327,"col":102,"offset":13282}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\setup-branch-protection.yml","start":{"line":207,"col":27,"offset":7166},"end":{"line":207,"col":52,"offset":7191}},{"path":".github\\workflows\\setup-branch-protection.yml","start":{"line":208,"col":24,"offset":7166},"end":{"line":208,"col":46,"offset":7188}}]],"message":"Syntax error at line .github\\workflows\\setup-branch-protection.yml:207:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ inputs.protection_level` was unexpected","path":".github\\workflows\\setup-branch-protection.yml","spans":[{"file":".github\\workflows\\setup-branch-protection.yml","start":{"line":207,"col":27,"offset":7166},"end":{"line":207,"col":52,"offset":7191}},{"file":".github\\workflows\\setup-branch-protection.yml","start":{"line":208,"col":24,"offset":7166},"end":{"line":208,"col":46,"offset":7188}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":86,"col":29,"offset":2333},"end":{"line":86,"col":60,"offset":2364}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":86,"col":89,"offset":2333},"end":{"line":86,"col":104,"offset":2348}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":88,"col":6,"offset":2333},"end":{"line":88,"col":49,"offset":2376}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:86:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ env.VALIDATION_SESSION_PREFIX` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":86,"col":29,"offset":2333},"end":{"line":86,"col":60,"offset":2364}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":86,"col":89,"offset":2333},"end":{"line":86,"col":104,"offset":2348}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":88,"col":6,"offset":2333},"end":{"line":88,"col":49,"offset":2376}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":95,"col":11,"offset":2632},"end":{"line":95,"col":48,"offset":2669}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":97,"col":11,"offset":2632},"end":{"line":97,"col":48,"offset":2669}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":103,"col":6,"offset":2632},"end":{"line":103,"col":45,"offset":2671}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:95:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.event.inputs.validation_mode` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":95,"col":11,"offset":2632},"end":{"line":95,"col":48,"offset":2669}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":97,"col":11,"offset":2632},"end":{"line":97,"col":48,"offset":2669}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":103,"col":6,"offset":2632},"end":{"line":103,"col":45,"offset":2671}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":109,"col":9,"offset":3513},"end":{"line":109,"col":46,"offset":3550}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":109,"col":77,"offset":3513},"end":{"line":109,"col":114,"offset":3550}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:109:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.event.inputs.validation_mode` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":109,"col":9,"offset":3513},"end":{"line":109,"col":46,"offset":3550}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":109,"col":77,"offset":3513},"end":{"line":109,"col":114,"offset":3550}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":155,"col":29,"offset":5108},"end":{"line":155,"col":83,"offset":5162}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":156,"col":6,"offset":5108},"end":{"line":158,"col":177,"offset":5390}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:155:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ needs.setup-validation.outputs.validation-session-id` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":155,"col":29,"offset":5108},"end":{"line":155,"col":83,"offset":5162}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":156,"col":6,"offset":5108},"end":{"line":158,"col":177,"offset":5390}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":162,"col":20,"offset":5566},"end":{"line":167,"col":30,"offset":5797}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:162:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`Uh System Information:\"\necho \"Memory: $(free -h | grep '^Mem:' | awk '{print $2}')\"\necho \"CPU: $(nproc) cores\"\necho \"Disk: $(df -h . | tail -1 | awk '{print $4}')\"\necho \"Python: $(python --version)\"\necho \"Git: $(git --version)\"\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":162,"col":20,"offset":5566},"end":{"line":167,"col":30,"offset":5797}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":172,"col":20,"offset":5952},"end":{"line":198,"col":4,"offset":6920}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:172:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`Op Running Consolidated Analyzer Validation\"\nVERBOSE_FLAG=\"\"\nif [ \"${{ github.event.inputs.verbose }}\" = \"true\" ]; then\n  VERBOSE_FLAG=\"--verbose\"\nfi\n\n# Test the three main consolidated commands work correctly\necho \"Testing consolidated connascence analyzer...\"\ncd analyzer && python core.py --path .. --format json --output ../validation-test.json || echo \"Test completed\"\ncd ..\n\necho \"Testing MECE analyzer...\"\ncd analyzer && python -m dup_detection.mece_analyzer --path .. --comprehensive --output ../mece-test.json || echo \"MECE test completed\"\ncd ..\n\necho \"Testing NASA policy analyzer...\"\ncd analyzer && python core.py --path .. --policy nasa_jpl_pot10 --format json --output ../nasa-test.json || echo \"NASA test completed\"\ncd ..\n\nVALIDATION_EXIT_CODE=$?\necho \"validation-exit-code=${VALIDATION_EXIT_CODE}\" >> $GITHUB_OUTPUT\n\nif [ ${VALIDATION_EXIT_CODE} -eq 0 ]; then\n  echo \"D]F Validation PASSED\"\nelse\n  echo \"D[aQyP Validation completed with warnings\"\nfi\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":172,"col":20,"offset":5952},"end":{"line":198,"col":4,"offset":6920}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":204,"col":9,"offset":7271},"end":{"line":204,"col":56,"offset":7318}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":209,"col":21,"offset":7271},"end":{"line":209,"col":24,"offset":7274}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":210,"col":1,"offset":7271},"end":{"line":210,"col":20,"offset":7290}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":213,"col":18,"offset":7271},"end":{"line":213,"col":68,"offset":7321}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:204:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ steps.validation.outputs.validation-exit-code` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":204,"col":9,"offset":7271},"end":{"line":204,"col":56,"offset":7318}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":209,"col":21,"offset":7271},"end":{"line":209,"col":24,"offset":7274}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":210,"col":1,"offset":7271},"end":{"line":210,"col":20,"offset":7290}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":213,"col":18,"offset":7271},"end":{"line":213,"col":68,"offset":7321}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":227,"col":11,"offset":8254},"end":{"line":274,"col":3,"offset":10145}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:227:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"\nimport json\nimport os\nfrom datetime import datetime\n\nmemory_data = {\n    'coordination_system': 'github-actions-memory',\n    'version': '1.0.0',\n    'session_id': '${{ needs.setup-validation.outputs.validation-session-id }}',\n    'matrix_name': '${{ matrix.name }}',\n    'timestamp': datetime.now().isoformat(),\n    'system_info': {\n        'runner_os': '${{ runner.os }}',\n        'memory_limit': '${{ matrix.memory_limit || \\\"2GB\\\" }}',\n        'timeout': ${{ matrix.timeout || 30 }}\n    },\n    'validation_summary': {},\n    'analyzer_tests': {\n        'connascence': 'pass' if os.path.exists('validation-test.json') else 'fail',\n        'mece': 'pass' if os.path.exists('mece-test.json') else 'fail',\n        'nasa': 'pass' if os.path.exists('nasa-test.json') else 'fail'\n    }\n}\n\n# Add consolidated analyzer results if available\nfor test_file, test_name in [('validation-test.json', 'connascence'), \n                            ('mece-test.json', 'mece'), \n                            ('nasa-test.json', 'nasa')]:\n    if os.path.exists(test_file):\n        try:\n            with open(test_file, 'r') as f:\n                test_data = json.load(f)\n            memory_data['validation_summary'][test_name] = {\n                'violations': len(test_data.get('violations', [])),\n                'success': test_data.get('success', True),\n                'file_size': os.path.getsize(test_file)\n            }\n        except:\n            memory_data['validation_summary'][test_name] = {'error': 'parse_failed'}\n\n# Write memory coordination data with proper path\nos.makedirs('ci-metrics/${{ matrix.name }}', exist_ok=True)\nwith open('ci-metrics/${{ matrix.name }}/memory-coordination.json', 'w') as f:\n    json.dump(memory_data, f, indent=2)\n    \nprint(f'R`TK Memory coordination data written for {memory_data[\\\"matrix_name\\\"]}')\nprint(f'Analyzer tests: {memory_data[\\\"analyzer_tests\\\"]}')\n\"\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":227,"col":11,"offset":8254},"end":{"line":274,"col":3,"offset":10145}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":291,"col":49,"offset":11110},"end":{"line":291,"col":96,"offset":11157}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:291:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ steps.validation.outputs.validation-exit-code` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":291,"col":49,"offset":11110},"end":{"line":291,"col":96,"offset":11157}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":322,"col":20,"offset":12183},"end":{"line":448,"col":44,"offset":16762}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:322:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`[A Running performance benchmarks...\"\n\n# Create benchmark script\ncat > scripts/ci/performance_benchmark.py << 'EOF'\n#!/usr/bin/env python3\n\"\"\"Performance benchmarking for CI pipeline\"\"\"\n\nimport time\nimport json\nimport psutil\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\nfrom memory_profiler import profile\n\nclass PerformanceBenchmark:\n    def __init__(self):\n        self.results = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"system_info\": {\n                \"cpu_count\": psutil.cpu_count(),\n                \"memory_total\": psutil.virtual_memory().total,\n                \"python_version\": sys.version\n            },\n            \"benchmarks\": {}\n        }\n    \n    def benchmark_validation_speed(self):\n        \"\"\"Benchmark validation script performance\"\"\"\n        print(\"R`UN Benchmarking validation speed...\")\n        \n        start_time = time.time()\n        start_memory = psutil.Process().memory_info().rss\n        \n        try:\n            # Benchmark consolidated analyzer performance\n            result = subprocess.run([\n                sys.executable, \"core.py\",\n                \"--path\", \"..\", \"--format\", \"json\", \"--output\", \"../benchmark-test.json\"\n            ], cwd=\"analyzer\", capture_output=True, text=True, timeout=300)\n            \n            end_time = time.time()\n            end_memory = psutil.Process().memory_info().rss\n            \n            self.results[\"benchmarks\"][\"validation_speed\"] = {\n                \"duration_seconds\": round(end_time - start_time, 2),\n                \"memory_delta_mb\": round((end_memory - start_memory) / 1024 / 1024, 2),\n                \"exit_code\": result.returncode,\n                \"status\": \"success\" if result.returncode == 0 else \"failed\"\n            }\n            \n        except subprocess.TimeoutExpired:\n            self.results[\"benchmarks\"][\"validation_speed\"] = {\n                \"status\": \"timeo... (truncated 2664 more characters)","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":322,"col":20,"offset":12183},"end":{"line":448,"col":44,"offset":16762}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":456,"col":20,"offset":18093},"end":{"line":456,"col":74,"offset":18147}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:456:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ needs.setup-validation.outputs.validation-session-id` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":456,"col":20,"offset":18093},"end":{"line":456,"col":74,"offset":18147}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":499,"col":20,"offset":19722},"end":{"line":526,"col":4,"offset":20673}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:499:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`UE Reproducibility Test - Attempt ${{ matrix.run }}\"\npython scripts/verify_counts.py --base-path . --verbose > reproducibility-run-${{ matrix.run }}.log 2>&1\n\n# Generate fingerprint of results\nif [ -f \"DEMO_ARTIFACTS/validation_report.json\" ]; then\n  python -c \"\n  import json\n  import hashlib\n  \n  with open('DEMO_ARTIFACTS/validation_report.json', 'r') as f:\n      data = json.load(f)\n  \n  # Create deterministic fingerprint\n  fingerprint_data = {\n      'summary': data.get('summary', {}),\n      'expected_counts': data.get('expected_counts', {}),\n      'actual_counts': data.get('actual_counts', {})\n  }\n  \n  fingerprint_str = json.dumps(fingerprint_data, sort_keys=True)\n  fingerprint_hash = hashlib.sha256(fingerprint_str.encode()).hexdigest()\n  \n  with open('reproducibility-fingerprint-${{ matrix.run }}.txt', 'w') as f:\n      f.write(fingerprint_hash)\n  \n  print(f'Reproducibility fingerprint ${{ matrix.run }}: {fingerprint_hash}')\n  \"\nfi\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":499,"col":20,"offset":19722},"end":{"line":526,"col":4,"offset":20673}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":531,"col":24,"offset":21015},"end":{"line":531,"col":27,"offset":21018}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":532,"col":40,"offset":21015},"end":{"line":532,"col":52,"offset":21027}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":533,"col":34,"offset":21015},"end":{"line":533,"col":37,"offset":21018}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:531:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `${{` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":531,"col":24,"offset":21015},"end":{"line":531,"col":27,"offset":21018}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":532,"col":40,"offset":21015},"end":{"line":532,"col":52,"offset":21027}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":533,"col":34,"offset":21015},"end":{"line":533,"col":37,"offset":21018}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":587,"col":6,"offset":22111},"end":{"line":587,"col":62,"offset":22167}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:587:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`PG Generated validation badge: ${VALIDATION_STATUS}\"\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":587,"col":6,"offset":22111},"end":{"line":587,"col":62,"offset":22167}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":668,"col":6,"offset":24600},"end":{"line":668,"col":63,"offset":24657}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:668:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`Op Generated count validation badge: ${COUNT_STATUS}\"\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":668,"col":6,"offset":24600},"end":{"line":668,"col":63,"offset":24657}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":676,"col":20,"offset":26184},"end":{"line":676,"col":74,"offset":26238}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":685,"col":20,"offset":26184},"end":{"line":685,"col":37,"offset":26201}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":686,"col":18,"offset":26184},"end":{"line":686,"col":33,"offset":26199}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:676:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ needs.setup-validation.outputs.validation-session-id` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":676,"col":20,"offset":26184},"end":{"line":676,"col":74,"offset":26238}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":685,"col":20,"offset":26184},"end":{"line":685,"col":37,"offset":26201}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":686,"col":18,"offset":26184},"end":{"line":686,"col":33,"offset":26199}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":807,"col":11,"offset":31869},"end":{"line":853,"col":3,"offset":33353}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:807:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"\nimport json\nimport os\nfrom datetime import datetime\n\ntrend_file = 'ci-metrics/trends/ci-trends-$(date +%Y-%m).json'\n\n# Load existing trend data\ntrend_data = {'runs': []}\nif os.path.exists(trend_file):\n    try:\n        with open(trend_file, 'r') as f:\n            trend_data = json.load(f)\n    except:\n        pass\n\n# Add current run data\nrun_data = {\n    'run_id': '${{ github.run_id }}',\n    'timestamp': datetime.now().isoformat(),\n    'sha': '${{ github.sha }}',\n    'ref': '${{ github.ref }}',\n    'workflow': '${{ github.workflow }}'\n}\n\n# Load comprehensive memory report if available\nif os.path.exists('ci-metrics/final/comprehensive-memory-report.json'):\n    with open('ci-metrics/final/comprehensive-memory-report.json', 'r') as f:\n        memory_report = json.load(f)\n    run_data['coordination_summary'] = memory_report.get('coordination_summary', {})\n    if memory_report.get('performance_data'):\n        perf_data = memory_report['performance_data']\n        benchmarks = perf_data.get('benchmarks', {})\n        if 'validation_speed' in benchmarks:\n            run_data['validation_duration'] = benchmarks['validation_speed'].get('duration_seconds')\n\ntrend_data['runs'].append(run_data)\n\n# Keep only last 100 runs to manage file size\nif len(trend_data['runs']) > 100:\n    trend_data['runs'] = trend_data['runs'][-100:]\n\nwith open(trend_file, 'w') as f:\n    json.dump(trend_data, f, indent=2)\n\nprint(f'R`TI Updated trend data: {len(trend_data[\\\"runs\\\"])} runs tracked')\n\"\n` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":807,"col":11,"offset":31869},"end":{"line":853,"col":3,"offset":33353}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":866,"col":19,"offset":34336},"end":{"line":866,"col":22,"offset":34339}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":867,"col":17,"offset":34336},"end":{"line":867,"col":20,"offset":34339}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":868,"col":15,"offset":34336},"end":{"line":868,"col":18,"offset":34339}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":879,"col":9,"offset":34336},"end":{"line":879,"col":30,"offset":34357}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":880,"col":3,"offset":34336},"end":{"line":880,"col":8,"offset":34341}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":881,"col":8,"offset":34336},"end":{"line":881,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":881,"col":70,"offset":34336},"end":{"line":881,"col":71,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":882,"col":8,"offset":34336},"end":{"line":882,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":882,"col":63,"offset":34336},"end":{"line":882,"col":64,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":883,"col":8,"offset":34336},"end":{"line":883,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":883,"col":76,"offset":34336},"end":{"line":883,"col":77,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":884,"col":9,"offset":34336},"end":{"line":884,"col":11,"offset":34338}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":885,"col":3,"offset":34336},"end":{"line":885,"col":8,"offset":34341}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":886,"col":8,"offset":34336},"end":{"line":886,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":886,"col":51,"offset":34336},"end":{"line":886,"col":52,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":887,"col":8,"offset":34336},"end":{"line":887,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":887,"col":41,"offset":34336},"end":{"line":887,"col":42,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":888,"col":8,"offset":34336},"end":{"line":888,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":888,"col":42,"offset":34336},"end":{"line":888,"col":43,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":889,"col":8,"offset":34336},"end":{"line":889,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":889,"col":45,"offset":34336},"end":{"line":889,"col":46,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":890,"col":8,"offset":34336},"end":{"line":890,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":890,"col":47,"offset":34336},"end":{"line":890,"col":48,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":891,"col":9,"offset":34336},"end":{"line":891,"col":11,"offset":34338}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":892,"col":3,"offset":34336},"end":{"line":892,"col":8,"offset":34341}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":893,"col":8,"offset":34336},"end":{"line":893,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":893,"col":44,"offset":34336},"end":{"line":893,"col":45,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":894,"col":8,"offset":34336},"end":{"line":894,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":894,"col":95,"offset":34336},"end":{"line":894,"col":96,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":895,"col":8,"offset":34336},"end":{"line":895,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":895,"col":70,"offset":34336},"end":{"line":895,"col":71,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":896,"col":8,"offset":34336},"end":{"line":896,"col":9,"offset":34337}},{"path":".github\\workflows\\validate-artifacts.yml","start":{"line":896,"col":46,"offset":34336},"end":{"line":896,"col":47,"offset":34337}}]],"message":"Syntax error at line .github\\workflows\\validate-artifacts.yml:866:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `${{` was unexpected","path":".github\\workflows\\validate-artifacts.yml","spans":[{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":866,"col":19,"offset":34336},"end":{"line":866,"col":22,"offset":34339}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":867,"col":17,"offset":34336},"end":{"line":867,"col":20,"offset":34339}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":868,"col":15,"offset":34336},"end":{"line":868,"col":18,"offset":34339}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":879,"col":9,"offset":34336},"end":{"line":879,"col":30,"offset":34357}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":880,"col":3,"offset":34336},"end":{"line":880,"col":8,"offset":34341}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":881,"col":8,"offset":34336},"end":{"line":881,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":881,"col":70,"offset":34336},"end":{"line":881,"col":71,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":882,"col":8,"offset":34336},"end":{"line":882,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":882,"col":63,"offset":34336},"end":{"line":882,"col":64,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":883,"col":8,"offset":34336},"end":{"line":883,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":883,"col":76,"offset":34336},"end":{"line":883,"col":77,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":884,"col":9,"offset":34336},"end":{"line":884,"col":11,"offset":34338}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":885,"col":3,"offset":34336},"end":{"line":885,"col":8,"offset":34341}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":886,"col":8,"offset":34336},"end":{"line":886,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":886,"col":51,"offset":34336},"end":{"line":886,"col":52,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":887,"col":8,"offset":34336},"end":{"line":887,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":887,"col":41,"offset":34336},"end":{"line":887,"col":42,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":888,"col":8,"offset":34336},"end":{"line":888,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":888,"col":42,"offset":34336},"end":{"line":888,"col":43,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":889,"col":8,"offset":34336},"end":{"line":889,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":889,"col":45,"offset":34336},"end":{"line":889,"col":46,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":890,"col":8,"offset":34336},"end":{"line":890,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":890,"col":47,"offset":34336},"end":{"line":890,"col":48,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":891,"col":9,"offset":34336},"end":{"line":891,"col":11,"offset":34338}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":892,"col":3,"offset":34336},"end":{"line":892,"col":8,"offset":34341}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":893,"col":8,"offset":34336},"end":{"line":893,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":893,"col":44,"offset":34336},"end":{"line":893,"col":45,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":894,"col":8,"offset":34336},"end":{"line":894,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":894,"col":95,"offset":34336},"end":{"line":894,"col":96,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":895,"col":8,"offset":34336},"end":{"line":895,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":895,"col":70,"offset":34336},"end":{"line":895,"col":71,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":896,"col":8,"offset":34336},"end":{"line":896,"col":9,"offset":34337}},{"file":".github\\workflows\\validate-artifacts.yml","start":{"line":896,"col":46,"offset":34336},"end":{"line":896,"col":47,"offset":34337}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":40,"col":15,"offset":941},"end":{"line":49,"col":4,"offset":1324}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:40:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `if npm run --silent 2>/dev/null | grep -E '^\\s*lint\\s' >/dev/null 2>&1; then\n  echo \"R`TL Running lint checks...\"\n  npm run lint || {\n    echo \"D[aQyP Lint warnings detected but not blocking build\"\n    echo \"This is acceptable for pre-compiled extensions\"\n  }\nelse\n  echo \"DEzQyP No lint script configured, skipping lint check\"\n  echo \"This is normal for pre-compiled extensions\"\nfi\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":40,"col":15,"offset":941},"end":{"line":49,"col":4,"offset":1324}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":55,"col":15,"offset":1542},"end":{"line":64,"col":4,"offset":1906}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:55:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `if [ -f \"tsconfig.json\" ]; then\n  echo \"R`T^ Running TypeScript type checking...\"\n  npx tsc --noEmit || {\n    echo \"D[aQyP TypeScript warnings detected but not blocking build\"\n    echo \"This is acceptable for pre-compiled extensions with minor type issues\"\n  }\nelse\n  echo \"DEzQyP No TypeScript configuration found\"\n  echo \"Using pre-compiled JavaScript files\"\nfi\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":55,"col":15,"offset":1542},"end":{"line":64,"col":4,"offset":1906}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":79,"col":20,"offset":2397},"end":{"line":87,"col":3,"offset":2730}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:79:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`US Running security audit...\"\nnpm audit --audit-level=high --production || {\n  echo \"D[aQyP Security audit found issues - checking severity...\"\n  npm audit --audit-level=critical --production || {\n    echo \"D^M Critical security vulnerabilities found!\"\n    exit 1\n  }\n  echo \"D]F No critical vulnerabilities - continuing build\"\n}\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":79,"col":20,"offset":2397},"end":{"line":87,"col":3,"offset":2730}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":142,"col":15,"offset":4809},"end":{"line":151,"col":4,"offset":5246}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:142:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `if npm run --silent 2>/dev/null | grep -E '^\\s*test\\s' >/dev/null 2>&1; then\n  echo \"R`hk Running test suite...\"\n  npm test || {\n    echo \"D[aQyP Tests failed but continuing build (acceptable for pre-compiled extensions)\"\n    echo \"Test failures may be due to missing test environment in CI\"\n  }\nelse\n  echo \"DEzQyP No test script configured - skipping tests\"\n  echo \"This is acceptable for extensions with manual testing validation\"\nfi\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":142,"col":15,"offset":4809},"end":{"line":151,"col":4,"offset":5246}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":206,"col":15,"offset":7342},"end":{"line":226,"col":4,"offset":8157}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:206:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `echo \"R`Tg Installing VSCE (VS Code Extension packager)...\"\nnpm install -g @vscode/vsce@latest\n\necho \"R`Tg Packaging extension...\"\nif vsce package --no-dependencies --no-update-package-json; then\n  echo \"D]F Extension packaged successfully!\"\nelse\n  echo \"D^M Packaging failed with standard options, trying alternatives...\"\n  if vsce package --allow-missing-repository --no-dependencies; then\n    echo \"D]F Extension packaged with fallback options!\"\n  else\n    echo \"D^M Packaging failed completely - checking structure...\"\n    echo \"R`UN Current directory contents:\"\n    ls -la\n    if [ -f \"package.json\" ]; then\n      echo \"R`TL Package.json content:\"\n      node -e \"const pkg=require('./package.json'); console.log('Main entry:', pkg.main); console.log('Engine:', pkg.engines?.vscode);\"\n    fi\n    exit 1\n  fi\nfi\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":206,"col":15,"offset":7342},"end":{"line":226,"col":4,"offset":8157}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":274,"col":6,"offset":8467},"end":{"line":274,"col":45,"offset":8506}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:274:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`OJ Package verification completed!\"\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":274,"col":6,"offset":8467},"end":{"line":274,"col":45,"offset":8506}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":319,"col":6,"offset":11068},"end":{"line":330,"col":37,"offset":11530}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:319:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`\\aQyP Auditing development dependencies...\"\nnpm audit --audit-level=moderate || {\n  echo \"DEzQyP Development dependencies have some security issues - acceptable for extensions\"\n  echo \"Extension packages don't ship development dependencies to end users\"\n}\n\necho \"R`Uh Attempting automatic security fixes...\"\nnpm audit fix --only=prod || {\n  echo \"DEzQyP Some issues couldn't be auto-fixed - manual review may be needed\"\n}\n\necho \"D]F Security audit completed\"\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":319,"col":6,"offset":11068},"end":{"line":330,"col":37,"offset":11530}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":344,"col":20,"offset":12654},"end":{"line":361,"col":4,"offset":13269}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:344:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`UN Additional security checks...\"\n\necho \"Checking for hardcoded secrets...\"\nFOUND_SECRETS=false\n\nif grep -r -i \"api_key\\|apikey\\|secret\\|token\\|password\" --include=\"*.js\" --include=\"*.ts\" --include=\"*.json\" . | grep -v node_modules | grep -v \"\\.git\" || true; then\n  echo \"D[aQyP Potential secrets found - manual review recommended\"\n  FOUND_SECRETS=true\nfi\n\nif find . -name \".env*\" -not -path \"./node_modules/*\" | head -5; then\n  echo \"D[aQyP Environment files found - ensure they don't contain secrets\"\n  FOUND_SECRETS=true\nfi\n\nif [ \"$FOUND_SECRETS\" = \"false\" ]; then\n  echo \"D]F No obvious secrets detected\"\nfi\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":344,"col":20,"offset":12654},"end":{"line":361,"col":4,"offset":13269}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":428,"col":6,"offset":14190},"end":{"line":435,"col":4,"offset":14462}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:428:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`[A Performance Analysis:\"\nif [ \"$SIZE_KB\" -lt 1024 ]; then\n  echo \"  D[b Excellent: Fast download and installation\"\nelif [ \"$SIZE_KB\" -lt 5120 ]; then\n  echo \"  D]F Good: Reasonable download time\"\nelse\n  echo \"  D[aQyP Large: May impact download/installation speed\"\nfi\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":428,"col":6,"offset":14190},"end":{"line":435,"col":4,"offset":14462}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":502,"col":26,"offset":19379},"end":{"line":502,"col":29,"offset":19382}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":503,"col":17,"offset":19379},"end":{"line":503,"col":20,"offset":19382}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":504,"col":21,"offset":19379},"end":{"line":504,"col":24,"offset":19382}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":537,"col":12,"offset":19379},"end":{"line":538,"col":41,"offset":19451}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:502:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `${{` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":502,"col":26,"offset":19379},"end":{"line":502,"col":29,"offset":19382}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":503,"col":17,"offset":19379},"end":{"line":503,"col":20,"offset":19382}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":504,"col":21,"offset":19379},"end":{"line":504,"col":24,"offset":19382}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":537,"col":12,"offset":19379},"end":{"line":538,"col":41,"offset":19451}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":557,"col":14,"offset":21540},"end":{"line":557,"col":26,"offset":21552}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":561,"col":32,"offset":21540},"end":{"line":561,"col":72,"offset":21580}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":562,"col":26,"offset":21540},"end":{"line":562,"col":71,"offset":21585}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":563,"col":27,"offset":21540},"end":{"line":563,"col":73,"offset":21586}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":564,"col":30,"offset":21540},"end":{"line":564,"col":79,"offset":21589}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":568,"col":12,"offset":21540},"end":{"line":568,"col":52,"offset":21580}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":568,"col":85,"offset":21540},"end":{"line":568,"col":125,"offset":21580}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:557:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.sha` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":557,"col":14,"offset":21540},"end":{"line":557,"col":26,"offset":21552}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":561,"col":32,"offset":21540},"end":{"line":561,"col":72,"offset":21580}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":562,"col":26,"offset":21540},"end":{"line":562,"col":71,"offset":21585}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":563,"col":27,"offset":21540},"end":{"line":563,"col":73,"offset":21586}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":564,"col":30,"offset":21540},"end":{"line":564,"col":79,"offset":21589}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":568,"col":12,"offset":21540},"end":{"line":568,"col":52,"offset":21580}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":568,"col":85,"offset":21540},"end":{"line":568,"col":125,"offset":21580}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":618,"col":15,"offset":24416},"end":{"line":692,"col":67,"offset":26652}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:618:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `echo \"R`Pc Enterprise Deployment Readiness Check\"\necho \"========================================\"\n\nVSIX_FILES=(*.vsix)\nif [ ${#VSIX_FILES[@]} -eq 0 ] || [ ! -f \"${VSIX_FILES[0]}\" ]; then\n  echo \"D^M No VSIX package found!\"\n  exit 1\nfi\n\nVSIX_FILE=\"${VSIX_FILES[0]}\"\necho \"R`Tg Validating: $VSIX_FILE\"\n\nif [ -f \"$VSIX_FILE\" ] && [ -s \"$VSIX_FILE\" ]; then\n  echo \"D]F Package exists and is not empty\"\n  \n  SIZE_BYTES=$(stat -c%s \"$VSIX_FILE\" 2>/dev/null || stat -f%z \"$VSIX_FILE\" 2>/dev/null || echo \"0\")\n  SIZE_MB=$(echo \"scale=2; $SIZE_BYTES / 1024 / 1024\" | bc 2>/dev/null || echo \"unknown\")\n  echo \"R`TP Package size: ${SIZE_MB}MB\"\nelse\n  echo \"D^M Package missing or empty\"\n  exit 1\nfi\n\necho \"\"\necho \"R`UN Package Structure Validation:\"\n\nif unzip -l \"$VSIX_FILE\" | grep -E \"(extension\\.js|out/extension\\.js|src/extension\\.js)\" >/dev/null 2>&1; then\n  echo \"D]F Extension entry point found\"\nelse\n  echo \"D^M Extension entry point missing\"\n  exit 1\nfi\n\nif unzip -l \"$VSIX_FILE\" | grep \"extension/package\\.json\" >/dev/null 2>&1; then\n  echo \"D]F Extension package.json found\"\n  \n  TEMP_PKG=$(mktemp)\n  unzip -p \"$VSIX_FILE\" extension/package.json > \"$TEMP_PKG\" 2>/dev/null || {\n    echo \"D^M Could not extract package.json\"\n    exit 1\n  }\n  \n  if grep -q '\"publisher\"' \"$TEMP_PKG\"; then\n    PUBLISHER=$(grep -o '\"publisher\":\\s*\"[^\"]*\"' \"$TEMP_PKG\" | cut -d'\"' -f4)\n    echo \"D]F Publisher: $PUBLISHER\"\n  else\n    echo \"D^M Publisher information missing\"\n    exit 1\n  fi\n  \n  if grep -q '\"engines\"' \"$TEMP_PKG\"; then\n    VSCODE_VERSION=$(grep -A 2 '\"engines\"' \"$TEMP_PKG\" | grep '\"vscode\"' | cut -d'\"' -f4 || echo \"unknown\")\n    echo \"D]F VS Code Engine: $VSCODE_VERSION\"\n  else\n    echo \"D^M VS Code engine version missing\"\n    exit 1\n  fi\n  \n  rm -f \"$TEMP_PKG\"\nelse\n  echo \"D^M Extension package.json not found\"\n  exit 1\nfi\n\necho \"\"\necho \"R`Op Enterprise Deployment Checklist:\"\necho \"D]F Package integrity verified\"\necho \"D]F Stru... (truncated 321 more characters)","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":618,"col":15,"offset":24416},"end":{"line":692,"col":67,"offset":26652}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":705,"col":22,"offset":27568},"end":{"line":705,"col":34,"offset":27580}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:705:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ github.sha` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":705,"col":22,"offset":27568},"end":{"line":705,"col":34,"offset":27580}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":785,"col":6,"offset":31409},"end":{"line":786,"col":72,"offset":31516}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:785:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`[A Ready to publish: $VSIX_FILE\"\necho \"To publish manually, run: vsce publish --packagePath $VSIX_FILE\"\n` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":785,"col":6,"offset":31409},"end":{"line":786,"col":72,"offset":31516}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":801,"col":36,"offset":31963},"end":{"line":801,"col":72,"offset":31999}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":802,"col":16,"offset":31963},"end":{"line":802,"col":57,"offset":32004}},{"path":".github\\workflows\\vscode-extension-ci.yml","start":{"line":811,"col":12,"offset":31963},"end":{"line":815,"col":57,"offset":32274}}]],"message":"Syntax error at line .github\\workflows\\vscode-extension-ci.yml:801:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ needs.enterprise-validation.result` was unexpected","path":".github\\workflows\\vscode-extension-ci.yml","spans":[{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":801,"col":36,"offset":31963},"end":{"line":801,"col":72,"offset":31999}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":802,"col":16,"offset":31963},"end":{"line":802,"col":57,"offset":32004}},{"file":".github\\workflows\\vscode-extension-ci.yml","start":{"line":811,"col":12,"offset":31963},"end":{"line":815,"col":57,"offset":32274}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\after-edit.yaml","start":{"line":30,"col":127,"offset":1175},"end":{"line":30,"col":139,"offset":1187}},{"path":"flow\\workflows\\after-edit.yaml","start":{"line":32,"col":24,"offset":1175},"end":{"line":32,"col":36,"offset":1187}}]],"message":"Syntax error at line flow\\workflows\\after-edit.yaml:30:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `{ item.title` was unexpected","path":"flow\\workflows\\after-edit.yaml","spans":[{"file":"flow\\workflows\\after-edit.yaml","start":{"line":30,"col":127,"offset":1175},"end":{"line":30,"col":139,"offset":1187}},{"file":"flow\\workflows\\after-edit.yaml","start":{"line":32,"col":24,"offset":1175},"end":{"line":32,"col":36,"offset":1187}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\after-edit.yaml","start":{"line":38,"col":16,"offset":1869},"end":{"line":42,"col":88,"offset":2458}}]],"message":"Syntax error at line flow\\workflows\\after-edit.yaml:38:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`UN Using Gemini-optimized researcher for large-context analysis...\"\n# Route to Gemini-optimized researcher for comprehensive analysis\nclaude Task --subagent_type researcher-gemini --description \"Large context impact analysis\" --prompt \"Conduct comprehensive impact analysis for: ${{ item.scope }}. Use Gemini CLI with full codebase context to identify hotspots, callers, configs, crosscuts, testFocus, and citations. Output impact.json format.\"\n# Fallback to direct Gemini if researcher unavailable\nclaude /gemini:impact \"${{ item.scope }}\" || echo \"Fallback to direct Gemini analysis\"\n` was unexpected","path":"flow\\workflows\\after-edit.yaml","spans":[{"file":"flow\\workflows\\after-edit.yaml","start":{"line":38,"col":16,"offset":1869},"end":{"line":42,"col":88,"offset":2458}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\after-edit.yaml","start":{"line":53,"col":16,"offset":2778},"end":{"line":77,"col":4,"offset":3748}}]],"message":"Syntax error at line flow\\workflows\\after-edit.yaml:53:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`PXQyP Running enhanced QA with unified memory coordination...\"\n\n# Initialize unified memory bridge\nsource scripts/memory_bridge.sh\ninitialize_memory_router\n\n# Cache optimization with unified memory integration\nclaude /conn:cache --optimize --memory-update\n\n# Retrieve historical QA patterns from unified memory\nhistorical_qa=$(scripts/memory_bridge.sh retrieve \"intelligence/patterns\" \"qa_success\" 2>/dev/null || echo '{}')\n\n# Comprehensive QA with architectural context and historical intelligence\nclaude /qa:run \\\n  --architecture \\\n  --performance-monitor \\\n  --sequential-thinking \\\n  --memory-update \\\n  --enhanced-artifacts \\\n  --historical-context \"$historical_qa\"\n\n# Store QA results in unified memory for cross-agent sharing\nif [[ -f .claude/.artifacts/qa_enhanced.json ]]; then\n  scripts/memory_bridge.sh store \"analysis/qa\" \"after_edit_$(date +%s)\" \"$(cat .claude/.artifacts/qa_enhanced.json)\" \"{\\\"session\\\": \\\"$SESSION_ID\\\", \\\"type\\\": \\\"after_edit\\\"}\"\nfi\n` was unexpected","path":"flow\\workflows\\after-edit.yaml","spans":[{"file":"flow\\workflows\\after-edit.yaml","start":{"line":53,"col":16,"offset":2778},"end":{"line":77,"col":4,"offset":3748}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\after-edit.yaml","start":{"line":84,"col":16,"offset":4082},"end":{"line":102,"col":19,"offset":4458}}]],"message":"Syntax error at line flow\\workflows\\after-edit.yaml:84:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`P\\QyP Running architectural impact analysis...\"\n\n# Architecture-aware analysis\nclaude /conn:arch \\\n  --hotspots \\\n  --detector-pool \\\n  --cross-component \\\n  --recommendations \\\n  --sequential-thinking \\\n  --memory-update\n\n# Performance monitoring\nclaude /conn:monitor \\\n  --memory \\\n  --resources \\\n  --benchmark \\\n  --trends \\\n  --sequential-thinking \\\n  --memory-update\n` was unexpected","path":"flow\\workflows\\after-edit.yaml","spans":[{"file":"flow\\workflows\\after-edit.yaml","start":{"line":84,"col":16,"offset":4082},"end":{"line":102,"col":19,"offset":4458}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\after-edit.yaml","start":{"line":156,"col":9,"offset":5779},"end":{"line":158,"col":94,"offset":5973}}]],"message":"Syntax error at line flow\\workflows\\after-edit.yaml:156:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `PXQyP Architectural Analysis Results:\"\nif [[ -f .claude/.artifacts/architecture_impact.json ]]; then\n  jq -r '.smart_recommendations[] | \"- \\(.priority | ascii_upcase): \\(.issue) -> \\(.solution)` was unexpected","path":"flow\\workflows\\after-edit.yaml","spans":[{"file":"flow\\workflows\\after-edit.yaml","start":{"line":156,"col":9,"offset":5779},"end":{"line":158,"col":94,"offset":5973}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":14,"col":16,"offset":613},"end":{"line":79,"col":22,"offset":2516}}]],"message":"Syntax error at line flow\\workflows\\pre-mortem-loop.yaml:14:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`ha Initializing pre-mortem swarm with fresh-eyes coordination...\"\n\n# Initialize unified memory bridge for cross-agent coordination\nsource scripts/memory_bridge.sh\ninitialize_memory_router\n\n# Initialize Claude Flow swarm for multi-agent coordination\nnpx claude-flow@alpha swarm init \\\n  --topology mesh \\\n  --max-agents 4 \\\n  --namespace \"$HIVE_NAMESPACE\" \\\n  --fresh-eyes-mode \\\n  2>/dev/null || true\n\n# Spawn coordinated agents with specific memory constraints\nnpx claude-flow@alpha agent spawn \\\n  --type \"claude-orchestrator\" \\\n  --session \"$SESSION_ID\" \\\n  --memory-enabled \\\n  --role \"coordinator\" 2>/dev/null || true\n  \nnpx claude-flow@alpha agent spawn \\\n  --type \"gemini-architect\" \\\n  --session \"$SESSION_ID\" \\\n  --memory-disabled \\\n  --fresh-context \\\n  --role \"architectural_analysis\" 2>/dev/null || true\n  \nnpx claude-flow@alpha agent spawn \\\n  --type \"codex-implementer\" \\\n  --session \"$SESSION_ID\" \\\n  --memory-disabled \\\n  --fresh-context \\\n  --role \"implementation_analysis\" 2>/dev/null || true\n  \nnpx claude-flow@alpha agent spawn \\\n  --type \"research-intelligence\" \\\n  --session \"$SESSION_ID\" \\\n  --research-enabled \\\n  --role \"pattern_discovery\" 2>/dev/null || true\n\n# Store initialization context\ninit_context=$(jq -n \\\n  --arg session \"$SESSION_ID\" \\\n  --arg namespace \"$HIVE_NAMESPACE\" \\\n  --arg target_rate \"$TARGET_FAILURE_RATE\" \\\n  --arg max_iter \"$MAX_ITERATIONS\" \\\n  --arg diversity \"$AGENT_DIVERSITY\" \\\n  '{\n    session_id: $session,\n    hive_namespace: $namespace,\n    target_failure_rate: ($target_rate | tonumber),\n    max_iterations: ($max_iter | tonumber),\n    agent_diversity: ($diversity == \"true\"),\n    swarm_topology: \"mesh\",\n    fresh_eyes_mode: true,\n    agents_spawned: 4\n  }')\n\nscripts/memory_bridge.sh store \\\n  \"coordination/premortem\" \\\n  \"init_$SESSION_ID\" \\\n  \"$init_context\" \\\n  '{\"type\": \"swarm_init\", \"phase\": \"initialization\"}'\n\necho \"$init_context\"\n` was unexpected","path":"flow\\workflows\\pre-mortem-loop.yaml","spans":[{"file":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":14,"col":16,"offset":613},"end":{"line":79,"col":22,"offset":2516}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":86,"col":16,"offset":3132},"end":{"line":117,"col":46,"offset":4231}}]],"message":"Syntax error at line flow\\workflows\\pre-mortem-loop.yaml:86:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`UN Researching common failure patterns for project type...\"\n\n# Extract project type from SPEC.md for targeted research\nPROJECT_TYPE=$(grep -i \"project\\|system\\|application\" SPEC.md | head -1 | sed 's/[^a-zA-Z ]//g' | xargs || echo \"software project\")\n\n# Research agent discovers domain-specific failure patterns\nclaude /research:web \\\n  \"$PROJECT_TYPE common failures lessons learned post-mortem\" \\\n  comprehensive \\\n  technical\n\nclaude /research:deep \\\n  \"$PROJECT_TYPE implementation anti-patterns risk management\" \\\n  comprehensive \\\n  technical\n\n# Store research findings in unified memory for agent access\nif [[ -f .claude/.artifacts/research-web.json ]]; then\n  scripts/memory_bridge.sh store \\\n    \"intelligence/patterns\" \\\n    \"failure_research_$SESSION_ID\" \\\n    \"$(cat .claude/.artifacts/research-web.json)\" \\\n    \"{\\\"type\\\": \\\"failure_patterns\\\", \\\"domain\\\": \\\"$PROJECT_TYPE\\\"}\"\nfi\n\n# Synthesize research findings\nclaude /research:analyze \\\n  \"$(cat .claude/.artifacts/research-*.json 2>/dev/null || echo '{}')\" \\\n  synthesis \\\n  guidance\n\necho \"Research completed for: $PROJECT_TYPE\"\n` was unexpected","path":"flow\\workflows\\pre-mortem-loop.yaml","spans":[{"file":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":86,"col":16,"offset":3132},"end":{"line":117,"col":46,"offset":4231}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":150,"col":6,"offset":4652},"end":{"line":196,"col":39,"offset":6438}}]],"message":"Syntax error at line flow\\workflows\\pre-mortem-loop.yaml:150:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`UN Gemini CLI: Fresh architectural analysis...\"\n# Gemini gets documents with NO research context for fresh perspective\nexport GEMINI_MEMORY_DISABLED=true\ngemini-cli /pre-mortem:analyze \\\n  --role architect \\\n  --memory-disabled \\\n  --fresh-eyes \\\n  --documents \"$SPEC_CONTENT|$PLAN_CONTENT\" \\\n  2>/dev/null || echo '{\"analysis\": \"Gemini CLI unavailable\", \"failure_probability\": 15}' > .claude/.artifacts/gemini_analysis.json\n\necho \"D[b Codex CLI: Fresh implementation analysis...\"  \n# Codex gets documents with NO research context for fresh perspective\nexport CODEX_MEMORY_DISABLED=true\ncodex-cli /pre-mortem:analyze \\\n  --role implementer \\\n  --memory-disabled \\\n  --fresh-eyes \\\n  --documents \"$SPEC_CONTENT|$PLAN_CONTENT\" \\\n  2>/dev/null || echo '{\"analysis\": \"Codex CLI unavailable\", \"failure_probability\": 12}' > .claude/.artifacts/codex_analysis.json\n\n# Store individual analyses in separate namespaces\nif [[ -f .claude/.artifacts/claude_premortem.json ]]; then\n  scripts/memory_bridge.sh store \\\n    \"analysis/claude\" \\\n    \"premortem_$SESSION_ID\" \\\n    \"$(cat .claude/.artifacts/claude_premortem.json)\" \\\n    '{\"agent\": \"claude\", \"memory_enabled\": true, \"iteration\": 1}'\nfi\n\nif [[ -f .claude/.artifacts/gemini_analysis.json ]]; then\n  scripts/memory_bridge.sh store \\\n    \"analysis/gemini\" \\\n    \"premortem_$SESSION_ID\" \\\n    \"$(cat .claude/.artifacts/gemini_analysis.json)\" \\\n    '{\"agent\": \"gemini\", \"fresh_eyes\": true, \"iteration\": 1}'\nfi\n\nif [[ -f .claude/.artifacts/codex_analysis.json ]]; then\n  scripts/memory_bridge.sh store \\\n    \"analysis/codex\" \\\n    \"premortem_$SESSION_ID\" \\\n    \"$(cat .claude/.artifacts/codex_analysis.json)\" \\\n    '{\"agent\": \"codex\", \"fresh_eyes\": true, \"iteration\": 1}'\nfi\n\n# Calculate initial consensus\nbash scripts/calculate_consensus.sh 1\n` was unexpected","path":"flow\\workflows\\pre-mortem-loop.yaml","spans":[{"file":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":150,"col":6,"offset":4652},"end":{"line":196,"col":39,"offset":6438}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":364,"col":20,"offset":15489},"end":{"line":364,"col":42,"offset":15511}}]],"message":"Syntax error at line flow\\workflows\\pre-mortem-loop.yaml:364:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `A Project is ready for` was unexpected","path":"flow\\workflows\\pre-mortem-loop.yaml","spans":[{"file":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":364,"col":20,"offset":15489},"end":{"line":364,"col":42,"offset":15511}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":392,"col":9,"offset":16326},"end":{"line":396,"col":83,"offset":16541}},{"path":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":424,"col":6,"offset":16326},"end":{"line":424,"col":65,"offset":16385}}]],"message":"Syntax error at line flow\\workflows\\pre-mortem-loop.yaml:392:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `UN Key remaining risks:\"\n\n# Extract top risks that couldn't be mitigated\nif [[ -f .claude/.artifacts/pre_mortem_report.json ]]; then\n  jq -r '.remaining_risks[]? | \"  - \\(.risk): \\(.probability)% (\\(.impact) impact)` was unexpected","path":"flow\\workflows\\pre-mortem-loop.yaml","spans":[{"file":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":392,"col":9,"offset":16326},"end":{"line":396,"col":83,"offset":16541}},{"file":"flow\\workflows\\pre-mortem-loop.yaml","start":{"line":424,"col":6,"offset":16326},"end":{"line":424,"col":65,"offset":16385}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\theater-detection.yaml","start":{"line":13,"col":16,"offset":541},"end":{"line":43,"col":27,"offset":1650}}]],"message":"Syntax error at line flow\\workflows\\theater-detection.yaml:13:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`On Initializing theater detection environment...\"\n\n# Ensure artifacts directory exists\nmkdir -p .claude/.artifacts/theater_detection\n\n# Initialize memory bridge for pattern coordination\nsource scripts/memory_bridge.sh\ninitialize_memory_router\n\n# Load historical theater patterns\nhistorical_patterns=$(scripts/memory_bridge.sh retrieve \"intelligence/theater_patterns\" \"detection_history\" 2>/dev/null || echo '{\"patterns\": [], \"confidence_scores\": {}}')\n\n# Initialize detection context\ndetection_context=$(jq -n \\\n  --arg session \"$SESSION_ID\" \\\n  --arg scope \"$DETECTION_SCOPE\" \\\n  --arg evidence_level \"$EVIDENCE_LEVEL\" \\\n  --argjson historical \"$historical_patterns\" \\\n  '{\n    session_id: $session,\n    detection_scope: $scope,\n    evidence_level: $evidence_level,\n    historical_patterns: $historical,\n    detection_timestamp: now | strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n    theater_detection_initialized: true\n  }')\n\n# Store initialization context\nscripts/memory_bridge.sh store \"coordination/theater_detection\" \"init_$SESSION_ID\" \"$detection_context\" '{\"type\": \"detection_init\"}'\n\necho \"$detection_context\"\n` was unexpected","path":"flow\\workflows\\theater-detection.yaml","spans":[{"file":"flow\\workflows\\theater-detection.yaml","start":{"line":13,"col":16,"offset":541},"end":{"line":43,"col":27,"offset":1650}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\theater-detection.yaml","start":{"line":50,"col":16,"offset":2055},"end":{"line":95,"col":44,"offset":3733}}]],"message":"Syntax error at line flow\\workflows\\theater-detection.yaml:50:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`TK Gathering quality context for theater detection...\"\n\n# Run quality gates to establish baseline\nquality_results=\"{}\"\n\n# Gather QA results if available\nif [[ -f .claude/.artifacts/qa.json ]]; then\n  qa_data=$(cat .claude/.artifacts/qa.json)\nelse\n  echo \"Running QA to establish quality baseline...\"\n  claude /qa:run --architecture --performance-monitor > /dev/null 2>&1 || true\n  qa_data=$(cat .claude/.artifacts/qa.json 2>/dev/null || echo '{}')\nfi\n\n# Gather connascence results if available\nif [[ -f .claude/.artifacts/connascence_full.json ]]; then\n  conn_data=$(cat .claude/.artifacts/connascence_full.json)\nelse\n  echo \"Running connascence analysis for architectural context...\"\n  claude /conn:scan --architecture --detector-pools > /dev/null 2>&1 || true\n  conn_data=$(cat .claude/.artifacts/connascence_full.json 2>/dev/null || echo '{}')\nfi\n\n# Gather security results if available\nif [[ -f .claude/.artifacts/semgrep.sarif ]]; then\n  sec_data=$(cat .claude/.artifacts/semgrep.sarif 2>/dev/null || echo '{}')\nelse\n  echo \"Running security scan for security theater detection...\"\n  claude /sec:scan --comprehensive > /dev/null 2>&1 || true\n  sec_data=$(cat .claude/.artifacts/semgrep.sarif 2>/dev/null || echo '{}')\nfi\n\n# Compile quality context\nquality_context=$(jq -n \\\n  --argjson qa \"$qa_data\" \\\n  --argjson connascence \"$conn_data\" \\\n  --argjson security \"$sec_data\" \\\n  '{\n    qa_results: $qa,\n    connascence_results: $connascence,\n    security_results: $security,\n    context_gathered_at: now | strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n  }')\n\necho \"$quality_context\" > .claude/.artifacts/theater_detection/quality_context.json\necho \"Quality context gathered and stored\"\n` was unexpected","path":"flow\\workflows\\theater-detection.yaml","spans":[{"file":"flow\\workflows\\theater-detection.yaml","start":{"line":50,"col":16,"offset":2055},"end":{"line":95,"col":44,"offset":3733}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\theater-detection.yaml","start":{"line":132,"col":20,"offset":5864},"end":{"line":132,"col":52,"offset":5896}}]],"message":"Syntax error at line flow\\workflows\\theater-detection.yaml:132:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `A Deploying theater-killer agent` was unexpected","path":"flow\\workflows\\theater-detection.yaml","spans":[{"file":"flow\\workflows\\theater-detection.yaml","start":{"line":132,"col":20,"offset":5864},"end":{"line":132,"col":52,"offset":5896}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\theater-detection.yaml","start":{"line":216,"col":16,"offset":9562},"end":{"line":262,"col":30,"offset":12227}}]],"message":"Syntax error at line flow\\workflows\\theater-detection.yaml:216:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`TK Consolidating theater detection results...\"\n\n# Load all detection results\ntheater_scan=$(cat .claude/.artifacts/theater_detection/theater_scan_results.json 2>/dev/null || echo '{}')\nreality_check=$(cat .claude/.artifacts/theater_detection/reality_check_results.json 2>/dev/null || echo '{}')\ntheater_killer=$(cat .claude/.artifacts/theater_detection/theater_killer_results.json 2>/dev/null || echo '{}')\ncompletion_audit=$(cat .claude/.artifacts/theater_detection/completion_audit_results.json 2>/dev/null || echo '{}')\n\n# Calculate consolidated metrics\ntheater_patterns_detected=$(echo \"$theater_scan\" | jq -r '.theater_summary.total_patterns_detected // 0')\nreality_score=$(echo \"$reality_check\" | jq -r '.overall_reality_assessment.reality_score // 0')\ncritical_blockers=$(echo \"$reality_check\" | jq -r '.overall_reality_assessment.critical_blockers // [] | length')\n\n# Generate consolidated report\nconsolidated_results=$(jq -n \\\n  --argjson theater_scan \"$theater_scan\" \\\n  --argjson reality_check \"$reality_check\" \\\n  --argjson theater_killer \"$theater_killer\" \\\n  --argjson completion_audit \"$completion_audit\" \\\n  --arg theater_count \"$theater_patterns_detected\" \\\n  --arg reality_score \"$reality_score\" \\\n  --arg critical_blockers \"$critical_blockers\" \\\n  '{\n    consolidation_timestamp: now | strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n    session_id: \"'$SESSION_ID'\",\n    detection_results: {\n      theater_scan: $theater_scan,\n      reality_check: $reality_check,\n      theater_killer: $theater_killer,\n      completion_audit: $completion_audit\n    },\n    summary_metrics: {\n      theater_patterns_detected: ($theater_count | tonumber),\n      reality_score: ($reality_score | tonumber),\n      critical_blockers: ($critical_blockers | tonumber),\n      overall_health: (if ($theater_count | tonumber) == 0 and ($reality_score | tonumber) > 0.8 and ($critical_blockers | tonumber) == 0 then \"excellent\" elif ($theater_count | to... (truncated 750 more characters)","path":"flow\\workflows\\theater-detection.yaml","spans":[{"file":"flow\\workflows\\theater-detection.yaml","start":{"line":216,"col":16,"offset":9562},"end":{"line":262,"col":30,"offset":12227}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\theater-detection.yaml","start":{"line":326,"col":16,"offset":15427},"end":{"line":372,"col":22,"offset":17595}}]],"message":"Syntax error at line flow\\workflows\\theater-detection.yaml:326:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`T^ Generating comprehensive theater detection report...\"\n\n# Load all results\nconsolidated=$(cat .claude/.artifacts/theater_detection/consolidated_results.json 2>/dev/null || echo '{}')\nremediation=$(cat .claude/.artifacts/theater_detection/remediation_summary.json 2>/dev/null || echo '{}')\n\n# Generate final report\nfinal_report=$(jq -n \\\n  --argjson consolidated \"$consolidated\" \\\n  --argjson remediation \"$remediation\" \\\n  --arg session \"$SESSION_ID\" \\\n  '{\n    theater_detection_report: {\n      session_id: $session,\n      detection_timestamp: now | strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n      scope: \"'$DETECTION_SCOPE'\",\n      evidence_level: \"'$EVIDENCE_LEVEL'\",\n      consolidated_results: $consolidated,\n      remediation_summary: $remediation,\n      final_status: (if $consolidated.summary_metrics.theater_patterns_detected == 0 then \"theater_free\" elif $remediation.remediation_success == true then \"theater_eliminated\" else \"theater_detected_pending_remediation\" end),\n      next_actions: (if $consolidated.summary_metrics.theater_patterns_detected == 0 then [\"Proceed with development - no theater detected\"] elif $remediation.remediation_success == true then [\"Theater eliminated - safe to proceed\"] else [\"Manual intervention required for remaining theater patterns\"] end)\n    }\n  }')\n\n# Store final report in memory\nscripts/memory_bridge.sh store \"intelligence/reports\" \"theater_detection_$(date +%s)\" \"$final_report\" '{\"type\": \"theater_detection_report\", \"session\": \"'$SESSION_ID'\"}'\n\necho \"$final_report\" > .claude/.artifacts/theater_detection_final_report.json\n\n# Display summary\ntheater_status=$(echo \"$final_report\" | jq -r '.theater_detection_report.final_status')\ncase \"$theater_status\" in\n  \"theater_free\")\n    echo \"D]F Theater Detection Result: CLEAN - No theater patterns detected\"\n    ;;\n  \"theater_eliminated\") \n    echo \"D]F Theater Detection Result: RESOLVED - Theater patterns eliminated\"\n    ;;\n  \"thea... (truncated 253 more characters)","path":"flow\\workflows\\theater-detection.yaml","spans":[{"file":"flow\\workflows\\theater-detection.yaml","start":{"line":326,"col":16,"offset":15427},"end":{"line":372,"col":22,"offset":17595}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"flow\\workflows\\theater-detection.yaml","start":{"line":379,"col":16,"offset":18110},"end":{"line":411,"col":45,"offset":19895}}]],"message":"Syntax error at line flow\\workflows\\theater-detection.yaml:379:\n When parsing a snippet as Bash for metavariable-pattern in rule 'yaml.github-actions.security.curl-eval.curl-eval', `\"R`ha Updating memory patterns and learning from theater detection...\"\n\n# Load final report\nfinal_report=$(cat .claude/.artifacts/theater_detection_final_report.json 2>/dev/null || echo '{}')\n\n# Extract patterns for learning\ntheater_patterns=$(echo \"$final_report\" | jq '.theater_detection_report.consolidated_results.detection_results.theater_scan.theater_findings // []')\nquality_correlations=$(echo \"$final_report\" | jq '.theater_detection_report.consolidated_results.detection_results // {}')\n\n# Update theater pattern library\nif [[ \"$theater_patterns\" != \"[]\" ]]; then\n  scripts/memory_bridge.sh store \"intelligence/theater_patterns\" \"learned_patterns_$(date +%s)\" \"$theater_patterns\" '{\"type\": \"pattern_learning\", \"session\": \"'$SESSION_ID'\"}'\nfi\n\n# Update quality correlation patterns\nscripts/memory_bridge.sh store \"intelligence/quality_correlations\" \"theater_quality_$(date +%s)\" \"$quality_correlations\" '{\"type\": \"quality_correlation_learning\", \"session\": \"'$SESSION_ID'\"}'\n\n# Update detection confidence scores based on results\ndetection_effectiveness=$(jq -n \\\n  --argjson report \"$final_report\" \\\n  '{\n    session_id: \"'$SESSION_ID'\",\n    detection_accuracy: ($report.theater_detection_report.consolidated_results.summary_metrics | if .theater_patterns_detected > 0 then \"patterns_found\" else \"clean_scan\" end),\n    remediation_success: ($report.theater_detection_report.remediation_summary.remediation_success // false),\n    learning_timestamp: now | strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n  }')\n\nscripts/memory_bridge.sh store \"models/theater_detection\" \"effectiveness_$(date +%s)\" \"$detection_effectiveness\" '{\"type\": \"effectiveness_learning\", \"session\": \"'$SESSION_ID'\"}'\n\n# Synchronize memory systems\nscripts/memory_bridge.sh sync\n\necho \"Memory patterns updated successfully\"\n` was unexpected","path":"flow\\workflows\\theater-detection.yaml","spans":[{"file":"flow\\workflows\\theater-detection.yaml","start":{"line":379,"col":16,"offset":18110},"end":{"line":411,"col":45,"offset":19895}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"scripts\\comprehensive_verification_pipeline.sh","start":{"line":518,"col":45,"offset":0},"end":{"line":518,"col":54,"offset":9}}]],"message":"Syntax error at line scripts\\comprehensive_verification_pipeline.sh:518:\n `/ 1000000` was unexpected","path":"scripts\\comprehensive_verification_pipeline.sh","spans":[{"file":"scripts\\comprehensive_verification_pipeline.sh","start":{"line":518,"col":45,"offset":0},"end":{"line":518,"col":54,"offset":9}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"scripts\\lib\\cleanup-commons.sh","start":{"line":11,"col":8,"offset":0},"end":{"line":17,"col":89,"offset":959}}]],"message":"Syntax error at line scripts\\lib\\cleanup-commons.sh:11:\n `(){ p=\"$(canon \"$1\")\" || return 1; [ -n \"$ALLOWED_BASE\" ] && case \"$p\" in \"$ALLOWED_BASE\"/*) return 0;; esac; case \"$p\" in \"$(repo_root)\"/*) return 0;; esac; return 1; }\nconfirm(){ [ \"$FORCE\" = 1 ] && return 0; [ -t 0 ] || die \"Refusing without TTY; use FORCE=1\"; read -r -p \"Proceed with cleanup? [y/N] \" a; case \"$a\" in y|Y|yes|YES) ;; *) die \"Aborted\"; esac; }\nsafe_rm(){ [ $# -gt 0 ] || die \"safe_rm: path required\"; for t in \"$@\"; do is_safe \"$t\" || die \"unsafe path: $t\"; done; confirm; run rm -rf -- \"$@\"; }\nwith_lock(){ l=\"${TMPDIR:-/tmp}/cleanup.$(printf %s \"$1\"|tr '/\\\\' '__').lock\"; shift; if mkdir \"$l\" 2>/dev/null; then trap 'rmdir \"$l\" 2>/dev/null || true' EXIT INT TERM; \"$@\"; else die \"lock held: $l\"; fi; }\nrequire_cmd(){ command -v \"$1\" >/dev/null 2>&1 || die \"Missing command: $1\"; }\ntrap 'st=$?; [ $st -eq 0 ] || warn \"Cleanup step failed ($st)\"' ERR\nexport -f log warn die run repo_root canon is_safe confirm safe_rm with_lock require_cmd` was unexpected","path":"scripts\\lib\\cleanup-commons.sh","spans":[{"file":"scripts\\lib\\cleanup-commons.sh","start":{"line":11,"col":8,"offset":0},"end":{"line":17,"col":89,"offset":959}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"scripts\\quality_measurement_reality_validation.sh","start":{"line":828,"col":52,"offset":0},"end":{"line":828,"col":61,"offset":9}}]],"message":"Syntax error at line scripts\\quality_measurement_reality_validation.sh:828:\n `/ 1000000` was unexpected","path":"scripts\\quality_measurement_reality_validation.sh","spans":[{"file":"scripts\\quality_measurement_reality_validation.sh","start":{"line":828,"col":52,"offset":0},"end":{"line":828,"col":61,"offset":9}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"scripts\\sandbox_janitor.sh","start":{"line":49,"col":92,"offset":0},"end":{"line":49,"col":98,"offset":6}}]],"message":"Syntax error at line scripts\\sandbox_janitor.sh:49:\n `/ 3600` was unexpected","path":"scripts\\sandbox_janitor.sh","spans":[{"file":"scripts\\sandbox_janitor.sh","start":{"line":49,"col":92,"offset":0},"end":{"line":49,"col":98,"offset":6}}]},{"code":3,"level":"warn","type":["PartialParsing",[{"path":"scripts\\update-agent-context.sh","start":{"line":156,"col":61,"offset":0},"end":{"line":158,"col":55,"offset":99}},{"path":"scripts\\update-agent-context.sh","start":{"line":162,"col":54,"offset":0},"end":{"line":163,"col":23,"offset":28}}]],"message":"Syntax error at line scripts\\update-agent-context.sh:156:\n `$)', content, re.DOTALL)\nif changes_section:\n    changes = changes_section.group(1).strip().split('` was unexpected","path":"scripts\\update-agent-context.sh","spans":[{"file":"scripts\\update-agent-context.sh","start":{"line":156,"col":61,"offset":0},"end":{"line":158,"col":55,"offset":99}},{"file":"scripts\\update-agent-context.sh","start":{"line":162,"col":54,"offset":0},"end":{"line":163,"col":23,"offset":28}}]}],"paths":{"scanned":[".claude\\agents\\analysis\\code-analyzer.md",".claude\\agents\\analysis\\code-review\\analyze-code-quality.md",".claude\\agents\\architecture\\system-design\\arch-system-design.md",".claude\\agents\\base-template-generator.md",".claude\\agents\\coder-codex.md",".claude\\agents\\completion-auditor.md",".claude\\agents\\consensus\\byzantine-coordinator.md",".claude\\agents\\consensus\\crdt-synchronizer.md",".claude\\agents\\consensus\\gossip-coordinator.md",".claude\\agents\\consensus\\performance-benchmarker.md",".claude\\agents\\consensus\\quorum-manager.md",".claude\\agents\\consensus\\raft-manager.md",".claude\\agents\\consensus\\README.md",".claude\\agents\\consensus\\security-manager.md",".claude\\agents\\core\\coder.md",".claude\\agents\\core\\planner.md",".claude\\agents\\core\\researcher.md",".claude\\agents\\core\\reviewer.md",".claude\\agents\\core\\tester.md",".claude\\agents\\data\\ml\\data-ml-model.md",".claude\\agents\\development\\backend\\dev-backend-api.md",".claude\\agents\\devops\\ci-cd\\ops-cicd-github.md",".claude\\agents\\documentation\\api-docs\\docs-api-openapi.md",".claude\\agents\\fresh-eyes-codex.md",".claude\\agents\\fresh-eyes-gemini.md",".claude\\agents\\github\\code-review-swarm.md",".claude\\agents\\github\\github-modes.md",".claude\\agents\\github\\issue-tracker.md",".claude\\agents\\github\\multi-repo-swarm.md",".claude\\agents\\github\\pr-manager.md",".claude\\agents\\github\\project-board-sync.md",".claude\\agents\\github\\release-manager.md",".claude\\agents\\github\\release-swarm.md",".claude\\agents\\github\\repo-architect.md",".claude\\agents\\github\\swarm-issue.md",".claude\\agents\\github\\swarm-pr.md",".claude\\agents\\github\\sync-coordinator.md",".claude\\agents\\github\\workflow-automation.md",".claude\\agents\\MIGRATION_SUMMARY.md",".claude\\agents\\optimization\\benchmark-suite.md",".claude\\agents\\optimization\\load-balancer.md",".claude\\agents\\optimization\\performance-monitor.md",".claude\\agents\\optimization\\README.md",".claude\\agents\\optimization\\resource-allocator.md",".claude\\agents\\optimization\\topology-optimizer.md",".claude\\agents\\README.md",".claude\\agents\\reality-checker.md",".claude\\agents\\researcher-gemini.md",".claude\\agents\\sparc\\architecture.md",".claude\\agents\\sparc\\pseudocode.md",".claude\\agents\\sparc\\refinement.md",".claude\\agents\\sparc\\specification.md",".claude\\agents\\specialized\\mobile\\spec-mobile-react-native.md",".claude\\agents\\swarm\\adaptive-coordinator.md",".claude\\agents\\swarm\\hierarchical-coordinator.md",".claude\\agents\\swarm\\mesh-coordinator.md",".claude\\agents\\swarm\\README.md",".claude\\agents\\templates\\automation-smart-agent.md",".claude\\agents\\templates\\coordinator-swarm-init.md",".claude\\agents\\templates\\github-pr-manager.md",".claude\\agents\\templates\\implementer-sparc-coder.md",".claude\\agents\\templates\\memory-coordinator.md",".claude\\agents\\templates\\migration-plan.md",".claude\\agents\\templates\\orchestrator-task.md",".claude\\agents\\templates\\performance-analyzer.md",".claude\\agents\\templates\\sparc-coordinator.md",".claude\\agents\\testing\\unit\\tdd-london-swarm.md",".claude\\agents\\testing\\validation\\production-validator.md",".claude\\agents\\theater-killer.md",".claude\\commands\\audit-swarm.md",".claude\\commands\\cleanup-post-completion.md",".claude\\commands\\codex",".claude\\commands\\codex-micro-fix.md",".claude\\commands\\codex-micro.md",".claude\\commands\\conn",".claude\\commands\\conn-arch.md",".claude\\commands\\conn-cache.md",".claude\\commands\\conn-monitor.md",".claude\\commands\\conn-scan.md",".claude\\commands\\fix",".claude\\commands\\fix-planned.md",".claude\\commands\\gemini",".claude\\commands\\gemini-impact.md",".claude\\commands\\memory-unified.md",".claude\\commands\\plan.md",".claude\\commands\\pm",".claude\\commands\\pm-sync.md",".claude\\commands\\pr",".claude\\commands\\pr-open.md",".claude\\commands\\pre-mortem-loop.md",".claude\\commands\\qa",".claude\\commands\\qa-analyze.md",".claude\\commands\\qa-gate.md",".claude\\commands\\qa-run.md",".claude\\commands\\reality-check.md",".claude\\commands\\research-analyze.md",".claude\\commands\\research-deep.md",".claude\\commands\\research-github.md",".claude\\commands\\research-models.md",".claude\\commands\\research-web.md",".claude\\commands\\sec",".claude\\commands\\sec-scan.md",".claude\\commands\\spec",".claude\\commands\\spec-plan.md",".claude\\commands\\specify.md",".claude\\commands\\tasks.md",".claude\\commands\\theater-scan.md",".claude\\memory_config.json",".claude\\settings.json",".claude\\settings.local.json",".claude\\templates\\mcp-footer.md",".claude\\templates\\spek-augment-header.md",".claude-flow\\metrics\\agent-metrics.json",".claude-flow\\metrics\\performance.json",".claude-flow\\metrics\\task-metrics.json",".env.example",".eslintrc.cjs",".github\\actions-test\\simulate_actions.sh",".github\\CODEOWNERS",".github\\quality-gates.py",".github\\scripts\\__pycache__\\sast_analysis.cpython-312.pyc",".github\\scripts\\__pycache__\\secrets_analysis.cpython-312.pyc",".github\\scripts\\__pycache__\\security_consolidation.cpython-312.pyc",".github\\scripts\\__pycache__\\security_gate_decision.cpython-312.pyc",".github\\scripts\\__pycache__\\supply_chain_analysis.cpython-312.pyc",".github\\scripts\\architecture_analysis.py",".github\\scripts\\comprehensive_analysis.py",".github\\scripts\\consolidate_analysis_results.py",".github\\scripts\\health_assessment.py",".github\\scripts\\mece_analysis.py",".github\\scripts\\performance_optimization.py",".github\\scripts\\quality_gate_decision.py",".github\\scripts\\quality_gates.py",".github\\scripts\\run_architecture_analysis.py",".github\\scripts\\run_cache_optimization.py",".github\\scripts\\run_connascence_analysis.py",".github\\scripts\\run_dogfooding_analysis.py",".github\\scripts\\run_mece_analysis.py",".github\\scripts\\run_performance_monitoring.py",".github\\scripts\\sarif_generation.py",".github\\scripts\\sast_analysis.py",".github\\scripts\\secrets_analysis.py",".github\\scripts\\security_consolidation.py",".github\\scripts\\security_gate_decision.py",".github\\scripts\\supply_chain_analysis.py",".github\\setup-branch-protection.md",".github\\validate-analyzer-pipeline.py",".github\\workflows\\architecture-analysis.yml",".github\\workflows\\auto-repair.yml",".github\\workflows\\cache-optimization.yml",".github\\workflows\\codeql-analysis.yml",".github\\workflows\\config\\performance-optimization.yml",".github\\workflows\\config\\security-hardening.yml",".github\\workflows\\connascence-analysis.yml",".github\\workflows\\connascence-core-analysis.yml",".github\\workflows\\enhanced-quality-gates.yml",".github\\workflows\\mece-duplication-analysis.yml",".github\\workflows\\monitoring-dashboard.yml",".github\\workflows\\nasa-compliance-check.yml",".github\\workflows\\performance-monitoring.yml",".github\\workflows\\quality-gate-enforcer.yml",".github\\workflows\\quality-gates.yml",".github\\workflows\\quality-orchestrator-parallel.yml",".github\\workflows\\quality-orchestrator.yml",".github\\workflows\\rollback-automation.yml",".github\\workflows\\security-pipeline.yml",".github\\workflows\\self-dogfooding.yml",".github\\workflows\\setup-branch-protection.yml",".github\\workflows\\validate-artifacts.yml",".github\\workflows\\vscode-extension-ci.yml",".gitignore",".hive-mind\\config.json",".hive-mind\\hive.db",".sandboxes\\.gitkeep",".swarm\\memory.db","AGENTS.md","analyzer\\.pkg-info\\dependency_links.txt","analyzer\\.pkg-info\\entry_points.txt","analyzer\\.pkg-info\\PKG-INFO","analyzer\\.pkg-info\\requires.txt","analyzer\\.pkg-info\\SOURCES.txt","analyzer\\.pkg-info\\top_level.txt","analyzer\\__init__.py","analyzer\\__main__.py","analyzer\\__pycache__\\__init__.cpython-311.pyc","analyzer\\__pycache__\\__init__.cpython-312.pyc","analyzer\\__pycache__\\__main__.cpython-312.pyc","analyzer\\__pycache__\\analysis_orchestrator.cpython-312.pyc","analyzer\\__pycache__\\cache_manager.cpython-311.pyc","analyzer\\__pycache__\\cache_manager.cpython-312.pyc","analyzer\\__pycache__\\check_connascence.cpython-311.pyc","analyzer\\__pycache__\\check_connascence.cpython-312.pyc","analyzer\\__pycache__\\check_connascence_minimal.cpython-312.pyc","analyzer\\__pycache__\\configuration_manager.cpython-311.pyc","analyzer\\__pycache__\\configuration_manager.cpython-312.pyc","analyzer\\__pycache__\\connascence_analyzer.cpython-312.pyc","analyzer\\__pycache__\\constants.cpython-311.pyc","analyzer\\__pycache__\\constants.cpython-312.pyc","analyzer\\__pycache__\\context_analyzer.cpython-311.pyc","analyzer\\__pycache__\\context_analyzer.cpython-312.pyc","analyzer\\__pycache__\\core.cpython-311.pyc","analyzer\\__pycache__\\core.cpython-312.pyc","analyzer\\__pycache__\\duplication_helper.cpython-311.pyc","analyzer\\__pycache__\\duplication_helper.cpython-312.pyc","analyzer\\__pycache__\\duplication_unified.cpython-311.pyc","analyzer\\__pycache__\\duplication_unified.cpython-312.pyc","analyzer\\__pycache__\\formal_grammar.cpython-311.pyc","analyzer\\__pycache__\\formal_grammar.cpython-312.pyc","analyzer\\__pycache__\\language_strategies.cpython-312.pyc","analyzer\\__pycache__\\policy_engine.cpython-312.pyc","analyzer\\__pycache__\\quality_calculator.cpython-312.pyc","analyzer\\__pycache__\\refactored_detector.cpython-311.pyc","analyzer\\__pycache__\\refactored_detector.cpython-312.pyc","analyzer\\__pycache__\\result_aggregator.cpython-312.pyc","analyzer\\__pycache__\\smart_integration_engine.cpython-311.pyc","analyzer\\__pycache__\\smart_integration_engine.cpython-312.pyc","analyzer\\__pycache__\\thresholds.cpython-311.pyc","analyzer\\__pycache__\\thresholds.cpython-312.pyc","analyzer\\__pycache__\\unified_analyzer.cpython-311.pyc","analyzer\\__pycache__\\unified_analyzer.cpython-312.pyc","analyzer\\analysis_orchestrator.py","analyzer\\analysis_output.txt","analyzer\\architecture\\__init__.py","analyzer\\architecture\\__pycache__\\__init__.cpython-311.pyc","analyzer\\architecture\\__pycache__\\__init__.cpython-312.pyc","analyzer\\architecture\\__pycache__\\aggregator.cpython-311.pyc","analyzer\\architecture\\__pycache__\\aggregator.cpython-312.pyc","analyzer\\architecture\\__pycache__\\configuration_manager.cpython-311.pyc","analyzer\\architecture\\__pycache__\\configuration_manager.cpython-312.pyc","analyzer\\architecture\\__pycache__\\detector_pool.cpython-311.pyc","analyzer\\architecture\\__pycache__\\detector_pool.cpython-312.pyc","analyzer\\architecture\\__pycache__\\enhanced_metrics.cpython-311.pyc","analyzer\\architecture\\__pycache__\\enhanced_metrics.cpython-312.pyc","analyzer\\architecture\\__pycache__\\orchestrator.cpython-311.pyc","analyzer\\architecture\\__pycache__\\orchestrator.cpython-312.pyc","analyzer\\architecture\\__pycache__\\recommendation_engine.cpython-311.pyc","analyzer\\architecture\\__pycache__\\recommendation_engine.cpython-312.pyc","analyzer\\architecture\\aggregator.py","analyzer\\architecture\\detector_pool.py","analyzer\\architecture\\enhanced_metrics.py","analyzer\\architecture\\orchestrator.py","analyzer\\architecture\\recommendation_engine.py","analyzer\\ast_engine\\__init__.py","analyzer\\ast_engine\\__main__.py","analyzer\\ast_engine\\__pycache__\\__init__.cpython-311.pyc","analyzer\\ast_engine\\__pycache__\\__init__.cpython-312.pyc","analyzer\\ast_engine\\__pycache__\\__main__.cpython-312.pyc","analyzer\\ast_engine\\__pycache__\\analyzer_orchestrator.cpython-311.pyc","analyzer\\ast_engine\\__pycache__\\analyzer_orchestrator.cpython-312.pyc","analyzer\\ast_engine\\__pycache__\\core_analyzer.cpython-311.pyc","analyzer\\ast_engine\\__pycache__\\core_analyzer.cpython-312.pyc","analyzer\\ast_engine\\analyzer_orchestrator.py","analyzer\\ast_engine\\core_analyzer.py","analyzer\\cache_manager.py","analyzer\\caching\\__pycache__\\ast_cache.cpython-312.pyc","analyzer\\caching\\ast_cache.py","analyzer\\config\\analysis_config.yaml","analyzer\\config\\detector_config.yaml","analyzer\\configuration_manager.py","analyzer\\connascence_analyzer.py","analyzer\\constants.py","analyzer\\context_analyzer.py","analyzer\\core\\__init__.py","analyzer\\core\\__pycache__\\__init__.cpython-312.pyc","analyzer\\core\\__pycache__\\unified_imports.cpython-312.pyc","analyzer\\core\\unified_imports.py","analyzer\\core.py","analyzer\\dashboard\\__init__.py","analyzer\\dashboard\\ci_integration.py","analyzer\\dashboard\\metrics.py","analyzer\\detectors\\__init__.py","analyzer\\detectors\\__pycache__\\__init__.cpython-311.pyc","analyzer\\detectors\\__pycache__\\__init__.cpython-312.pyc","analyzer\\detectors\\__pycache__\\algorithm_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\algorithm_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\base.cpython-311.pyc","analyzer\\detectors\\__pycache__\\base.cpython-312.pyc","analyzer\\detectors\\__pycache__\\connascence_ast_analyzer.cpython-312.pyc","analyzer\\detectors\\__pycache__\\convention_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\convention_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\execution_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\execution_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\god_object_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\god_object_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\magic_literal_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\magic_literal_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\position_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\position_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\timing_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\timing_detector.cpython-312.pyc","analyzer\\detectors\\__pycache__\\values_detector.cpython-311.pyc","analyzer\\detectors\\__pycache__\\values_detector.cpython-312.pyc","analyzer\\detectors\\algorithm_detector.py","analyzer\\detectors\\base.py","analyzer\\detectors\\connascence_ast_analyzer.py","analyzer\\detectors\\convention_detector.py","analyzer\\detectors\\execution_detector.py","analyzer\\detectors\\god_object_detector.py","analyzer\\detectors\\magic_literal_detector.py","analyzer\\detectors\\position_detector.py","analyzer\\detectors\\timing_detector.py","analyzer\\detectors\\values_detector.py","analyzer\\dup_detection\\__init__.py","analyzer\\dup_detection\\__main__.py","analyzer\\dup_detection\\__pycache__\\__init__.cpython-311.pyc","analyzer\\dup_detection\\__pycache__\\__init__.cpython-312.pyc","analyzer\\dup_detection\\__pycache__\\__main__.cpython-312.pyc","analyzer\\dup_detection\\__pycache__\\mece_analyzer.cpython-311.pyc","analyzer\\dup_detection\\__pycache__\\mece_analyzer.cpython-312.pyc","analyzer\\dup_detection\\mece_analyzer.py","analyzer\\duplication_unified.py","analyzer\\formal_grammar.py","analyzer\\integrations\\__init__.py","analyzer\\integrations\\tool_coordinator.py","analyzer\\interfaces\\__pycache__\\detector_interface.cpython-312.pyc","analyzer\\interfaces\\detector_interface.py","analyzer\\language_strategies.py","analyzer\\mece\\__init__.py","analyzer\\mece\\__pycache__\\__init__.cpython-312.pyc","analyzer\\mece\\__pycache__\\mece_analyzer.cpython-312.pyc","analyzer\\mece\\mece_analyzer.py","analyzer\\nasa_engine\\__init__.py","analyzer\\nasa_engine\\__pycache__\\__init__.cpython-311.pyc","analyzer\\nasa_engine\\__pycache__\\__init__.cpython-312.pyc","analyzer\\nasa_engine\\__pycache__\\nasa_analyzer.cpython-311.pyc","analyzer\\nasa_engine\\__pycache__\\nasa_analyzer.cpython-312.pyc","analyzer\\nasa_engine\\nasa_analyzer.py","analyzer\\optimization\\__init__.py","analyzer\\optimization\\__pycache__\\__init__.cpython-311.pyc","analyzer\\optimization\\__pycache__\\__init__.cpython-312.pyc","analyzer\\optimization\\__pycache__\\ast_optimizer.cpython-311.pyc","analyzer\\optimization\\__pycache__\\ast_optimizer.cpython-312.pyc","analyzer\\optimization\\__pycache__\\file_cache.cpython-311.pyc","analyzer\\optimization\\__pycache__\\file_cache.cpython-312.pyc","analyzer\\optimization\\__pycache__\\incremental_analyzer.cpython-312.pyc","analyzer\\optimization\\__pycache__\\memory_monitor.cpython-311.pyc","analyzer\\optimization\\__pycache__\\memory_monitor.cpython-312.pyc","analyzer\\optimization\\__pycache__\\performance_benchmark.cpython-311.pyc","analyzer\\optimization\\__pycache__\\performance_benchmark.cpython-312.pyc","analyzer\\optimization\\__pycache__\\resource_manager.cpython-311.pyc","analyzer\\optimization\\__pycache__\\resource_manager.cpython-312.pyc","analyzer\\optimization\\__pycache__\\streaming_performance_monitor.cpython-311.pyc","analyzer\\optimization\\__pycache__\\streaming_performance_monitor.cpython-312.pyc","analyzer\\optimization\\__pycache__\\unified_visitor.cpython-311.pyc","analyzer\\optimization\\__pycache__\\unified_visitor.cpython-312.pyc","analyzer\\optimization\\ast_optimizer.py","analyzer\\optimization\\file_cache.py","analyzer\\optimization\\incremental_analyzer.py","analyzer\\optimization\\memory_monitor.py","analyzer\\optimization\\performance_benchmark.py","analyzer\\optimization\\README.md","analyzer\\optimization\\resource_manager.py","analyzer\\optimization\\streaming_performance_monitor.py","analyzer\\optimization\\unified_visitor.py","analyzer\\performance\\__init__.py","analyzer\\performance\\__pycache__\\__init__.cpython-312.pyc","analyzer\\performance\\__pycache__\\parallel_analyzer.cpython-312.pyc","analyzer\\performance\\parallel_analyzer.py","analyzer\\policy_engine.py","analyzer\\quality_calculator.py","analyzer\\refactored_detector.py","analyzer\\reporting\\__init__.py","analyzer\\reporting\\__pycache__\\__init__.cpython-311.pyc","analyzer\\reporting\\__pycache__\\__init__.cpython-312.pyc","analyzer\\reporting\\__pycache__\\coordinator.cpython-311.pyc","analyzer\\reporting\\__pycache__\\coordinator.cpython-312.pyc","analyzer\\reporting\\__pycache__\\json.cpython-311.pyc","analyzer\\reporting\\__pycache__\\json.cpython-312.pyc","analyzer\\reporting\\__pycache__\\markdown.cpython-311.pyc","analyzer\\reporting\\__pycache__\\markdown.cpython-312.pyc","analyzer\\reporting\\__pycache__\\sarif.cpython-311.pyc","analyzer\\reporting\\__pycache__\\sarif.cpython-312.pyc","analyzer\\reporting\\coordinator.py","analyzer\\reporting\\json.py","analyzer\\reporting\\markdown.py","analyzer\\reporting\\sarif.py","analyzer\\result_aggregator.py","analyzer\\smart_integration_engine.py","analyzer\\streaming\\__init__.py","analyzer\\streaming\\__pycache__\\__init__.cpython-311.pyc","analyzer\\streaming\\__pycache__\\__init__.cpython-312.pyc","analyzer\\streaming\\__pycache__\\dashboard_reporter.cpython-311.pyc","analyzer\\streaming\\__pycache__\\dashboard_reporter.cpython-312.pyc","analyzer\\streaming\\__pycache__\\incremental_cache.cpython-311.pyc","analyzer\\streaming\\__pycache__\\incremental_cache.cpython-312.pyc","analyzer\\streaming\\__pycache__\\result_aggregator.cpython-311.pyc","analyzer\\streaming\\__pycache__\\result_aggregator.cpython-312.pyc","analyzer\\streaming\\__pycache__\\stream_processor.cpython-311.pyc","analyzer\\streaming\\__pycache__\\stream_processor.cpython-312.pyc","analyzer\\streaming\\dashboard_reporter.py","analyzer\\streaming\\incremental_cache.py","analyzer\\streaming\\result_aggregator.py","analyzer\\streaming\\stream_processor.py","analyzer\\test_results\\self_analysis_comprehensive.json","analyzer\\test_results\\self_analysis_nasa.json","analyzer\\test_results\\self_god_objects.json","analyzer\\test_results\\self_mece_analysis.json","analyzer\\test_results\\test_analysis.json","analyzer\\test_results\\test_nasa.json","analyzer\\test_results\\test_sarif.json","analyzer\\thresholds.py","analyzer\\unified_analyzer.py","analyzer\\utils\\__init__.py","analyzer\\utils\\__pycache__\\__init__.cpython-311.pyc","analyzer\\utils\\__pycache__\\__init__.cpython-312.pyc","analyzer\\utils\\__pycache__\\code_utils.cpython-311.pyc","analyzer\\utils\\__pycache__\\code_utils.cpython-312.pyc","analyzer\\utils\\__pycache__\\common_patterns.cpython-312.pyc","analyzer\\utils\\__pycache__\\config_manager.cpython-312.pyc","analyzer\\utils\\__pycache__\\connascence_validator.cpython-312.pyc","analyzer\\utils\\__pycache__\\error_handling.cpython-312.pyc","analyzer\\utils\\__pycache__\\types.cpython-311.pyc","analyzer\\utils\\__pycache__\\types.cpython-312.pyc","analyzer\\utils\\code_utils.py","analyzer\\utils\\common_patterns.py","analyzer\\utils\\config_manager.py","analyzer\\utils\\connascence_validator.py","analyzer\\utils\\error_handling.py","analyzer\\utils\\injection\\__pycache__\\container.cpython-312.pyc","analyzer\\utils\\injection\\container.py","analyzer\\utils\\types.py","bandit_results.json","CLAUDE.md","configs\\.semgrep.yml","configs\\codex.json","configs\\plane.json","docs\\AGENT-WIRING-OPTIMIZATION.md","docs\\ANALYSIS-RESULT-FORMAT.md","docs\\ANALYZER-CAPABILITIES.md","docs\\ANALYZER-CONSOLIDATION-PLAN.md","docs\\ARCHITECTURAL-ANALYSIS.md","docs\\audit-findings.md","docs\\CLI-INTEGRATION-GAPS.md","docs\\CONNASCENCE-VIOLATION-PATTERNS-RESEARCH.md","docs\\ENHANCED-CICD-INTEGRATION-SPECIFICATIONS.md","docs\\FINAL-PRODUCTION-ASSESSMENT.md","docs\\GOD-OBJECT-DECOMPOSITION-RESEARCH.md","docs\\history\\PHASE-2-IMPLEMENTATION-SUMMARY.md","docs\\history\\PHASE-3-IMPLEMENTATION-SUMMARY.md","docs\\IMPLEMENTATION-SPECIFICATIONS.md","docs\\MCP-AUTO-INITIALIZATION-GUIDE.md","docs\\MCP-ENHANCED-DEBUGGING-SYSTEM.md","docs\\MCP-INTELLIGENT-DEBUGGING-SYSTEM.md","docs\\MECE-CONSOLIDATION-PLAN.md","docs\\MECE-README-ANALYSIS.md","docs\\NASA-POT10-CODE-REVIEW-CHECKLIST.md","docs\\NASA-POT10-COMPLIANCE-STRATEGIES.md","docs\\PHASE-2-VALIDATION-REPORT.md","docs\\PHASE3-PERFORMANCE-OPTIMIZATION-STRATEGY.md","docs\\process\\GUARDRAILS.md","docs\\PRODUCTION-VALIDATION-REPORT.md","docs\\PROJECT-STRUCTURE.md","docs\\QUICK-REFERENCE-MCP-DEBUGGING.md","docs\\reference\\COMMANDS.md","docs\\reference\\QUICK-REFERENCE.md","docs\\S-R-P-E-K-METHODOLOGY.md","docs\\SECURITY-INTEGRATION-ANALYSIS.md","docs\\spc.csv","docs\\SYSTEM-ARCHITECTURE-ANALYSIS.md","docs\\THEATER-DETECTION-AUDIT-REPORT.md","docs\\UNIFIED-INTEGRATION-STRATEGY.md","docs\\UNIFIED-MEMORY-ARCHITECTURE.md","examples\\getting-started.md","examples\\README.md","examples\\sample-specs\\auth-system.md","examples\\troubleshooting.md","examples\\workflows\\spec-to-pr.md","flow\\agents\\coder.md","flow\\agents\\planner.md","flow\\agents\\refinement.md","flow\\agents\\research-agent.md","flow\\agents\\researcher.md","flow\\agents\\reviewer.md","flow\\agents\\tester.md","flow\\workflows\\after-edit.yaml","flow\\workflows\\ci-auto-repair.yaml","flow\\workflows\\pre-mortem-loop.yaml","flow\\workflows\\spec-to-pr.yaml","flow\\workflows\\swarm-audit-cycle.yaml","flow\\workflows\\theater-detection.yaml","interfaces\\cli\\__init__.py","interfaces\\cli\\__pycache__\\__init__.cpython-311.pyc","interfaces\\cli\\__pycache__\\__init__.cpython-312.pyc","interfaces\\cli\\__pycache__\\config_discovery.cpython-311.pyc","interfaces\\cli\\__pycache__\\config_discovery.cpython-312.pyc","interfaces\\cli\\__pycache__\\connascence.cpython-311.pyc","interfaces\\cli\\__pycache__\\connascence.cpython-312.pyc","interfaces\\cli\\__pycache__\\main_python.cpython-312.pyc","interfaces\\cli\\__pycache__\\policy_detection.cpython-311.pyc","interfaces\\cli\\__pycache__\\policy_detection.cpython-312.pyc","interfaces\\cli\\__pycache__\\simple_cli.cpython-311.pyc","interfaces\\cli\\__pycache__\\simple_cli.cpython-312.pyc","interfaces\\cli\\config_discovery.py","interfaces\\cli\\connascence.py","interfaces\\cli\\main_python.py","interfaces\\cli\\package.json","interfaces\\cli\\policy_detection.py","interfaces\\cli\\README.md","interfaces\\cli\\simple_cli.py","interfaces\\cli\\src\\mcp\\server.ts","interfaces\\core\\__init__.py","interfaces\\core\\__pycache__\\__init__.cpython-311.pyc","interfaces\\core\\__pycache__\\__init__.cpython-312.pyc","interfaces\\core\\__pycache__\\interface_base.cpython-311.pyc","interfaces\\core\\__pycache__\\interface_base.cpython-312.pyc","interfaces\\core\\__pycache__\\shared_components.cpython-311.pyc","interfaces\\core\\__pycache__\\shared_components.cpython-312.pyc","interfaces\\core\\interface_base.py","interfaces\\core\\shared_components.py","jest.config.js","LICENSE","memory\\constitution.md","memory\\constitution_update_checklist.md","memory\\memory-store.json","package-lock.json","package.json","pip_audit_results.json","policy\\__init__.py","policy\\__pycache__\\__init__.cpython-312.pyc","policy\\__pycache__\\baselines.cpython-312.pyc","policy\\__pycache__\\budgets.cpython-312.pyc","policy\\__pycache__\\manager.cpython-312.pyc","policy\\baselines.py","policy\\budgets.py","policy\\manager.py","QUALITY.md","README-EXTENDED.md","README-MCP-SETUP.md","README.md","requirements.txt","scripts\\analyzer_improvement_loop.sh","scripts\\apply_improvements.sh","scripts\\audit_swarm.sh","scripts\\batch_update_agents.sh","scripts\\calculate_consensus.sh","scripts\\check-task-prerequisites.sh","scripts\\cleanup-commons.sh","scripts\\codex_apply.sh","scripts\\common.sh","scripts\\compare_baselines.py","scripts\\compare_self_analysis.py","scripts\\comprehensive_verification_pipeline.sh","scripts\\contextual_loop.sh","scripts\\create-new-feature.sh","scripts\\diff_coverage.js","scripts\\diff_coverage.py","scripts\\e2e_validation_suite.py","scripts\\gate_fail_reason.sh","scripts\\generate-handoff-docs.sh","scripts\\get-feature-paths.sh","scripts\\github_workflow_test.py","scripts\\impact_quickcheck.sh","scripts\\intelligent_failure_analysis.sh","scripts\\iterative_improvement_loop.sh","scripts\\lib\\cleanup-commons.sh","scripts\\lint_agents.sh","scripts\\mcp-auto-init-enhanced.ps1","scripts\\mcp-auto-init-enhanced.sh","scripts\\mcp-auto-init.ps1","scripts\\mcp-auto-init.sh","scripts\\memory_bridge.sh","scripts\\ops_tripwires.sh","scripts\\performance-monitor.sh","scripts\\performance_regression_detector.py","scripts\\phase2_validation.py","scripts\\phase3_deployment_validator.py","scripts\\post-completion-cleanup.sh","scripts\\premortem_convergence.sh","scripts\\production-fixes.sh","scripts\\quality_loop_github.sh","scripts\\quality_measurement_reality_validation.sh","scripts\\reality_validator.sh","scripts\\remove_unicode.py","scripts\\reproduce_enterprise_demo.py","scripts\\run_complete_quality_loop.sh","scripts\\run_qa.sh","scripts\\sandbox_janitor.sh","scripts\\security_compliance_auditor.py","scripts\\self_correct.sh","scripts\\setup-plan.sh","scripts\\simple_quality_loop.sh","scripts\\smoke_test_agents.js","scripts\\state-recovery.sh","scripts\\surgical_fix_system.sh","scripts\\synthesize_improvements.sh","scripts\\temp-commons.sh","scripts\\update-agent-context.sh","scripts\\update_agents_spek_augment.sh","scripts\\update_readme_metrics.py","scripts\\update_remaining_agents.sh","scripts\\validate-completion.sh","scripts\\validate-mcp-environment.sh","scripts\\validate_github_fixes.py","scripts\\verify-fixes.sh","scripts\\verify_counts.py","scripts\\windows-compat.sh","scripts\\windows_quality_loop.ps1","semgrep_results.json","setup.py","SPEC.md","src\\analyzers\\nasa\\__pycache__\\bounded_ast_walker.cpython-312.pyc","src\\analyzers\\nasa\\__pycache__\\defensive_programming_specialist.cpython-312.pyc","src\\analyzers\\nasa\\__pycache__\\function_decomposer.cpython-312.pyc","src\\analyzers\\nasa\\__pycache__\\nasa_compliance_auditor.cpython-312.pyc","src\\analyzers\\nasa\\__pycache__\\security_manager.cpython-312.pyc","src\\analyzers\\nasa\\bounded_ast_walker.py","src\\analyzers\\nasa\\defensive_programming_specialist.py","src\\analyzers\\nasa\\function_decomposer.py","src\\analyzers\\nasa\\nasa_compliance_auditor.py","src\\analyzers\\nasa\\security_manager.py","src\\index.ts","src\\theater-detection\\__init__.py","src\\theater-detection\\__pycache__\\__init__.cpython-312.pyc","src\\theater-detection\\__pycache__\\theater-detector.cpython-312.pyc","src\\theater-detection\\continuous-monitor.py","src\\theater-detection\\deploy_loop3.py","src\\theater-detection\\reality-validator.py","src\\theater-detection\\theater-detector.py","templates\\agent-file-template.md","templates\\MAINTENANCE.md.template","templates\\plan-template.md","templates\\spec-template.md","templates\\tasks-template.md","test_architecture_workflow.py","test_errors.py","test_security_pipeline.py","test_security_workflow.py","test_workflows_comprehensive.py","test_yaml_syntax.py","test_yaml_validator.py","tsconfig.json"]},"time":{"rules":[],"rules_parse_time":1.5117995738983154,"profiling_times":{"config_time":1.8417644500732422,"core_time":34.70455265045166,"ignores_time":0.0009973049163818359,"total_time":36.54831075668335},"parsing_time":{"total_time":0.0,"per_file_time":{"mean":0.0,"std_dev":0.0},"very_slow_stats":{"time_ratio":0.0,"count_ratio":0.0},"very_slow_files":[]},"scanning_time":{"total_time":28.60500454902649,"per_file_time":{"mean":0.01875738003214855,"std_dev":0.009136844203792321},"very_slow_stats":{"time_ratio":0.09581905728867068,"count_ratio":0.0006557377049180328},"very_slow_files":[{"fpath":"analyzer\\unified_analyzer.py","ftime":2.7409045696258545}]},"matching_time":{"total_time":0.0,"per_file_and_rule_time":{"mean":0.0,"std_dev":0.0},"very_slow_stats":{"time_ratio":0.0,"count_ratio":0.0},"very_slow_rules_on_files":[]},"tainting_time":{"total_time":0.0,"per_def_and_rule_time":{"mean":0.0,"std_dev":0.0},"very_slow_stats":{"time_ratio":0.0,"count_ratio":0.0},"very_slow_rules_on_defs":[]},"fixpoint_timeouts":[{"error_type":"Fixpoint timeout","severity":"warn","message":"Fixpoint timeout while performing taint analysis at .github\\scripts\\consolidate_analysis_results.py:12:4 [rules: 1, first: python.boto3.security.hardcoded-token.hardcoded-token]","location":{"path":".github\\scripts\\consolidate_analysis_results.py","start":{"line":12,"col":5,"offset":256},"end":{"line":12,"col":33,"offset":284}}},{"error_type":"Fixpoint timeout","severity":"warn","message":"Fixpoint timeout while performing taint analysis at .github\\scripts\\security_consolidation.py:12:4 [rules: 1, first: python.boto3.security.hardcoded-token.hardcoded-token]","location":{"path":".github\\scripts\\security_consolidation.py","start":{"line":12,"col":5,"offset":195},"end":{"line":12,"col":9,"offset":199}}},{"error_type":"Fixpoint timeout","severity":"warn","message":"Fixpoint timeout while performing taint analysis at scripts\\security_compliance_auditor.py:274:8 [rules: 1, first: python.boto3.security.hardcoded-token.hardcoded-token]","location":{"path":"scripts\\security_compliance_auditor.py","start":{"line":274,"col":9,"offset":12818},"end":{"line":274,"col":32,"offset":12841}}},{"error_type":"Fixpoint timeout","severity":"warn","message":"Fixpoint timeout while performing taint analysis at test_security_workflow.py:13:4 [rules: 1, first: python.boto3.security.hardcoded-token.hardcoded-token]","location":{"path":"test_security_workflow.py","start":{"line":13,"col":5,"offset":231},"end":{"line":13,"col":27,"offset":253}}},{"error_type":"Fixpoint timeout","severity":"warn","message":"Fixpoint timeout while performing taint analysis at test_yaml_syntax.py:11:4 [rules: 1, first: python.boto3.security.hardcoded-token.hardcoded-token]","location":{"path":"test_yaml_syntax.py","start":{"line":11,"col":5,"offset":204},"end":{"line":11,"col":21,"offset":220}}}],"prefiltering":{"project_level_time":0.0,"file_level_time":0.0,"rules_with_project_prefilters_ratio":0.0,"rules_with_file_prefilters_ratio":0.9794937658739321,"rules_selected_ratio":0.1620006926806742,"rules_matched_ratio":0.1620006926806742},"targets":[],"total_bytes":0,"max_memory_bytes":1138369280},"engine_requested":"OSS","skipped_rules":[]}