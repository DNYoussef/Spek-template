"""
Extracted operations service from cross_phase_learning_integration

Automatically generated by God Object Decomposer
"""

from typing import Dict, List, Optional, Any
import json
from dataclasses import dataclass
import logging
import sys
import asyncio
import os


"""Initialize pattern classifier."""
    def __init__(self):
        """Initialize pattern classifier."""
        self.pattern_templates = {
            "optimization": {
                "keywords": ["performance", "efficiency", "speed", "memory", "cache", "threading"],
                "metrics": ["improvement_percentage", "execution_time", "memory_usage"],
                "confidence_threshold": 0.7
            },
            "architecture": {
                "keywords": ["design", "structure", "component", "module", "interface"],
                "metrics": ["maintainability", "coupling", "cohesion"],
                "confidence_threshold": 0.8
            },
            "quality": {
                "keywords": ["testing", "validation", "compliance", "safety", "reliability"],
                "metrics": ["test_coverage", "defect_rate", "compliance_score"],
                "confidence_threshold": 0.75
            },
            "performance": {
                "keywords": ["benchmark", "profiling", "bottleneck", "optimization"],
                "metrics": ["throughput", "latency", "resource_utilization"],
                "confidence_threshold": 0.8
            }
        }

        # Pattern recognition statistics
        self.classification_stats = {
            "patterns_classified": 0,
            "accuracy_rate": 0.0,
            "classification_history": deque(maxlen=1000)
        }

"""Classify a correlation into a learning pattern."""
    def classify_pattern(self,
                        correlation: MemoryCorrelation,
                        performance_data: Optional[List[PerformanceCorrelation]] = None) -> LearningPattern:
        """Classify a correlation into a learning pattern."""
        pattern_type = self._determine_pattern_type(correlation, performance_data)
        confidence_score = self._calculate_confidence_score(correlation, performance_data, pattern_type)
        success_rate = self._estimate_success_rate(correlation, performance_data, pattern_type)

        pattern = LearningPattern(
            pattern_id=self._generate_pattern_id(correlation),
            pattern_type=pattern_type,
            source_phases=[correlation.source_phase],
            target_phases=[correlation.target_phase],
            pattern_data=self._extract_pattern_data(correlation, performance_data),
            success_rate=success_rate,
            confidence_score=confidence_score
        )

        # Update classification statistics
        self.classification_stats["patterns_classified"] += 1
        self.classification_stats["classification_history"].append({
            "pattern_type": pattern_type,
            "confidence": confidence_score,
            "timestamp": time.time()
        })

        return pattern

"""Determine the type of pattern based on correlation and performance data."""
    def _determine_pattern_type(self,
                               correlation: MemoryCorrelation,
                               performance_data: Optional[List[PerformanceCorrelation]]) -> str:
        """Determine the type of pattern based on correlation and performance data."""
        # Start with correlation type as base
        if correlation.correlation_type in self.pattern_templates:
            base_type = correlation.correlation_type
        else:
            base_type = "optimization"  # Default

        # Analyze metadata for pattern type indicators
        metadata_text = json.dumps(correlation.metadata).lower()
        type_scores = {}

        for pattern_type, template in self.pattern_templates.items():
            score = 0.0
            for keyword in template["keywords"]:
                if keyword in metadata_text:
                    score += 1.0

            # Normalize score by number of keywords
            type_scores[pattern_type] = score / len(template["keywords"])

        # Consider performance data if available
        if performance_data:
            for perf_corr in performance_data:
                metric_name = perf_corr.metric_name.lower()
                for pattern_type, template in self.pattern_templates.items():
                    for template_metric in template["metrics"]:
                        if template_metric in metric_name:
                            type_scores[pattern_type] = type_scores.get(pattern_type, 0) + 0.5

        # Return type with highest score, fallback to base type
        if type_scores:
            best_type = max(type_scores.items(), key=lambda x: x[1])
            if best_type[1] > 0:
                return best_type[0]

        return base_type

"""Calculate confidence score for the classified pattern."""
    def _calculate_confidence_score(self,
                                  correlation: MemoryCorrelation,
                                  performance_data: Optional[List[PerformanceCorrelation]],
                                  pattern_type: str) -> float:
        """Calculate confidence score for the classified pattern."""
        base_confidence = correlation.correlation_strength

        # Adjust confidence based on pattern type threshold
        template = self.pattern_templates.get(pattern_type, {})
        threshold = template.get("confidence_threshold", 0.75)

        if base_confidence < threshold:
            base_confidence *= 0.8  # Reduce confidence for below-threshold patterns

        # Boost confidence with performance data
        if performance_data:
            validated_data = [p for p in performance_data if p.validation_status == "validated"]
            if validated_data:
                avg_improvement = statistics.mean([p.improvement_percentage for p in validated_data])
                if avg_improvement > 20:  # Significant improvement
                    base_confidence = min(1.0, base_confidence + 0.1)

        # Consider metadata richness
        metadata_richness = len(correlation.metadata) / 10.0  # Normalize to 0-1
        metadata_richness = min(1.0, metadata_richness)

        # Final confidence is weighted combination
        final_confidence = (base_confidence * 0.7 + metadata_richness * 0.3)
        return max(0.0, min(1.0, final_confidence))

"""Estimate success rate for the pattern."""
    def _estimate_success_rate(self,
                              correlation: MemoryCorrelation,
                              performance_data: Optional[List[PerformanceCorrelation]],
                              pattern_type: str) -> float:
        """Estimate success rate for the pattern."""
        # Base success rate on correlation strength
        base_rate = correlation.correlation_strength

        # Adjust based on performance validation
        if performance_data:
            validated_count = len([p for p in performance_data if p.validation_status == "validated"])
            total_count = len(performance_data)

            if total_count > 0:
                validation_rate = validated_count / total_count
                base_rate = (base_rate + validation_rate) / 2.0

        # Pattern type adjustments
        type_multipliers = {
            "optimization": 0.9,  # High success rate for optimizations
            "performance": 0.95,  # Very high for performance patterns
            "architecture": 0.8,  # Moderate for architecture patterns
            "quality": 0.85  # Good for quality patterns
        }

        multiplier = type_multipliers.get(pattern_type, 0.8)
        return max(0.0, min(1.0, base_rate * multiplier))

"""Generate unique pattern ID."""
    def _generate_pattern_id(self, correlation: MemoryCorrelation) -> str:
        """Generate unique pattern ID."""
        pattern_string = f"{correlation.source_phase}_{correlation.target_phase}_{correlation.correlation_type}_{correlation.timestamp}"
        return hashlib.md5(pattern_string.encode(), usedforsecurity=False).hexdigest()[:16]

"""Extract structured pattern data."""
    def _extract_pattern_data(self,
                             correlation: MemoryCorrelation,
                             performance_data: Optional[List[PerformanceCorrelation]]) -> Dict[str, Any]:
        """Extract structured pattern data."""
        pattern_data = {
            "source_phase": correlation.source_phase,
            "target_phase": correlation.target_phase,
            "correlation_type": correlation.correlation_type,
            "correlation_strength": correlation.correlation_strength,
            "metadata": correlation.metadata.copy(),
            "performance_improvements": []
        }

        if performance_data:
            for perf_corr in performance_data:
                pattern_data["performance_improvements"].append({
                    "metric_name": perf_corr.metric_name,
                    "improvement_percentage": perf_corr.improvement_percentage,
                    "validation_status": perf_corr.validation_status,
                    "correlation_factors": perf_corr.correlation_factors
                })

        return pattern_data

"""Initialize recommendation engine."""
    def __init__(self):
        """Initialize recommendation engine."""
        self.recommendation_templates = {
            "performance_optimization": {
                "priority_factors": ["improvement_potential", "implementation_effort", "risk_level"],
                "effort_estimation": {
                    "cache_optimization": "medium",
                    "algorithm_improvement": "high",
                    "threading_optimization": "high",
                    "memory_optimization": "medium",
                    "io_optimization": "low"
                }
            },
            "architecture_improvement": {
                "priority_factors": ["maintainability_impact", "future_flexibility", "technical_debt"],
                "effort_estimation": {
                    "component_refactoring": "high",
                    "interface_improvement": "medium",
                    "design_pattern_application": "medium",
                    "dependency_optimization": "low"
                }
            }
        }

        self.recommendation_history: List[OptimizationRecommendation] = []
        self.effectiveness_tracking: Dict[str, LearningEffectiveness] = {}

"""Generate optimization recommendations for a target phase."""
    def generate_recommendations(self,
                                target_phase: str,
                                learned_patterns: List[LearningPattern],
                                current_metrics: Optional[Dict[str, float]] = None) -> List[OptimizationRecommendation]:
        """Generate optimization recommendations for a target phase."""
        recommendations = []

        # Filter patterns applicable to target phase
        applicable_patterns = [
            p for p in learned_patterns
            if target_phase in p.target_phases or not p.target_phases
        ]

        # Sort by confidence and success rate
        applicable_patterns.sort(key=lambda p: (p.confidence_score * p.success_rate), reverse=True)

        for pattern in applicable_patterns[:10]:  # Top 10 patterns
            recommendation = self._create_recommendation_from_pattern(pattern, target_phase, current_metrics)
            if recommendation:
                recommendations.append(recommendation)

        # Sort recommendations by priority and confidence
        recommendations.sort(key=lambda r: (r.priority == "high", r.confidence), reverse=True)

        return recommendations

"""Create recommendation from a learned pattern."""
    def _create_recommendation_from_pattern(self,
                                          pattern: LearningPattern,
                                          target_phase: str,
                                          current_metrics: Optional[Dict[str, float]]) -> Optional[OptimizationRecommendation]:
        """Create recommendation from a learned pattern."""
        try:
            # Determine recommendation type and priority
            rec_type = self._map_pattern_to_recommendation_type(pattern)
            priority = self._calculate_priority(pattern, current_metrics)

            # Estimate expected improvement
            expected_improvement = self._estimate_improvement(pattern, current_metrics)

            # Determine implementation effort
            effort = self._estimate_implementation_effort(pattern)

            # Extract implementation steps
            impl_steps = self._generate_implementation_steps(pattern)

            # Identify risks and prerequisites
            risks = self._identify_risks(pattern)
            prerequisites = self._extract_prerequisites(pattern)

            # Create validation criteria
            validation_criteria = self._generate_validation_criteria(pattern)

            recommendation = OptimizationRecommendation(
                recommendation_id=f"rec_{pattern.pattern_id}_{target_phase}",
                target_phase=target_phase,
                recommendation_type=rec_type,
                priority=priority,
                confidence=pattern.confidence_score,
                expected_improvement=expected_improvement,
                implementation_effort=effort,
                supporting_patterns=[pattern.pattern_id],
                prerequisites=prerequisites,
                risks=risks,
                implementation_steps=impl_steps,
                validation_criteria=validation_criteria
            )

            return recommendation

        except Exception as e:
            logger.error(f"Failed to create recommendation from pattern {pattern.pattern_id}: {e}")
            return None

"""Map pattern type to recommendation type."""
    def _map_pattern_to_recommendation_type(self, pattern: LearningPattern) -> str:
        """Map pattern type to recommendation type."""
        mapping = {
            "optimization": "performance_optimization",
            "performance": "performance_optimization",
            "architecture": "architecture_improvement",
            "quality": "quality_enhancement"
        }
        return mapping.get(pattern.pattern_type, "general_improvement")

"""Calculate priority level for the recommendation."""
    def _calculate_priority(self, pattern: LearningPattern, current_metrics: Optional[Dict[str, float]]) -> str:
        """Calculate priority level for the recommendation."""
        # Base priority on pattern effectiveness
        base_score = pattern.confidence_score * pattern.success_rate

        # Adjust based on performance improvements in pattern data
        perf_improvements = pattern.pattern_data.get("performance_improvements", [])
        if perf_improvements:
            avg_improvement = statistics.mean([
                p.get("improvement_percentage", 0) for p in perf_improvements
                if p.get("validation_status") == "validated"
            ])

            if avg_improvement > 50:
                base_score += 0.2
            elif avg_improvement > 20:
                base_score += 0.1

        # Consider usage count (proven patterns)
        if pattern.usage_count > 5:
            base_score += 0.1

        # Priority thresholds
        if base_score > 0.8:
            return "high"
        elif base_score > 0.6:
            return "medium"
        else:
            return "low"

"""Estimate expected improvement percentage."""
    def _estimate_improvement(self, pattern: LearningPattern, current_metrics: Optional[Dict[str, float]]) -> float:
        """Estimate expected improvement percentage."""
        # Extract historical improvements from pattern
        perf_improvements = pattern.pattern_data.get("performance_improvements", [])

        if perf_improvements:
            validated_improvements = [
                p.get("improvement_percentage", 0) for p in perf_improvements
                if p.get("validation_status") == "validated"
            ]

            if validated_improvements:
                # Use conservative estimate (75th percentile)
                return statistics.quantiles(validated_improvements, n=4)[2]  # 75th percentile

        # Fallback estimation based on pattern confidence and success rate
        base_improvement = pattern.confidence_score * pattern.success_rate * 50  # Max 50% improvement

        # Adjust based on pattern type
        type_multipliers = {
            "optimization": 1.2,
            "performance": 1.3,
            "architecture": 0.8,
            "quality": 0.9
        }

        multiplier = type_multipliers.get(pattern.pattern_type, 1.0)
        return base_improvement * multiplier

"""Estimate implementation effort level."""
    def _estimate_implementation_effort(self, pattern: LearningPattern) -> str:
        """Estimate implementation effort level."""
        # Check pattern metadata for effort indicators
        metadata_text = json.dumps(pattern.pattern_data).lower()

        high_effort_indicators = ["refactoring", "architecture", "redesign", "major", "complete"]
        medium_effort_indicators = ["optimization", "improvement", "enhancement", "modification"]
        low_effort_indicators = ["configuration", "tuning", "parameter", "simple", "minor"]

        high_count = sum(1 for indicator in high_effort_indicators if indicator in metadata_text)
        medium_count = sum(1 for indicator in medium_effort_indicators if indicator in metadata_text)
        low_count = sum(1 for indicator in low_effort_indicators if indicator in metadata_text)

        if high_count > medium_count and high_count > low_count:
            return "high"
        elif low_count > medium_count and low_count > high_count:
            return "low"
        else:
            return "medium"

"""Generate implementation steps based on pattern."""
    def _generate_implementation_steps(self, pattern: LearningPattern) -> List[str]:
        """Generate implementation steps based on pattern."""
        steps = []
        pattern_type = pattern.pattern_type

        # Base steps by pattern type
        if pattern_type == "optimization":
            steps = [
                "1. Analyze current performance baseline",
                "2. Identify optimization targets from pattern data",
                "3. Implement optimization techniques",
                "4. Validate performance improvements",
                "5. Monitor for regressions"
            ]
        elif pattern_type == "architecture":
            steps = [
                "1. Review current architecture design",
                "2. Plan architectural improvements based on pattern",
                "3. Implement changes incrementally",
                "4. Update documentation and interfaces",
                "5. Validate system integration"
            ]
        elif pattern_type == "quality":
            steps = [
                "1. Assess current quality metrics",
                "2. Implement quality improvements from pattern",
                "3. Update testing and validation procedures",
                "4. Verify compliance requirements",
                "5. Monitor quality metrics"
            ]
        else:
            steps = [
                "1. Analyze pattern applicability to current phase",
                "2. Plan implementation approach",
                "3. Execute implementation in stages",
                "4. Validate results against expected outcomes",
                "5. Document lessons learned"
            ]

        # Add pattern-specific details
        correlation_factors = []
        perf_improvements = pattern.pattern_data.get("performance_improvements", [])
        for perf in perf_improvements:
            correlation_factors.extend(perf.get("correlation_factors", []))

        if correlation_factors:
            unique_factors = list(set(correlation_factors))
            steps.append(f"6. Focus on key factors: {", '.join(unique_factors[:3])}')

        return steps

"""Identify potential risks in applying the pattern."""
    def _identify_risks(self, pattern: LearningPattern) -> List[str]:
        """Identify potential risks in applying the pattern."""
        risks = []

        # Risks based on confidence level
        if pattern.confidence_score < 0.7:
            risks.append("Low confidence in pattern effectiveness")

        # Risks based on success rate
        if pattern.success_rate < 0.8:
            risks.append("Pattern has shown mixed results in previous applications")

        # Risks based on pattern type
        if pattern.pattern_type == "architecture":
            risks.append("Architectural changes may introduce integration issues")
            risks.append("Significant testing required to validate changes")

        if pattern.pattern_type == "optimization":
            risks.append("Performance optimizations may introduce subtle bugs")
            risks.append("Changes may affect system stability under load")

        # Check for complexity indicators
        metadata_text = json.dumps(pattern.pattern_data).lower()
        if "threading" in metadata_text or "concurrent" in metadata_text:
            risks.append("Concurrency changes require careful thread safety validation")

        if "memory" in metadata_text:
            risks.append("Memory-related changes need thorough leak testing")

        return risks

"""Extract prerequisites for applying the pattern."""
    def _extract_prerequisites(self, pattern: LearningPattern) -> List[str]:
        """Extract prerequisites for applying the pattern."""
        prerequisites = []

        # Add pattern-specific prerequisites
        if pattern.prerequisites:
            prerequisites.extend(pattern.prerequisites)

        # Add inferred prerequisites based on pattern data
        correlation_factors = []
        perf_improvements = pattern.pattern_data.get("performance_improvements", [])
        for perf in perf_improvements:
            correlation_factors.extend(perf.get("correlation_factors", []))

        # Convert factors to prerequisites
        factor_to_prereq = {
            "detector_pool": "Detector pool system must be implemented",
            "unified_visitor": "Unified visitor pattern must be available",
            "thread_safety": "Thread-safe infrastructure must be in place",
            "caching": "Caching system must be operational"
        }

        for factor in set(correlation_factors):
            if factor in factor_to_prereq:
                prerequisites.append(factor_to_prereq[factor])

        return prerequisites

"""Generate validation criteria for the recommendation."""
    def _generate_validation_criteria(self, pattern: LearningPattern) -> List[str]:
        """Generate validation criteria for the recommendation."""
        criteria = []

        # Performance-based criteria
        expected_improvement = self._estimate_improvement(pattern, None)
        if expected_improvement > 0:
            criteria.append(f"Achieve at least {expected_improvement:.1f}% improvement in target metrics")

        # Pattern-specific criteria
        if pattern.pattern_type == "optimization":
            criteria.extend([
                "No performance regressions in unrelated areas",
                "Memory usage remains within acceptable bounds",
                "System stability maintained under load"
            ])

        elif pattern.pattern_type == "quality":
            criteria.extend([
                "Quality metrics improve without compromising functionality",
                "All existing tests continue to pass",
                "New quality measures show positive trends"
            ])

        # General criteria
        criteria.extend([
            "Implementation completed within estimated effort",
            "No critical bugs introduced",
            "Pattern effectiveness validated through measurement"
        ])

        return criteria

"""Track the effectiveness of an applied recommendation."""
    def track_recommendation_effectiveness(self,
                                         recommendation_id: str,
                                         before_metrics: Dict[str, float],
                                         after_metrics: Dict[str, float]) -> LearningEffectiveness:
        """Track the effectiveness of an applied recommendation."""
        recommendation = next(
            (r for r in self.recommendation_history if r.recommendation_id == recommendation_id),
            None
        )

        if not recommendation:
            raise ValueError(f"Recommendation {recommendation_id} not found")

        # Calculate actual improvement
        improvement_achieved = 0.0
        if "performance" in after_metrics and "performance" in before_metrics:
            improvement_achieved = ((after_metrics["performance"] - before_metrics["performance"])
                                  / before_metrics["performance"] * 100)

        # Calculate effectiveness score
        expected_improvement = recommendation.expected_improvement
        if expected_improvement > 0:
            effectiveness_score = min(1.0, improvement_achieved / expected_improvement)
        else:
            effectiveness_score = 1.0 if improvement_achieved > 0 else 0.0

        effectiveness = LearningEffectiveness(
            pattern_id=recommendation.supporting_patterns[0] if recommendation.supporting_patterns else "",
            application_phase=recommendation.target_phase,
            before_metrics=before_metrics,
            after_metrics=after_metrics,
            improvement_achieved=improvement_achieved,
            expected_improvement=expected_improvement,
            effectiveness_score=max(0.0, effectiveness_score),
            application_timestamp=time.time(),
            validation_timestamp=time.time()
        )

        self.effectiveness_tracking[recommendation_id] = effectiveness
        return effectiveness

"""Initialize cross-phase learning integration."""
    def __init__(self, memory_model: Optional[UnifiedMemoryModel] = None):
        """Initialize cross-phase learning integration."""
        self.memory_model = memory_model or (get_global_memory_model() if MEMORY_SYSTEM_AVAILABLE else None)
        self.storage = get_global_storage() if MEMORY_SYSTEM_AVAILABLE else None

        self.pattern_classifier = PatternClassifier()
        self.recommendation_engine = OptimizationRecommendationEngine()

        # Learning state
        self.learned_patterns: Dict[str, LearningPattern] = {}
        self.active_recommendations: Dict[str, List[OptimizationRecommendation]] = defaultdict(list)
        self.learning_lock = threading.RLock()

        # Learning effectiveness tracking
        self.effectiveness_history: List[LearningEffectiveness] = []
        self.learning_metrics = {
            "patterns_learned": 0,
            "recommendations_generated": 0,
            "successful_applications": 0,
            "average_effectiveness": 0.0,
            "learning_confidence": 0.0
        }

        logger.info("Cross-Phase Learning Integration initialized")

"""Get comprehensive learning insights report."""
    def get_learning_insights_report(self) -> Dict[str, Any]:
        """Get comprehensive learning insights report."""
        with self.learning_lock:
            patterns_by_type = defaultdict(list)
            for pattern in self.learned_patterns.values():
                patterns_by_type[pattern.pattern_type].append(pattern)

        report = {
            "summary": self.learning_metrics.copy(),
            "patterns_by_type": {},
            "top_patterns": [],
            "learning_trends": [],
            "effectiveness_analysis": {},
            "recommendations_summary": {}
        }

        # Analyze patterns by type
        for pattern_type, patterns in patterns_by_type.items():
            avg_confidence = statistics.mean([p.confidence_score for p in patterns])
            avg_success_rate = statistics.mean([p.success_rate for p in patterns])
            total_usage = sum(p.usage_count for p in patterns)

            report["patterns_by_type"][pattern_type] = {
                "count": len(patterns),
                "avg_confidence": avg_confidence,
                "avg_success_rate": avg_success_rate,
                "total_usage": total_usage
            }

        # Top patterns by effectiveness
        all_patterns = list(self.learned_patterns.values())
        top_patterns = sorted(
            all_patterns,
            key=lambda p: (p.confidence_score * p.success_rate * (1 + p.usage_count / 10)),
            reverse=True
        )[:10]

        report["top_patterns"] = [
            {
                "pattern_id": p.pattern_id,
                "pattern_type": p.pattern_type,
                "confidence_score": p.confidence_score,
                "success_rate": p.success_rate,
                "usage_count": p.usage_count,
                "source_phases": p.source_phases,
                "target_phases": p.target_phases
            }
            for p in top_patterns
        ]

        # Effectiveness analysis
        if self.effectiveness_history:
            effectiveness_scores = [e.effectiveness_score for e in self.effectiveness_history]
            report["effectiveness_analysis"] = {
                "total_applications": len(self.effectiveness_history),
                "avg_effectiveness": statistics.mean(effectiveness_scores),
                "success_rate": len([s for s in effectiveness_scores if s > 0.7]) / len(effectiveness_scores),
                "effectiveness_trend": effectiveness_scores[-10:]  # Last 10 scores
            }

        # Recommendations summary
        total_recommendations = sum(len(recs) for recs in self.active_recommendations.values())
        high_priority_recs = sum(
            len([r for r in recs if r.priority == "high"])
            for recs in self.active_recommendations.values()
        )

        report["recommendations_summary"] = {
            "total_active_recommendations": total_recommendations,
            "high_priority_count": high_priority_recs,
            "phases_with_recommendations": len(self.active_recommendations)
        }

        return report

"""Identify phases that could benefit from patterns learned in the given phase."""
    def _identify_related_phases(self, phase_id: str) -> List[str]:
        """Identify phases that could benefit from patterns learned in the given phase."""
        # Simple heuristic: next phases in sequence
        phase_sequences = {
            "phase1": ["phase2", "phase3"],
            "phase2": ["phase3", "phase4"],
            "phase3": ["phase4", "phase5"],
            "phase4": ["phase5"],
            "phase5": ["phase1"]  # Circular learning
        }

        return phase_sequences.get(phase_id, [])

"""Update overall learning metrics."""
    def _update_learning_metrics(self) -> None:
        """Update overall learning metrics."""
        if self.effectiveness_history:
            self.learning_metrics["average_effectiveness"] = statistics.mean([
                e.effectiveness_score for e in self.effectiveness_history
            ])

        # Calculate learning confidence based on pattern quality
        if self.learned_patterns:
            pattern_confidences = [p.confidence_score for p in self.learned_patterns.values()]
            self.learning_metrics["learning_confidence"] = statistics.mean(pattern_confidences)

"""Shutdown learning integration system."""
    def shutdown(self) -> None:
        """Shutdown learning integration system."""
        logger.info("Shutting down Cross-Phase Learning Integration...")

        # Save final learning state if needed
        final_metrics = self.learning_metrics.copy()
        logger.info(f"Final learning metrics: {final_metrics}")

        logger.info("Cross-Phase Learning Integration shutdown completed")

"""Get or create global cross-phase learning integration."""
def get_global_learning_integration() -> CrossPhaseLearningIntegration:
    """Get or create global cross-phase learning integration."""
    global _global_learning_integration

    with _learning_lock:
        if _global_learning_integration is None:
            _global_learning_integration = CrossPhaseLearningIntegration()

    return _global_learning_integration

