"""
Extracted operations service from loop_orchestrator

Automatically generated by God Object Decomposer
"""

import time
from dataclasses import dataclass
from typing import Optional
from datetime import datetime
from typing import Dict, List, Optional, Any
from typing import List
from git_safety_manager import GitSafetyManager
import subprocess
from pathlib import Path
from datetime import timedelta
import sys
from typing import Dict
import os
import argparse
import json
from dataclasses import field
from typing import Set
import re
from src.analysis.failure_pattern_detector import FailurePatternDetector
from typing import Any
import threading
from lib.shared.utilities import get_logger
from typing import Tuple
import asyncio


    def __init__(self):
        self.connascence_patterns = self._load_connascence_patterns()
        self.coupling_analyzers = self._initialize_coupling_analyzers()

"""Initialize tools for coupling analysis."""
    def _initialize_coupling_analyzers(self) -> Dict[str, Any]:
        """Initialize tools for coupling analysis."""
        return {
            "ast_analyzer": "python-ast or babel-parser for syntax trees",
            "dependency_tracker": "madge, dependency-cruiser for JS/TS",
            "call_graph_builder": "pycallgraph, or custom implementation",
            "data_flow_analyzer": "custom implementation",
            "import_analyzer": "es6-module-analyzer, importlib for Python"
        }

"""Detect connascence issues across multiple files."""
    def detect_connascence_issues(self, file_paths: List[str]) -> List[ConnascenceIssue]:
        """Detect connascence issues across multiple files."""
        logger.info(f"Analyzing connascence across {len(file_paths)} files...")

        issues = []

        # Analyze each file and its relationships
        for primary_file in file_paths:
            file_issues = self._analyze_file_coupling(primary_file, file_paths)
            issues.extend(file_issues)

        # Group related issues
        grouped_issues = self._group_related_issues(issues)

        logger.info(f"Detected {len(grouped_issues)} connascence issues")
        return grouped_issues

"""Analyze coupling patterns for a specific file."""
    def _analyze_file_coupling(self, primary_file: str, all_files: List[str]) -> List[ConnascenceIssue]:
        """Analyze coupling patterns for a specific file."""
        issues = []

        try:
            with open(primary_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Find imports and dependencies
            dependencies = self._extract_dependencies(content, primary_file)

            # Analyze each type of connascence
            for connascence_type, pattern_info in self.connascence_patterns.items():
                detected_issues = self._detect_specific_connascence(
                    primary_file, content, connascence_type, pattern_info, all_files
                )
                issues.extend(detected_issues)

        except Exception as e:
            logger.warning(f"Error analyzing {primary_file}: {e}")

        return issues

"""Extract dependencies from file content."""
    def _extract_dependencies(self, content: str, file_path: str) -> List[str]:
        """Extract dependencies from file content."""
        dependencies = []

        # JavaScript/TypeScript imports
        import_patterns = [
            r"import .+ from ['\"]([^'\"]+)['\"]",
            r"import ['\"]([^'\"]+)['\"]",
            r"require\(['\"]([^'\"]+)['\"]\)",
            r"from ['\"]([^'\"]+)['\"] import"
        ]

        for pattern in import_patterns:
            matches = re.findall(pattern, content)
            dependencies.extend(matches)

        # Python imports
        python_patterns = [
            r"from ([^\s]+) import",
            r"import ([^\s,]+)"
        ]

        for pattern in python_patterns:
            matches = re.findall(pattern, content)
            dependencies.extend(matches)

        return dependencies

"""Detect a specific type of connascence."""
    def _detect_specific_connascence(self, primary_file: str, content: str,
                                   connascence_type: str, pattern_info: Dict[str, Any],
                                   all_files: List[str]) -> List[ConnascenceIssue]:
        """Detect a specific type of connascence."""
        issues = []

        # Find coupled files based on patterns
        coupled_files = self._find_coupled_files(primary_file, content, pattern_info, all_files)

        if coupled_files:
            # Calculate coupling strength
            coupling_strength = self._calculate_coupling_strength(
                primary_file, coupled_files, connascence_type
            )

            # Extract context information
            context_lines = self._extract_context_lines(primary_file, content, pattern_info)

            issue = ConnascenceIssue(
                issue_type=connascence_type,
                primary_file=primary_file,
                coupled_files=coupled_files,
                severity=pattern_info["severity"],
                coupling_strength=coupling_strength,
                description=pattern_info["description"],
                suggested_refactoring=pattern_info["refactor_techniques"],
                context_lines=context_lines
            )

            issues.append(issue)

        return issues

"""Find files coupled to the primary file."""
    def _find_coupled_files(self, primary_file: str, content: str,
                          pattern_info: Dict[str, Any], all_files: List[str]) -> List[str]:
        """Find files coupled to the primary file."""
        coupled_files = []

        # Extract dependencies and cross-references
        dependencies = self._extract_dependencies(content, primary_file)

        # Find files that match dependency patterns
        for dep in dependencies:
            for file_path in all_files:
                if dep in file_path or Path(file_path).stem == dep:
                    if file_path != primary_file:
                        coupled_files.append(file_path)

        # Find files with similar function/class names (naming coupling)
        if "name" in pattern_info.get("description", "").lower():
            coupled_files.extend(self._find_naming_coupled_files(primary_file, content, all_files))

        return list(set(coupled_files))

"""Find files coupled through naming conventions."""
    def _find_naming_coupled_files(self, primary_file: str, content: str, all_files: List[str]) -> List[str]:
        """Find files coupled through naming conventions."""
        coupled_files = []

        # Extract function and class names from primary file
        function_names = re.findall(r"function ([a-zA-Z_][a-zA-Z0-9_]*)", content)
        class_names = re.findall(r"class ([a-zA-Z_][a-zA-Z0-9_]*)", content)

        # Check other files for similar names
        for file_path in all_files:
            if file_path == primary_file:
                continue

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    other_content = f.read()

                # Check for similar function/class names
                for name in function_names + class_names:
                    if name in other_content:
                        coupled_files.append(file_path)
                        break

            except Exception:
                continue

        return coupled_files

"""Calculate the strength of coupling between files."""
    def _calculate_coupling_strength(self, primary_file: str, coupled_files: List[str],
                                   connascence_type: str) -> float:
        """Calculate the strength of coupling between files."""
        base_strength = {
            "coincidental": 0.2,
            "logical": 0.3,
            "temporal": 0.7,
            "procedural": 0.4,
            "communicational": 0.8,
            "sequential": 0.5,
            "functional": 0.1
        }.get(connascence_type, 0.5)

        # Adjust based on number of coupled files
        file_factor = min(1.0, len(coupled_files) / 5.0)

        # Adjust based on file sizes (larger files = stronger coupling)
        try:
            primary_size = Path(primary_file).stat().st_size
            size_factor = min(1.0, primary_size / 10000)  # Normalize to 10KB
        except:
            size_factor = 0.5

        final_strength = base_strength * (1 + file_factor + size_factor) / 3
        return min(1.0, final_strength)

"""Extract line numbers that show coupling context."""
    def _extract_context_lines(self, file_path: str, content: str,
                             pattern_info: Dict[str, Any]) -> Dict[str, List[int]]:
        """Extract line numbers that show coupling context."""
        context_lines = {file_path: []}

        lines = content.split('\n')

        for i, line in enumerate(lines, 1):
            for pattern in pattern_info.get("patterns", []):
                if re.search(pattern, line, re.IGNORECASE):
                    context_lines[file_path].append(i)

        return context_lines

"""Group related connascence issues to avoid duplication."""
    def _group_related_issues(self, issues: List[ConnascenceIssue]) -> List[ConnascenceIssue]:
        """Group related connascence issues to avoid duplication."""
        grouped = {}

        for issue in issues:
            # Create a key based on the set of files involved
            file_set = tuple(sorted([issue.primary_file] + issue.coupled_files))
            key = f"{issue.issue_type}:{hash(file_set)}"

            if key not in grouped:
                grouped[key] = issue
            else:
                # Merge with existing issue
                existing = grouped[key]
                existing.coupled_files = list(set(existing.coupled_files + issue.coupled_files))
                existing.coupling_strength = max(existing.coupling_strength, issue.coupling_strength)

        return list(grouped.values())

    def __init__(self):
        self.test_runner_script = "scripts/comprehensive_test_runner.py"
        self.baseline_results = None
        self.current_results = None

"""Calculate improvement in test success rate."""
    def calculate_improvement(self) -> float:
        """Calculate improvement in test success rate."""
        if not self.baseline_results or not self.current_results:
            return 0.0

        baseline_rate = self.baseline_results.get('success_rate', 0.0)
        current_rate = self.current_results.get('success_rate', 0.0)

        return current_rate - baseline_rate

"""Check if there's a test regression compared to baseline."""
    def has_regression(self) -> bool:
        """Check if there's a test regression compared to baseline."""
        improvement = self.calculate_improvement()
        return improvement < 0

"""Check if current test results meet the target success rate."""
    def meets_target(self, target_rate: float = 100.0) -> bool:
        """Check if current test results meet the target success rate."""
        if not self.current_results:
            return False

        current_rate = self.current_results.get('success_rate', 0.0)
        return current_rate >= target_rate

    def __init__(self):
        self.history_file = Path(".claude/.artifacts/test_prediction_history.json")
        self.prediction_history = self._load_prediction_history()

"""Predict the probability of test success for given changes."""
    def predict_success_probability(self, change_context: Dict[str, Any]) -> float:
        """Predict the probability of test success for given changes."""
        # Extract features for prediction
        features = self._extract_features(change_context)

        # Use historical data for prediction
        if len(self.prediction_history.get("predictions", [])) < 5:
            # Not enough history, use heuristics
            return self._heuristic_prediction(features)

        # Use historical pattern matching
        return self._pattern_based_prediction(features)

"""Extract features for prediction from change context."""
    def _extract_features(self, change_context: Dict[str, Any]) -> Dict[str, Any]:
        """Extract features for prediction from change context."""
        return {
            "file_count": len(change_context.get("affected_files", [])),
            "change_complexity": change_context.get("complexity", "medium"),
            "has_test_changes": any("test" in f for f in change_context.get("affected_files", [])),
            "coupling_strength": change_context.get("coupling_strength", 0.0),
            "issue_type": change_context.get("issue_type", "unknown"),
            "previous_success_rate": change_context.get("baseline_success_rate", 0.0)
        }

"""Use heuristics for prediction when insufficient historical data."""
    def _heuristic_prediction(self, features: Dict[str, Any]) -> float:
        """Use heuristics for prediction when insufficient historical data."""
        base_probability = 0.7

        # Adjust based on file count
        file_count = features["file_count"]
        if file_count > 5:
            base_probability -= 0.2
        elif file_count == 1:
            base_probability += 0.1

        # Adjust based on complexity
        complexity = features["change_complexity"]
        if complexity == "high":
            base_probability -= 0.3
        elif complexity == "low":
            base_probability += 0.2

        # Adjust based on test changes
        if features["has_test_changes"]:
            base_probability += 0.1

        # Adjust based on coupling
        coupling = features["coupling_strength"]
        if coupling > 0.7:
            base_probability -= 0.2

        return max(0.0, min(1.0, base_probability))

"""Use historical patterns for prediction."""
    def _pattern_based_prediction(self, features: Dict[str, Any]) -> float:
        """Use historical patterns for prediction."""
        predictions = self.prediction_history["predictions"]

        # Find similar cases in history
        similar_cases = []
        for prediction in predictions[-20:]:  # Use recent history
            similarity = self._calculate_similarity(features, prediction["features"])
            if similarity > 0.6:
                similar_cases.append((similarity, prediction["actual_success"]))

        if not similar_cases:
            return self._heuristic_prediction(features)

        # Weight by similarity
        weighted_sum = sum(similarity * success for similarity, success in similar_cases)
        total_weight = sum(similarity for similarity, _ in similar_cases)

        return weighted_sum / total_weight if total_weight > 0 else 0.5

"""Calculate similarity between two feature sets."""
    def _calculate_similarity(self, features1: Dict[str, Any], features2: Dict[str, Any]) -> float:
        """Calculate similarity between two feature sets."""
        similarity = 0.0
        total_features = 0

        for key in features1:
            if key in features2:
                total_features += 1
                if isinstance(features1[key], (int, float)) and isinstance(features2[key], (int, float)):
                    # Numerical similarity
                    max_val = max(abs(features1[key]), abs(features2[key]), 1)
                    diff = abs(features1[key] - features2[key])
                    similarity += 1.0 - (diff / max_val)
                elif features1[key] == features2[key]:
                    # Exact match
                    similarity += 1.0

        return similarity / total_features if total_features > 0 else 0.0

"""Record prediction results for learning."""
    def record_prediction(self, features: Dict[str, Any], predicted_success: float, actual_success: bool):
        """Record prediction results for learning."""
        self.prediction_history["predictions"].append({
            "timestamp": datetime.now().isoformat(),
            "features": features,
            "predicted_success": predicted_success,
            "actual_success": actual_success,
            "accuracy": 1.0 - abs(predicted_success - (1.0 if actual_success else 0.0))
        })

        # Keep only recent predictions to manage memory
        if len(self.prediction_history["predictions"]) > 100:
            self.prediction_history["predictions"] = self.prediction_history["predictions"][-100:]

        # Update accuracy metrics
        recent_predictions = self.prediction_history["predictions"][-20:]
        avg_accuracy = sum(p["accuracy"] for p in recent_predictions) / len(recent_predictions)
        self.prediction_history["accuracy_metrics"] = {
            "recent_accuracy": avg_accuracy,
            "total_predictions": len(self.prediction_history["predictions"]),
            "last_updated": datetime.now().isoformat()
        }

        # Save to file
        try:
            self.history_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.history_file, 'w') as f:
                json.dump(self.prediction_history, f, indent=2)
        except Exception as e:
            print(f"Warning: Could not save prediction history: {e}")

    def __init__(self):
        self.repair_strategies = self._initialize_repair_strategies()
        self.repair_history = []

"""Initialize auto-repair strategies for different failure types."""
    def _initialize_repair_strategies(self) -> Dict[str, Any]:
        """Initialize auto-repair strategies for different failure types."""
        return {
            "import_errors": {
                "pattern": r"ModuleNotFoundError|ImportError",
                "repair_function": self._repair_import_errors,
                "confidence": 0.8
            },
            "syntax_errors": {
                "pattern": r"SyntaxError|IndentationError",
                "repair_function": self._repair_syntax_errors,
                "confidence": 0.6
            },
            "assertion_failures": {
                "pattern": r"AssertionError|assertion failed",
                "repair_function": self._repair_assertion_failures,
                "confidence": 0.4
            },
            "file_not_found": {
                "pattern": r"FileNotFoundError|No such file",
                "repair_function": self._repair_file_not_found,
                "confidence": 0.7
            },
            "environment_issues": {
                "pattern": r"Environment|PATH|permission denied",
                "repair_function": self._repair_environment_issues,
                "confidence": 0.5
            }
        }

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}

        # NEW: Queen Coordinator Integration
        self.queen_coordinator = QueenCoordinator(config)
        self.queen_analysis: Optional[QueenAnalysis] = None

        # NEW: Git Safety Manager Integration
        git_safety_enabled = self.config.get("git_safety_enabled", True)
        if git_safety_enabled:
            try:
                # Try relative import first
                from .git_safety_manager import GitSafetyManager
                self.git_safety_manager = GitSafetyManager(config)
                self.git_safety_enabled = True
                logger.info("Git Safety Manager initialized")
            except ImportError:
                try:
                    # Fallback to direct import
                    import sys
                    from pathlib import Path
                    sys.path.append(str(Path(__file__).parent))
                    from git_safety_manager import GitSafetyManager
                    self.git_safety_manager = GitSafetyManager(config)
                    self.git_safety_enabled = True
                    logger.info("Git Safety Manager initialized (fallback import)")
                except ImportError:
                    logger.warning("Git Safety Manager not available, proceeding without Git safety")
                    self.git_safety_manager = None
                    self.git_safety_enabled = False
        else:
            self.git_safety_manager = None
            self.git_safety_enabled = False

        # Original components
        self.connascence_detector = ConnascenceDetector()
        self.current_execution: Optional[LoopExecution] = None
        self.specialist_agents = self._initialize_specialist_agents()
        self.refactor_knowledge_base = self._load_refactor_knowledge()

        # Enhanced testing integration
        self.test_coordinator = TestCoordinator()
        self.test_success_predictor = TestSuccessPredictor()
        self.auto_repair_engine = AutoRepairEngine()
        self.test_execution_history = []

"""Initialize specialist agents for different types of issues."""
    def _initialize_specialist_agents(self) -> Dict[str, str]:
        """Initialize specialist agents for different types of issues."""
        return {
            "connascence_specialist": "Task tool with connascence-specific expertise",
            "refactoring_specialist": "Task tool with refactoring pattern knowledge",
            "coupling_analyzer": "Task tool with dependency analysis expertise",
            "pattern_researcher": "Task tool with online pattern research capability",
            "architecture_reviewer": "Task tool with system architecture expertise",
            "code_quality_expert": "Task tool with code quality and metrics expertise"
        }

"""Extract file paths from failure data."""
    def _extract_affected_files(self, failure_data: Dict[str, Any]) -> List[str]:
        """Extract file paths from failure data."""
        affected_files = []

        # Look for file paths in failure messages and logs
        for failure in failure_data.get("critical_failures", []):
            step_name = failure.get("step_name", "")
            job_name = failure.get("job_name", "")

            # Extract file paths from step names and job names
            file_patterns = [
                r"([a-zA-Z0-9_/.-]+\.(js|ts|py|java|go|rs|cpp|c|h))",
                r"src/[a-zA-Z0-9_/.-]+",
                r"test/[a-zA-Z0-9_/.-]+",
                r"lib/[a-zA-Z0-9_/.-]+"
            ]

            for pattern in file_patterns:
                matches = re.findall(pattern, f"{step_name} {job_name}")
                for match in matches:
                    file_path = match[0] if isinstance(match, tuple) else match
                    if path_exists(file_path):
                        affected_files.append(str(Path(file_path).resolve()))

        # Also scan current directory for recently modified files
        if not affected_files:
            try:
                result = subprocess.run(
                    ["git", "diff", "--name-only", "HEAD~1"],
                    capture_output=True, text=True, timeout=30
                )
                if result.returncode == 0:
                    git_files = result.stdout.strip().split('\n')
                    for file_path in git_files:
                        if file_path and path_exists(file_path):
                            affected_files.append(str(Path(file_path).resolve()))
            except:
                pass

        return list(set(affected_files))

"""Generate step-by-step implementation plan."""
    def _generate_implementation_plan(self, issue: ConnascenceIssue, technique: str) -> List[str]:
        """Generate step-by-step implementation plan."""
        base_plan = [
            f"1. Analyze current coupling in {issue.primary_file}",
            f"2. Identify refactoring boundaries for {technique}",
            "3. Create comprehensive test coverage for affected code",
            f"4. Apply {technique} refactoring incrementally",
            "5. Validate functionality preservation",
            "6. Update documentation and imports",
            "7. Run full test suite and quality checks"
        ]

        # Add technique-specific steps
        if technique == "extract_class":
            base_plan.insert(4, "4a. Create new class with appropriate interface")
            base_plan.insert(5, "4b. Move related methods and data")
            base_plan.insert(6, "4c. Update client code to use new class")

        elif technique == "dependency_injection":
            base_plan.insert(4, "4a. Define interfaces for dependencies")
            base_plan.insert(5, "4b. Create dependency injection container")
            base_plan.insert(6, "4c. Refactor constructors to accept dependencies")

        return base_plan

"""Assess risk level of refactoring."""
    def _assess_refactoring_risk(self, issue: ConnascenceIssue) -> str:
        """Assess risk level of refactoring."""
        risk_factors = 0

        # High coupling strength increases risk
        if issue.coupling_strength > 0.7:
            risk_factors += 2

        # Multiple coupled files increase risk
        if len(issue.coupled_files) > 3:
            risk_factors += 1

        # Certain types are riskier
        if issue.issue_type in ["temporal", "communicational"]:
            risk_factors += 1

        if risk_factors >= 3:
            return "high"
        elif risk_factors >= 1:
            return "medium"
        else:
            return "low"

"""Estimate effort in hours for refactoring."""
    def _estimate_refactoring_effort(self, issue: ConnascenceIssue) -> int:
        """Estimate effort in hours for refactoring."""
        base_effort = {
            "coincidental": 2,
            "logical": 3,
            "temporal": 8,
            "procedural": 4,
            "communicational": 6,
            "sequential": 5,
            "functional": 1
        }.get(issue.issue_type, 4)

        # Adjust for coupling strength and number of files
        multiplier = 1 + (issue.coupling_strength * 0.5) + (len(issue.coupled_files) * 0.2)

        return max(1, int(base_effort * multiplier))

"""Create validation strategy for refactoring."""
    def _create_validation_strategy(self, issue: ConnascenceIssue) -> List[str]:
        """Create validation strategy for refactoring."""
        return [
            "Run existing test suite before refactoring",
            "Create additional tests for coupling points",
            "Validate functionality preservation step by step",
            "Check performance impact of changes",
            "Verify no new coupling introduced",
            "Update integration tests if needed",
            "Code review by architecture expert"
        ]

"""Generate comprehensive commit message."""
    def _generate_commit_message(self, execution: LoopExecution) -> str:
        """Generate comprehensive commit message."""

        fixes_applied = execution.step_results.get("fix_implementation", {}).get("successful_fixes", 0)
        coupling_improvements = execution.step_results.get("theater_detection", {}).get("coupling_improvements", 0)

        message = f"""Automated CI/CD failure resolution - Loop {execution.loop_id}

Iteration: {execution.current_iteration}/{execution.max_iterations}
Fixes applied: {fixes_applied}
Coupling improvements: {coupling_improvements}
Connascence issues addressed: {len(execution.connascence_issues)}

Multi-file coordination:
{self._format_multi_file_fixes(execution.multi_file_fixes)}

Validation:
- Theater detection passed: {not execution.step_results.get('theater_detection', {}).get('theater_detected', True)}
- Sandbox testing: {execution.step_results.get('sandbox_testing', {}).get('test_suite_passed', False)}
- Authenticity score: {execution.step_results.get('theater_detection', {}).get('authenticity_score', 0.0):.2f}

Generated with SPEK Enhanced Development Platform CI/CD Loop
Co-Authored-By: Claude <noreply@anthropic.com>"""

        return message

"""Format multi-file fixes for commit message."""
    def _format_multi_file_fixes(self, fixes: List[MultiFileFix]) -> str:
        """Format multi-file fixes for commit message."""
        if not fixes:
            return "- No multi-file coordination required"

        formatted = []
        for fix in fixes:
            formatted.append(f"- {fix.description} ({fix.refactor_technique})")

        return "\n".join(formatted)

"""Generate comprehensive execution report."""
    def _generate_execution_report(self, execution: LoopExecution) -> Dict[str, Any]:
        """Generate comprehensive execution report."""

        return {
            "execution_metadata": {
                "loop_id": execution.loop_id,
                "start_time": execution.start_time,
                "end_time": datetime.now(),
                "total_iterations": execution.current_iteration,
                "max_iterations": execution.max_iterations,
                "escalation_triggered": execution.escalation_triggered
            },
            "connascence_analysis": {
                "issues_detected": len(execution.connascence_issues),
                "issue_types": list(set(issue.issue_type for issue in execution.connascence_issues)),
                "average_coupling_strength": sum(issue.coupling_strength for issue in execution.connascence_issues) / len(execution.connascence_issues) if execution.connascence_issues else 0,
                "high_severity_issues": len([issue for issue in execution.connascence_issues if issue.severity == "high"])
            },
            "multi_file_coordination": {
                "fixes_attempted": len(execution.multi_file_fixes),
                "refactoring_techniques_used": list(set(fix.refactor_technique for fix in execution.multi_file_fixes)),
                "coordination_strategies": list(set(fix.coordination_strategy for fix in execution.multi_file_fixes))
            },
            "step_results": execution.step_results,
            "success_metrics": {
                "authenticity_score": execution.step_results.get("theater_detection", {}).get("authenticity_score", 0.0),
                "coupling_improvements": execution.step_results.get("theater_detection", {}).get("coupling_improvements", 0),
                "test_success": execution.step_results.get("sandbox_testing", {}).get("test_suite_passed", False),
                "overall_success": not execution.escalation_triggered
            }
        }

"""Main entry point for loop orchestrator."""
def main():
    """Main entry point for loop orchestrator."""
    import argparse

    parser = argparse.ArgumentParser(description="CI/CD Loop Orchestrator")
    parser.add_argument("--input", required=True, help="Input failure data JSON file")
    parser.add_argument("--max-iterations", type=int, default=5, help="Maximum loop iterations")
    parser.add_argument("--config", help="Configuration file path")

    args = parser.parse_args()

    # Load failure data
    with open(args.input, 'r') as f:
        failure_data = json.load(f)

    # Load configuration
    config = {}
    if args.config and path_exists(args.config):
        with open(args.config, 'r') as f:
            config = json.load(f)

    # Initialize and run orchestrator
    orchestrator = LoopOrchestrator(config)

    # Run the loop
    async def run_loop():
        execution = await orchestrator.execute_loop(failure_data, args.max_iterations)

        print(f"Loop execution completed:")
        print(f"- Loop ID: {execution.loop_id}")
        print(f"- Iterations: {execution.current_iteration}")
        print(f"- Connascence issues detected: {len(execution.connascence_issues)}")
        print(f"- Multi-file fixes: {len(execution.multi_file_fixes)}")
        print(f"- Escalation triggered: {execution.escalation_triggered}")

        return execution

    # Run async loop
    asyncio.run(run_loop())

