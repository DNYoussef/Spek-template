# SPEK Development Platform - Deployment Manual

## Table of Contents

1. [Overview](#overview)
2. [Pre-Deployment Requirements](#pre-deployment-requirements)
3. [Environment Setup](#environment-setup)
4. [Production Deployment](#production-deployment)
5. [Container Deployment](#container-deployment)
6. [Cloud Deployment](#cloud-deployment)
7. [Configuration Management](#configuration-management)
8. [Security Configuration](#security-configuration)
9. [Monitoring and Alerting](#monitoring-and-alerting)
10. [Performance Tuning](#performance-tuning)
11. [Disaster Recovery](#disaster-recovery)
12. [Maintenance Procedures](#maintenance-procedures)

## Overview

This deployment manual provides comprehensive instructions for deploying the SPEK Enhanced Development Platform in production environments. SPEK delivers 58.3% performance improvement with NASA POT10 compliance and defense industry-grade security.

### Deployment Architecture

```
Production Deployment Architecture
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Load Balancer                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    Reverse Proxy (nginx)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        SPEK Instance 1            ‚îÇ  ‚îÇ        SPEK Instance 2            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    Unified API Layer       ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ    Unified API Layer       ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ System Integration         ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ System Integration         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Controller                 ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Controller                 ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ Phase Managers             ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Phase Managers             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - JSON Schema              ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ - JSON Schema              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Linter Integration       ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ - Linter Integration       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Performance Optimization ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ - Performance Optimization ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Precision Validation     ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ - Precision Validation     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                                       ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Shared Resources                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ     Redis       ‚îÇ  ‚îÇ   PostgreSQL    ‚îÇ  ‚îÇ Shared Storage  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Cache       ‚îÇ  ‚îÇ    Database     ‚îÇ  ‚îÇ   (Analysis)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Monitoring Stack                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Prometheus    ‚îÇ  ‚îÇ     Grafana     ‚îÇ  ‚îÇ   AlertManager  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    Metrics      ‚îÇ  ‚îÇ   Dashboards    ‚îÇ  ‚îÇ     Alerts      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Deployment Characteristics

- **High Availability**: Multi-instance deployment with load balancing
- **Scalability**: Horizontal scaling support
- **Security**: NATO/Defense industry grade security (95% NASA POT10 compliance)
- **Performance**: 58.3% improvement target maintained
- **Monitoring**: Comprehensive observability and alerting

## Pre-Deployment Requirements

### System Requirements

#### Minimum Requirements

| Component | Specification |
|-----------|---------------|
| **CPU** | 4 cores, 2.4GHz+ |
| **Memory** | 8GB RAM |
| **Storage** | 50GB SSD |
| **Network** | 1Gbps |
| **OS** | Ubuntu 20.04+, RHEL 8+, or equivalent |

#### Recommended Requirements

| Component | Specification |
|-----------|---------------|
| **CPU** | 8 cores, 3.0GHz+ |
| **Memory** | 16GB RAM |
| **Storage** | 200GB NVMe SSD |
| **Network** | 10Gbps |
| **OS** | Ubuntu 22.04 LTS |

#### Enterprise Requirements

| Component | Specification |
|-----------|---------------|
| **CPU** | 16+ cores, 3.5GHz+ |
| **Memory** | 32GB+ RAM |
| **Storage** | 1TB+ NVMe SSD |
| **Network** | 25Gbps+ |
| **OS** | Ubuntu 22.04 LTS with security hardening |

### Software Dependencies

#### Core Dependencies

```bash
# Python runtime
Python 3.9-3.11

# System packages
sudo apt-get update
sudo apt-get install -y \
    python3 \
    python3-pip \
    python3-venv \
    git \
    curl \
    wget \
    unzip \
    build-essential \
    libssl-dev \
    libffi-dev \
    python3-dev

# Optional: Database support
sudo apt-get install -y postgresql-client redis-tools
```

#### Python Dependencies

```bash
# Core SPEK dependencies
pip install \
    pathspec>=0.9.0 \
    toml>=0.10.0 \
    typing-extensions>=4.0.0 \
    dataclasses>=0.6 \
    asyncio-extras>=1.3.0

# Performance dependencies
pip install \
    numpy>=1.21.0 \
    psutil>=5.8.0 \
    uvloop>=0.16.0

# Monitoring dependencies
pip install \
    prometheus-client>=0.12.0 \
    structlog>=21.0.0
```

### Network Requirements

#### Ports

| Port | Protocol | Purpose | Access |
|------|----------|---------|---------|
| 8000 | HTTP | SPEK API Server | Internal |
| 8443 | HTTPS | SPEK API Server (TLS) | External |
| 6379 | TCP | Redis Cache | Internal |
| 5432 | TCP | PostgreSQL Database | Internal |
| 9090 | HTTP | Prometheus Metrics | Internal |
| 3000 | HTTP | Grafana Dashboard | Internal |

#### Firewall Configuration

```bash
# Ubuntu/Debian with ufw
sudo ufw allow from 10.0.0.0/8 to any port 8000
sudo ufw allow from 10.0.0.0/8 to any port 8443
sudo ufw allow from 10.0.0.0/8 to any port 6379
sudo ufw allow from 10.0.0.0/8 to any port 5432
sudo ufw allow from 10.0.0.0/8 to any port 9090
sudo ufw allow from 10.0.0.0/8 to any port 3000

# RHEL/CentOS with firewalld
sudo firewall-cmd --permanent --add-rich-rule="rule family=ipv4 source address=10.0.0.0/8 port port=8000 protocol=tcp accept"
sudo firewall-cmd --permanent --add-rich-rule="rule family=ipv4 source address=10.0.0.0/8 port port=8443 protocol=tcp accept"
sudo firewall-cmd --reload
```

## Environment Setup

### User and Directory Setup

```bash
# Create SPEK user
sudo useradd -r -m -s /bin/bash -d /opt/spek spek

# Create directory structure
sudo mkdir -p /opt/spek/{app,config,data,logs,cache}
sudo mkdir -p /var/log/spek
sudo mkdir -p /etc/spek

# Set ownership
sudo chown -R spek:spek /opt/spek
sudo chown -R spek:spek /var/log/spek
sudo chown -R spek:spek /etc/spek

# Set permissions
sudo chmod 750 /opt/spek
sudo chmod 750 /var/log/spek
sudo chmod 750 /etc/spek
```

### Application Installation

```bash
# Switch to SPEK user
sudo -u spek -i

# Create virtual environment
cd /opt/spek
python3 -m venv venv
source venv/bin/activate

# Install SPEK
git clone https://github.com/your-org/spek-platform.git app
cd app
pip install -r requirements.txt
pip install -e .

# Verify installation
python -c "from analyzer.unified_api import UnifiedAnalyzerAPI; print('‚úì SPEK installed successfully')"
```

### Configuration Files

#### Production Configuration

**File**: `/etc/spek/production.yaml`

```yaml
spek:
  environment: production
  debug: false
  log_level: INFO
  
  server:
    host: "0.0.0.0"
    port: 8000
    workers: 8
    max_requests: 1000
    max_requests_jitter: 100
    timeout: 300
    keepalive: 65
    
  analysis:
    default_policy: nasa-compliance
    parallel_execution: true
    max_workers: 8
    cache_enabled: true
    timeout_seconds: 600
    retry_attempts: 3
    
  phases:
    json_schema:
      enabled: true
      strict_validation: true
      timeout_seconds: 60
    linter_integration:
      enabled: true
      real_time_processing: true
      timeout_seconds: 120
    performance_optimization:
      enabled: true
      target_improvement: 0.583
      baseline_measurements: 10
      timeout_seconds: 300
    precision_validation:
      enabled: true
      byzantine_nodes: 5
      consensus_threshold: 0.95
      theater_detection_sensitivity: high
      timeout_seconds: 180
  
  security:
    nasa_compliance_threshold: 0.95
    enable_byzantine_consensus: true
    enable_theater_detection: true
    strict_mode: true
    tls_enabled: true
    tls_cert_path: "/etc/spek/ssl/spek.crt"
    tls_key_path: "/etc/spek/ssl/spek.key"
    
  database:
    url: "postgresql://spek:${SPEK_DB_PASSWORD}@localhost:5432/spek"
    pool_size: 20
    max_overflow: 0
    pool_timeout: 30
    pool_recycle: 3600
    
  cache:
    redis_url: "redis://localhost:6379/0"
    default_timeout: 3600
    key_prefix: "spek:prod:"
    max_connections: 100
    
  monitoring:
    metrics_enabled: true
    metrics_port: 9090
    health_check_enabled: true
    performance_tracking: true
    audit_logging: true
    
  logging:
    level: INFO
    format: json
    file: "/var/log/spek/spek.log"
    max_size: "100MB"
    backup_count: 5
    
  storage:
    base_path: "/opt/spek/data"
    cache_path: "/opt/spek/cache"
    temp_path: "/tmp/spek"
    max_storage_size: "10GB"
    cleanup_interval: 3600
```

#### Environment Variables

**File**: `/etc/spek/environment`

```bash
# Core settings
export SPEK_ENV=production
export SPEK_CONFIG_PATH=/etc/spek/production.yaml
export SPEK_LOG_LEVEL=INFO
export SPEK_DEBUG=false

# Database credentials
export SPEK_DB_PASSWORD=your_secure_password_here
export SPEK_DB_HOST=localhost
export SPEK_DB_PORT=5432
export SPEK_DB_NAME=spek

# Cache settings
export SPEK_REDIS_URL=redis://localhost:6379/0
export SPEK_REDIS_PASSWORD=your_redis_password_here

# Security settings
export SPEK_SECRET_KEY=your_secret_key_here
export SPEK_JWT_SECRET=your_jwt_secret_here
export SPEK_ENCRYPTION_KEY=your_encryption_key_here

# Performance settings
export SPEK_MAX_WORKERS=8
export SPEK_MEMORY_LIMIT=8192
export SPEK_TIMEOUT=600

# Monitoring
export SPEK_METRICS_ENABLED=true
export SPEK_ALERT_WEBHOOK_URL=https://alerts.company.com/spek

# SSL/TLS
export SPEK_TLS_CERT_PATH=/etc/spek/ssl/spek.crt
export SPEK_TLS_KEY_PATH=/etc/spek/ssl/spek.key

# Feature flags
export SPEK_NASA_COMPLIANCE_STRICT=true
export SPEK_BYZANTINE_FAULT_TOLERANCE=true
export SPEK_THEATER_DETECTION_ENABLED=true
export SPEK_PERFORMANCE_MONITORING_ENABLED=true
```

#### Service Configuration

**File**: `/etc/systemd/system/spek.service`

```ini
[Unit]
Description=SPEK Enhanced Development Platform
After=network.target postgresql.service redis.service
Wants=postgresql.service redis.service

[Service]
Type=notify
User=spek
Group=spek
WorkingDirectory=/opt/spek/app
EnvironmentFile=/etc/spek/environment
ExecStart=/opt/spek/venv/bin/python -m spek.server
ExecReload=/bin/kill -HUP $MAINPID
Restart=always
RestartSec=5
TimeoutStopSec=30
KillMode=mixed
PrivateTmp=yes
NoNewPrivileges=yes
ProtectSystem=strict
ProtectHome=yes
ReadWritePaths=/opt/spek/data /opt/spek/cache /var/log/spek /tmp/spek

# Security settings
LimitNOFILE=65535
LimitNPROC=4096

# Resource limits
MemoryLimit=8G
CPUQuota=800%

[Install]
WantedBy=multi-user.target
```

## Production Deployment

### Step-by-Step Deployment

#### Step 1: System Preparation

```bash
# Update system
sudo apt-get update && sudo apt-get upgrade -y

# Install prerequisites
sudo apt-get install -y python3 python3-pip python3-venv git nginx postgresql redis-server

# Configure PostgreSQL
sudo -u postgres createuser -P spek
sudo -u postgres createdb -O spek spek

# Configure Redis
sudo systemctl enable redis-server
sudo systemctl start redis-server

# Secure Redis
sudo sed -i 's/# requirepass foobared/requirepass your_redis_password_here/' /etc/redis/redis.conf
sudo systemctl restart redis-server
```

#### Step 2: Application Deployment

```bash
# Deploy as SPEK user
sudo -u spek -i
cd /opt/spek

# Clone and install application
git clone https://github.com/your-org/spek-platform.git app
cd app

# Create virtual environment
python3 -m venv ../venv
source ../venv/bin/activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .

# Initialize database
python -m spek.db.init

# Run initial tests
python -m pytest tests/integration/ -v
```

#### Step 3: SSL/TLS Configuration

```bash
# Generate SSL certificate (for development - use proper CA certs in production)
sudo mkdir -p /etc/spek/ssl
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
    -keyout /etc/spek/ssl/spek.key \
    -out /etc/spek/ssl/spek.crt \
    -subj "/C=US/ST=State/L=City/O=Organization/CN=your-domain.com"

# Set proper permissions
sudo chown spek:spek /etc/spek/ssl/spek.*
sudo chmod 600 /etc/spek/ssl/spek.key
sudo chmod 644 /etc/spek/ssl/spek.crt
```

#### Step 4: Service Configuration

```bash
# Copy service file
sudo cp deployment/systemd/spek.service /etc/systemd/system/

# Reload systemd and enable service
sudo systemctl daemon-reload
sudo systemctl enable spek
sudo systemctl start spek

# Check service status
sudo systemctl status spek
```

#### Step 5: Reverse Proxy Configuration

**File**: `/etc/nginx/sites-available/spek`

```nginx
upstream spek_backend {
    server 127.0.0.1:8000 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:8001 max_fails=3 fail_timeout=30s backup;
    keepalive 32;
}

server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    # SSL configuration
    ssl_certificate /etc/spek/ssl/spek.crt;
    ssl_certificate_key /etc/spek/ssl/spek.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384;
    ssl_prefer_server_ciphers on;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 1d;
    
    # Security headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    
    # Logging
    access_log /var/log/nginx/spek_access.log;
    error_log /var/log/nginx/spek_error.log;
    
    # General configuration
    client_max_body_size 100M;
    client_body_timeout 30s;
    client_header_timeout 30s;
    send_timeout 30s;
    
    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types application/json application/javascript text/css text/javascript text/xml application/xml application/xml+rss text/plain;
    
    # Health check endpoint
    location /health {
        proxy_pass http://spek_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        access_log off;
    }
    
    # API endpoints
    location /api/ {
        proxy_pass http://spek_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 30s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
        proxy_buffering off;
    }
    
    # Metrics endpoint (restrict access)
    location /metrics {
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
        
        proxy_pass http://spek_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    # Static files (if any)
    location /static/ {
        alias /opt/spek/app/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

Enable the site:

```bash
# Enable site
sudo ln -s /etc/nginx/sites-available/spek /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

#### Step 6: Validation

```bash
# Test health endpoint
curl -k https://your-domain.com/health

# Test API endpoint
curl -k -X POST https://your-domain.com/api/v1/analysis/submit \
    -H "Content-Type: application/json" \
    -d '{"project_name": "test", "files": []}'

# Check service logs
sudo journalctl -u spek -f

# Check application logs
sudo tail -f /var/log/spek/spek.log
```

## Container Deployment

### Docker Configuration

#### Dockerfile

**File**: `Dockerfile`

```dockerfile
FROM python:3.11-slim-bullseye

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    libssl-dev \
    libffi-dev \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Create user
RUN useradd -r -m -s /bin/bash -d /app spek

# Set work directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .
RUN pip install -e .

# Create necessary directories
RUN mkdir -p /app/data /app/cache /app/logs && \
    chown -R spek:spek /app

# Switch to non-root user
USER spek

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Command
CMD ["python", "-m", "spek.server"]
```

#### Docker Compose

**File**: `docker-compose.yml`

```yaml
version: '3.8'

services:
  spek:
    build: .
    ports:
      - "8000:8000"
    environment:
      - SPEK_ENV=production
      - SPEK_DB_HOST=postgres
      - SPEK_REDIS_URL=redis://redis:6379/0
      - SPEK_LOG_LEVEL=INFO
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - spek_data:/app/data
      - spek_cache:/app/cache
      - spek_logs:/app/logs
    networks:
      - spek_network
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    restart: unless-stopped

  postgres:
    image: postgres:14-alpine
    environment:
      - POSTGRES_DB=spek
      - POSTGRES_USER=spek
      - POSTGRES_PASSWORD=${SPEK_DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - spek_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U spek"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${SPEK_REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - spek_network
    healthcheck:
      test: ["CMD", "redis-cli", "auth", "${SPEK_REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - spek
    networks:
      - spek_network
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - spek_network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - spek_network
    restart: unless-stopped

volumes:
  spek_data:
  spek_cache:
  spek_logs:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  spek_network:
    driver: bridge
```

#### Environment File

**File**: `.env.production`

```bash
# Database
SPEK_DB_PASSWORD=your_secure_db_password
SPEK_DB_HOST=postgres
SPEK_DB_PORT=5432
SPEK_DB_NAME=spek

# Redis
SPEK_REDIS_PASSWORD=your_secure_redis_password
SPEK_REDIS_URL=redis://redis:6379/0

# Security
SPEK_SECRET_KEY=your_secret_key_here
SPEK_JWT_SECRET=your_jwt_secret_here

# Monitoring
GRAFANA_PASSWORD=your_grafana_password

# SPEK Configuration
SPEK_NASA_COMPLIANCE_STRICT=true
SPEK_BYZANTINE_FAULT_TOLERANCE=true
SPEK_PERFORMANCE_MONITORING_ENABLED=true
```

#### Docker Deployment Commands

```bash
# Build and start services
docker-compose -f docker-compose.yml up -d --build

# Scale SPEK instances
docker-compose -f docker-compose.yml up -d --scale spek=3

# View logs
docker-compose logs -f spek

# Execute commands in container
docker-compose exec spek python -m spek.cli --help

# Stop services
docker-compose down

# Update deployment
docker-compose pull
docker-compose up -d --build
```

## Cloud Deployment

### AWS Deployment

#### ECS Task Definition

**File**: `ecs-task-definition.json`

```json
{
  "family": "spek-production",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "2048",
  "memory": "4096",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT:role/spek-task-role",
  "containerDefinitions": [
    {
      "name": "spek",
      "image": "your-registry/spek:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "SPEK_ENV",
          "value": "production"
        },
        {
          "name": "SPEK_LOG_LEVEL",
          "value": "INFO"
        }
      ],
      "secrets": [
        {
          "name": "SPEK_DB_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT:secret:spek/db-password"
        },
        {
          "name": "SPEK_REDIS_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT:secret:spek/redis-password"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/spek-production",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

#### CloudFormation Template

**File**: `cloudformation-template.yaml`

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'SPEK Production Infrastructure'

Parameters:
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID for deployment
  
  SubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: Subnet IDs for deployment
  
  DatabasePassword:
    Type: String
    NoEcho: true
    Description: Password for RDS database

Resources:
  # Application Load Balancer
  LoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: spek-alb
      Type: application
      Scheme: internet-facing
      Subnets: !Ref SubnetIds
      SecurityGroups:
        - !Ref ALBSecurityGroup

  # ALB Target Group
  TargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: spek-targets
      Port: 8000
      Protocol: HTTP
      VpcId: !Ref VpcId
      TargetType: ip
      HealthCheckPath: /health
      HealthCheckProtocol: HTTP
      HealthCheckIntervalSeconds: 30
      HealthCheckTimeoutSeconds: 10
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 5

  # ALB Listener
  ALBListener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref TargetGroup
      LoadBalancerArn: !Ref LoadBalancer
      Port: 443
      Protocol: HTTPS
      Certificates:
        - CertificateArn: !Ref SSLCertificate

  # SSL Certificate
  SSLCertificate:
    Type: AWS::CertificateManager::Certificate
    Properties:
      DomainName: spek.yourdomain.com
      ValidationMethod: DNS

  # ECS Cluster
  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: spek-production

  # ECS Service
  ECSService:
    Type: AWS::ECS::Service
    DependsOn: ALBListener
    Properties:
      ServiceName: spek-service
      Cluster: !Ref ECSCluster
      TaskDefinition: !Ref TaskDefinition
      DesiredCount: 2
      LaunchType: FARGATE
      NetworkConfiguration:
        AwsvpcConfiguration:
          Subnets: !Ref SubnetIds
          SecurityGroups:
            - !Ref ECSSecurityGroup
          AssignPublicIp: ENABLED
      LoadBalancers:
        - ContainerName: spek
          ContainerPort: 8000
          TargetGroupArn: !Ref TargetGroup

  # RDS Database
  Database:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: spek-production
      DBInstanceClass: db.t3.medium
      Engine: postgres
      EngineVersion: '14.6'
      AllocatedStorage: '100'
      StorageType: gp2
      DBName: spek
      MasterUsername: spek
      MasterUserPassword: !Ref DatabasePassword
      VPCSecurityGroups:
        - !Ref DatabaseSecurityGroup
      DBSubnetGroupName: !Ref DatabaseSubnetGroup
      BackupRetentionPeriod: 7
      MultiAZ: true
      StorageEncrypted: true

  # ElastiCache Redis
  RedisCluster:
    Type: AWS::ElastiCache::ReplicationGroup
    Properties:
      ReplicationGroupId: spek-redis
      ReplicationGroupDescription: SPEK Redis Cluster
      NodeType: cache.t3.micro
      NumCacheClusters: 2
      Engine: redis
      EngineVersion: '7.0'
      Port: 6379
      SecurityGroupIds:
        - !Ref RedisSecurityGroup
      SubnetGroupName: !Ref RedisSubnetGroup
      AtRestEncryptionEnabled: true
      TransitEncryptionEnabled: true

  # Security Groups
  ALBSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for ALB
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0

  ECSSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for ECS tasks
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 8000
          ToPort: 8000
          SourceSecurityGroupId: !Ref ALBSecurityGroup

Outputs:
  LoadBalancerDNS:
    Description: DNS name of the load balancer
    Value: !GetAtt LoadBalancer.DNSName
  
  DatabaseEndpoint:
    Description: RDS database endpoint
    Value: !GetAtt Database.Endpoint.Address
  
  RedisEndpoint:
    Description: Redis cluster endpoint
    Value: !GetAtt RedisCluster.RedisEndpoint.Address
```

### Kubernetes Deployment

#### Kubernetes Manifests

**File**: `k8s-deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spek
  namespace: spek
  labels:
    app: spek
spec:
  replicas: 3
  selector:
    matchLabels:
      app: spek
  template:
    metadata:
      labels:
        app: spek
    spec:
      containers:
      - name: spek
        image: your-registry/spek:latest
        ports:
        - containerPort: 8000
        env:
        - name: SPEK_ENV
          value: "production"
        - name: SPEK_DB_HOST
          value: "postgres-service"
        - name: SPEK_REDIS_URL
          value: "redis://redis-service:6379/0"
        envFrom:
        - secretRef:
            name: spek-secrets
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: spek-data
          mountPath: /app/data
        - name: spek-cache
          mountPath: /app/cache
      volumes:
      - name: spek-data
        persistentVolumeClaim:
          claimName: spek-data-pvc
      - name: spek-cache
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: spek-service
  namespace: spek
spec:
  selector:
    app: spek
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: spek-ingress
  namespace: spek
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - spek.yourdomain.com
    secretName: spek-tls
  rules:
  - host: spek.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: spek-service
            port:
              number: 80

---
apiVersion: v1
kind: Secret
metadata:
  name: spek-secrets
  namespace: spek
type: Opaque
data:
  SPEK_DB_PASSWORD: <base64-encoded-password>
  SPEK_REDIS_PASSWORD: <base64-encoded-password>
  SPEK_SECRET_KEY: <base64-encoded-secret>

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spek-data-pvc
  namespace: spek
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd
```

## Configuration Management

### Configuration Validation

```python
#!/usr/bin/env python3
"""
Configuration validation script for SPEK deployment
"""

import os
import yaml
import sys
from pathlib import Path

def validate_config(config_path: str):
    """Validate SPEK configuration file"""
    
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"‚ùå Failed to load config: {e}")
        return False
    
    # Required sections
    required_sections = ['spek', 'analysis', 'phases', 'security']
    for section in required_sections:
        if section not in config:
            print(f"‚ùå Missing required section: {section}")
            return False
    
    # Validate SPEK section
    spek_config = config['spek']
    if spek_config.get('environment') not in ['development', 'production']:
        print(f"‚ùå Invalid environment: {spek_config.get('environment')}")
        return False
    
    # Validate phases
    phases_config = config['phases']
    required_phases = ['json_schema', 'linter_integration', 'performance_optimization', 'precision_validation']
    for phase in required_phases:
        if phase not in phases_config:
            print(f"‚ùå Missing phase configuration: {phase}")
            return False
    
    # Validate security settings
    security_config = config['security']
    if security_config.get('nasa_compliance_threshold', 0) < 0.8:
        print(f"‚ö†Ô∏è  NASA compliance threshold too low: {security_config.get('nasa_compliance_threshold')}")
    
    print("‚úÖ Configuration validation passed")
    return True

def validate_environment():
    """Validate environment setup"""
    
    # Check required environment variables
    required_vars = [
        'SPEK_ENV',
        'SPEK_CONFIG_PATH',
        'SPEK_DB_PASSWORD',
        'SPEK_REDIS_PASSWORD'
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        print(f"‚ùå Missing environment variables: {', '.join(missing_vars)}")
        return False
    
    # Check file permissions
    config_path = os.getenv('SPEK_CONFIG_PATH')
    if config_path and os.path.exists(config_path):
        stat = os.stat(config_path)
        if stat.st_mode & 0o077:  # Check if group/others have access
            print(f"‚ö†Ô∏è  Config file permissions too permissive: {config_path}")
    
    print("‚úÖ Environment validation passed")
    return True

if __name__ == "__main__":
    config_path = sys.argv[1] if len(sys.argv) > 1 else "/etc/spek/production.yaml"
    
    print("üîç Validating SPEK deployment configuration...")
    
    config_valid = validate_config(config_path)
    env_valid = validate_environment()
    
    if config_valid and env_valid:
        print("\n‚úÖ All validations passed - deployment ready!")
        sys.exit(0)
    else:
        print("\n‚ùå Validation failed - please fix issues before deployment")
        sys.exit(1)
```

### Configuration Templates

#### Development Template

**File**: `config/templates/development.yaml`

```yaml
spek:
  environment: development
  debug: true
  log_level: DEBUG
  
  analysis:
    default_policy: standard
    max_workers: 2
    timeout_seconds: 300
    
  phases:
    json_schema:
      enabled: true
      strict_validation: false
    linter_integration:
      enabled: true
      auto_fix_suggestions: true
    performance_optimization:
      enabled: false  # Disabled for faster development
      target_improvement: 0.3
    precision_validation:
      enabled: false  # Disabled for faster development
      
  security:
    nasa_compliance_threshold: 0.80
    strict_mode: false
    
  monitoring:
    metrics_enabled: false
    performance_tracking: false
```

#### Staging Template

**File**: `config/templates/staging.yaml`

```yaml
spek:
  environment: staging
  debug: false
  log_level: INFO
  
  analysis:
    default_policy: nasa-compliance
    max_workers: 4
    timeout_seconds: 600
    
  phases:
    json_schema:
      enabled: true
      strict_validation: true
    linter_integration:
      enabled: true
      real_time_processing: true
    performance_optimization:
      enabled: true
      target_improvement: 0.583
    precision_validation:
      enabled: true
      byzantine_nodes: 3
      
  security:
    nasa_compliance_threshold: 0.95
    enable_byzantine_consensus: true
    enable_theater_detection: true
    
  monitoring:
    metrics_enabled: true
    performance_tracking: true
```

## Security Configuration

### TLS/SSL Configuration

#### Certificate Generation

```bash
# Generate private key
openssl genrsa -out /etc/spek/ssl/spek.key 2048

# Generate certificate signing request
openssl req -new -key /etc/spek/ssl/spek.key -out /etc/spek/ssl/spek.csr \
    -subj "/C=US/ST=State/L=City/O=Organization/CN=spek.yourdomain.com"

# Generate self-signed certificate (for testing)
openssl x509 -req -days 365 -in /etc/spek/ssl/spek.csr \
    -signkey /etc/spek/ssl/spek.key -out /etc/spek/ssl/spek.crt

# Set proper permissions
chmod 600 /etc/spek/ssl/spek.key
chmod 644 /etc/spek/ssl/spek.crt
chown spek:spek /etc/spek/ssl/spek.*
```

#### Security Hardening Script

```bash
#!/bin/bash
# Security hardening script for SPEK deployment

set -e

echo "üîí Applying security hardening..."

# Update system packages
apt-get update && apt-get upgrade -y

# Install security tools
apt-get install -y fail2ban ufw aide

# Configure firewall
ufw --force enable
ufw default deny incoming
ufw default allow outgoing
ufw allow from 10.0.0.0/8 to any port 22
ufw allow from 10.0.0.0/8 to any port 8000
ufw allow from 10.0.0.0/8 to any port 8443

# Configure fail2ban
cat > /etc/fail2ban/jail.local << EOF
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 3

[sshd]
enabled = true
port = ssh
logpath = /var/log/auth.log
maxretry = 3

[nginx-http-auth]
enabled = true
port = http,https
logpath = /var/log/nginx/error.log
EOF

systemctl enable fail2ban
systemctl start fail2ban

# Secure shared memory
echo "tmpfs /run/shm tmpfs defaults,noexec,nosuid 0 0" >> /etc/fstab

# Kernel hardening
cat > /etc/sysctl.d/99-spek-security.conf << EOF
# Network security
net.ipv4.ip_forward = 0
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.log_martians = 1
net.ipv4.conf.default.log_martians = 1
net.ipv4.icmp_echo_ignore_broadcasts = 1
net.ipv4.icmp_ignore_bogus_error_responses = 1
net.ipv4.tcp_syncookies = 1

# Memory protection
kernel.exec-shield = 1
kernel.randomize_va_space = 2
EOF

sysctl -p /etc/sysctl.d/99-spek-security.conf

# File integrity monitoring
aide --init
mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db

# Setup log monitoring
cat > /etc/logrotate.d/spek << EOF
/var/log/spek/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 spek spek
    postrotate
        systemctl reload spek
    endscript
}
EOF

echo "‚úÖ Security hardening completed"
```

### Access Control

#### RBAC Configuration

**File**: `/etc/spek/rbac.yaml`

```yaml
roles:
  admin:
    permissions:
      - analysis:*
      - system:*
      - config:*
      - monitoring:*
    
  analyst:
    permissions:
      - analysis:read
      - analysis:submit
      - analysis:results
      - monitoring:read
    
  viewer:
    permissions:
      - analysis:read
      - analysis:results
      - monitoring:read

users:
  - username: admin
    roles: [admin]
    mfa_required: true
    
  - username: security_analyst
    roles: [analyst]
    mfa_required: true
    
  - username: developer
    roles: [viewer]
    mfa_required: false

api_keys:
  - key: api_key_1
    name: CI/CD Pipeline
    roles: [analyst]
    expires: "2024-12-31"
    
  - key: api_key_2
    name: Monitoring System
    roles: [viewer]
    expires: "2025-06-30"
```

## Monitoring and Alerting

### Prometheus Configuration

**File**: `prometheus.yml`

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "spek_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - localhost:9093

scrape_configs:
  - job_name: 'spek'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s
    
  - job_name: 'postgresql'
    static_configs:
      - targets: ['localhost:9187']
      
  - job_name: 'redis'
    static_configs:
      - targets: ['localhost:9121']
      
  - job_name: 'nginx'
    static_configs:
      - targets: ['localhost:9113']

  - job_name: 'node'
    static_configs:
      - targets: ['localhost:9100']
```

### Alert Rules

**File**: `spek_rules.yml`

```yaml
groups:
  - name: spek.rules
    rules:
      # High-level service availability
      - alert: SPEKServiceDown
        expr: up{job="spek"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "SPEK service is down"
          description: "SPEK service has been down for more than 1 minute"
          
      # Performance alerts
      - alert: SPEKHighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 30
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "SPEK high response time"
          description: "95th percentile response time is {{ $value }}s"
          
      - alert: SPEKPerformanceDegradation
        expr: spek_performance_improvement_ratio < 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "SPEK performance below target"
          description: "Performance improvement is {{ $value | humanizePercentage }}, target is 58.3%"
          
      # Resource usage alerts
      - alert: SPEKHighMemoryUsage
        expr: process_resident_memory_bytes / 1024 / 1024 > 4096
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "SPEK high memory usage"
          description: "Memory usage is {{ $value }}MB"
          
      - alert: SPEKHighCPUUsage
        expr: rate(process_cpu_seconds_total[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "SPEK high CPU usage"
          description: "CPU usage is {{ $value | humanizePercentage }}"
          
      # Security and compliance alerts
      - alert: SPEKNASAComplianceBelow95
        expr: spek_nasa_compliance_score < 0.95
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "NASA compliance below threshold"
          description: "NASA compliance score is {{ $value | humanizePercentage }}"
          
      - alert: SPEKByzantineConsensusFailure
        expr: spek_byzantine_consensus_score < 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Byzantine consensus failure"
          description: "Byzantine consensus score is {{ $value | humanizePercentage }}"
          
      # Database alerts
      - alert: PostgreSQLDown
        expr: up{job="postgresql"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database is not responding"
          
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis is down"
          description: "Redis cache is not responding"
```

### Grafana Dashboards

Dashboard configuration for monitoring SPEK performance:

```json
{
  "dashboard": {
    "id": null,
    "title": "SPEK Production Dashboard",
    "tags": ["spek", "production"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Service Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"spek\"}",
            "legendFormat": "Service Status"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "mappings": [
              {
                "options": {
                  "0": {"text": "DOWN", "color": "red"},
                  "1": {"text": "UP", "color": "green"}
                },
                "type": "value"
              }
            ]
          }
        }
      },
      {
        "id": 2,
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "Requests/sec"
          }
        ]
      },
      {
        "id": 3,
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "id": 4,
        "title": "Performance Improvement",
        "type": "stat",
        "targets": [
          {
            "expr": "spek_performance_improvement_ratio",
            "legendFormat": "Performance Improvement"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percentunit",
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0.0},
                {"color": "yellow", "value": 0.4},
                {"color": "green", "value": 0.583}
              ]
            }
          }
        }
      },
      {
        "id": 5,
        "title": "NASA Compliance Score",
        "type": "stat",
        "targets": [
          {
            "expr": "spek_nasa_compliance_score",
            "legendFormat": "NASA Compliance"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percentunit",
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0.0},
                {"color": "yellow", "value": 0.9},
                {"color": "green", "value": 0.95}
              ]
            }
          }
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

## Performance Tuning

### System Optimization

#### Kernel Parameters

**File**: `/etc/sysctl.d/99-spek-performance.conf`

```bash
# Network performance
net.core.rmem_default = 262144
net.core.rmem_max = 134217728
net.core.wmem_default = 262144
net.core.wmem_max = 134217728
net.ipv4.tcp_rmem = 4096 4096 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.core.netdev_max_backlog = 5000

# File system performance
fs.file-max = 2097152
vm.swappiness = 1
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5

# Process limits
kernel.pid_max = 4194304
```

#### Application Performance Tuning

**File**: `performance_tuner.py`

```python
#!/usr/bin/env python3
"""
Performance tuning script for SPEK production deployment
"""

import os
import psutil
import yaml
from pathlib import Path

class SPEKPerformanceTuner:
    """Optimize SPEK performance based on system resources"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.system_info = self._get_system_info()
    
    def _get_system_info(self):
        """Get system resource information"""
        return {
            'cpu_count': psutil.cpu_count(),
            'memory_gb': psutil.virtual_memory().total // (1024**3),
            'disk_type': self._detect_disk_type(),
            'load_average': os.getloadavg()[0]
        }
    
    def _detect_disk_type(self):
        """Detect if using SSD or HDD"""
        try:
            with open('/sys/block/sda/queue/rotational', 'r') as f:
                return 'SSD' if f.read().strip() == '0' else 'HDD'
        except:
            return 'Unknown'
    
    def optimize_config(self):
        """Optimize configuration based on system resources"""
        
        with open(self.config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # Optimize worker count
        optimal_workers = min(self.system_info['cpu_count'], 8)
        if self.system_info['memory_gb'] < 8:
            optimal_workers = min(optimal_workers, 4)
        
        config['spek']['analysis']['max_workers'] = optimal_workers
        
        # Optimize cache settings based on memory
        if self.system_info['memory_gb'] >= 16:
            config['spek']['cache']['max_memory'] = '2GB'
        elif self.system_info['memory_gb'] >= 8:
            config['spek']['cache']['max_memory'] = '1GB'
        else:
            config['spek']['cache']['max_memory'] = '512MB'
        
        # Optimize timeouts based on disk type
        if self.system_info['disk_type'] == 'SSD':
            config['spek']['phases']['performance_optimization']['timeout_seconds'] = 180
        else:
            config['spek']['phases']['performance_optimization']['timeout_seconds'] = 300
        
        # Optimize based on system load
        if self.system_info['load_average'] > self.system_info['cpu_count']:
            # System under load, reduce parallelism
            config['spek']['analysis']['max_workers'] = max(1, optimal_workers // 2)
            config['spek']['phases']['precision_validation']['enabled'] = False
        
        # Write optimized config
        backup_path = f"{self.config_path}.backup"
        os.rename(self.config_path, backup_path)
        
        with open(self.config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, indent=2)
        
        print(f"‚úÖ Configuration optimized:")
        print(f"   - Workers: {optimal_workers}")
        print(f"   - Cache: {config['spek']['cache']['max_memory']}")
        print(f"   - System: {self.system_info}")
        print(f"   - Backup: {backup_path}")

if __name__ == "__main__":
    tuner = SPEKPerformanceTuner("/etc/spek/production.yaml")
    tuner.optimize_config()
```

### Database Optimization

#### PostgreSQL Configuration

**File**: `/etc/postgresql/14/main/postgresql.conf` (key settings)

```ini
# Memory settings
shared_buffers = 2GB                    # 25% of RAM
effective_cache_size = 6GB              # 75% of RAM
work_mem = 64MB                         # For sorting/hashing
maintenance_work_mem = 512MB

# Connection settings
max_connections = 200
max_prepared_transactions = 200

# Write-ahead logging
wal_buffers = 16MB
checkpoint_completion_target = 0.9
wal_writer_delay = 200ms
commit_delay = 100000

# Query planner
random_page_cost = 1.1                  # For SSD
effective_io_concurrency = 200          # For SSD

# Logging
log_min_duration_statement = 1000       # Log slow queries
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
```

#### Redis Optimization

**File**: `/etc/redis/redis.conf` (key settings)

```ini
# Memory settings
maxmemory 2gb
maxmemory-policy allkeys-lru

# Persistence
save 900 1
save 300 10
save 60 10000

# Network
tcp-keepalive 300
timeout 0

# Performance
tcp-backlog 511
databases 16
```

## Disaster Recovery

### Backup Strategy

#### Database Backup Script

```bash
#!/bin/bash
# Database backup script for SPEK

set -e

BACKUP_DIR="/opt/spek/backups"
RETENTION_DAYS=30
DB_NAME="spek"
DB_USER="spek"

# Create backup directory
mkdir -p "${BACKUP_DIR}"

# Generate backup filename
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="${BACKUP_DIR}/spek_db_${TIMESTAMP}.sql.gz"

echo "üîÑ Starting database backup..."

# Create database dump
pg_dump -h localhost -U "${DB_USER}" -d "${DB_NAME}" \
    --verbose --clean --create --if-exists \
    | gzip > "${BACKUP_FILE}"

if [ $? -eq 0 ]; then
    echo "‚úÖ Database backup completed: ${BACKUP_FILE}"
    
    # Calculate backup size
    BACKUP_SIZE=$(du -h "${BACKUP_FILE}" | cut -f1)
    echo "   Size: ${BACKUP_SIZE}"
else
    echo "‚ùå Database backup failed"
    exit 1
fi

# Cleanup old backups
echo "üßπ Cleaning up old backups..."
find "${BACKUP_DIR}" -name "spek_db_*.sql.gz" -mtime +${RETENTION_DAYS} -delete

# Upload to cloud storage (optional)
if [ -n "${AWS_S3_BACKUP_BUCKET}" ]; then
    echo "‚òÅÔ∏è  Uploading to S3..."
    aws s3 cp "${BACKUP_FILE}" "s3://${AWS_S3_BACKUP_BUCKET}/spek/database/"
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ S3 upload completed"
    else
        echo "‚ùå S3 upload failed"
    fi
fi

echo "üîÑ Backup process completed"
```

#### Application Data Backup

```bash
#!/bin/bash
# Application data backup script

set -e

BACKUP_DIR="/opt/spek/backups"
APP_DATA_DIR="/opt/spek/data"
CACHE_DIR="/opt/spek/cache"
CONFIG_DIR="/etc/spek"

TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="${BACKUP_DIR}/spek_data_${TIMESTAMP}.tar.gz"

echo "üîÑ Starting application data backup..."

# Create compressed archive
tar -czf "${BACKUP_FILE}" \
    -C /opt/spek data \
    -C /etc spek \
    --exclude="*/cache/*" \
    --exclude="*/logs/*" \
    --exclude="*/tmp/*"

if [ $? -eq 0 ]; then
    echo "‚úÖ Application data backup completed: ${BACKUP_FILE}"
    
    # Calculate backup size
    BACKUP_SIZE=$(du -h "${BACKUP_FILE}" | cut -f1)
    echo "   Size: ${BACKUP_SIZE}"
else
    echo "‚ùå Application data backup failed"
    exit 1
fi

# Cleanup old backups
find "${BACKUP_DIR}" -name "spek_data_*.tar.gz" -mtime +30 -delete

echo "üîÑ Application backup process completed"
```

### Recovery Procedures

#### Database Recovery Script

```bash
#!/bin/bash
# Database recovery script for SPEK

set -e

if [ $# -ne 1 ]; then
    echo "Usage: $0 <backup_file.sql.gz>"
    exit 1
fi

BACKUP_FILE="$1"
DB_NAME="spek"
DB_USER="spek"

if [ ! -f "${BACKUP_FILE}" ]; then
    echo "‚ùå Backup file not found: ${BACKUP_FILE}"
    exit 1
fi

echo "üîÑ Starting database recovery from: ${BACKUP_FILE}"
echo "‚ö†Ô∏è  This will replace the current database. Continue? (y/N)"
read -r response

if [[ ! "${response}" =~ ^[Yy]$ ]]; then
    echo "Recovery cancelled"
    exit 0
fi

# Stop SPEK service
echo "üõë Stopping SPEK service..."
systemctl stop spek

# Drop existing database and recreate
echo "üóëÔ∏è  Dropping existing database..."
sudo -u postgres dropdb --if-exists "${DB_NAME}"
sudo -u postgres createdb -O "${DB_USER}" "${DB_NAME}"

# Restore database
echo "üì• Restoring database..."
gunzip -c "${BACKUP_FILE}" | psql -h localhost -U "${DB_USER}" -d "${DB_NAME}"

if [ $? -eq 0 ]; then
    echo "‚úÖ Database recovery completed"
else
    echo "‚ùå Database recovery failed"
    exit 1
fi

# Start SPEK service
echo "üöÄ Starting SPEK service..."
systemctl start spek

# Wait for service to be ready
sleep 10

# Health check
curl -f http://localhost:8000/health > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ SPEK service is healthy after recovery"
else
    echo "‚ö†Ô∏è  SPEK service health check failed"
fi

echo "üîÑ Recovery process completed"
```

## Maintenance Procedures

### Regular Maintenance Tasks

#### Daily Maintenance Script

```bash
#!/bin/bash
# Daily maintenance script for SPEK

set -e

LOG_FILE="/var/log/spek/maintenance.log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

log "üîÑ Starting daily maintenance..."

# Check service health
log "üè• Checking service health..."
if systemctl is-active --quiet spek; then
    log "‚úÖ SPEK service is running"
else
    log "‚ùå SPEK service is not running"
    systemctl start spek
fi

# Database maintenance
log "üóÑÔ∏è  Running database maintenance..."
sudo -u postgres psql -d spek -c "VACUUM ANALYZE;" > /dev/null 2>&1
log "‚úÖ Database vacuum completed"

# Cache cleanup
log "üßπ Cleaning cache..."
redis-cli -p 6379 --eval /opt/spek/scripts/cache_cleanup.lua > /dev/null 2>&1
log "‚úÖ Cache cleanup completed"

# Log rotation
log "üìú Rotating logs..."
logrotate -f /etc/logrotate.d/spek
log "‚úÖ Log rotation completed"

# Check disk space
DISK_USAGE=$(df /opt/spek | awk 'NR==2 {print $5}' | sed 's/%//')
if [ "${DISK_USAGE}" -gt 80 ]; then
    log "‚ö†Ô∏è  Disk usage is high: ${DISK_USAGE}%"
    # Cleanup old temporary files
    find /tmp/spek -type f -mtime +1 -delete 2>/dev/null || true
    find /opt/spek/cache -type f -mtime +7 -delete 2>/dev/null || true
fi

# Performance check
RESPONSE_TIME=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8000/health)
if (( $(echo "${RESPONSE_TIME} > 5.0" | bc -l) )); then
    log "‚ö†Ô∏è  High response time: ${RESPONSE_TIME}s"
fi

log "‚úÖ Daily maintenance completed"
```

#### Weekly Maintenance Script

```bash
#!/bin/bash
# Weekly maintenance script for SPEK

set -e

LOG_FILE="/var/log/spek/weekly_maintenance.log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

log "üîÑ Starting weekly maintenance..."

# Full database backup
log "üíæ Creating database backup..."
/opt/spek/scripts/backup_database.sh
log "‚úÖ Database backup completed"

# Application data backup
log "üì¶ Creating application data backup..."
/opt/spek/scripts/backup_app_data.sh
log "‚úÖ Application data backup completed"

# System updates
log "üîÑ Checking for system updates..."
apt-get update > /dev/null 2>&1
UPDATES=$(apt list --upgradable 2>/dev/null | wc -l)
if [ "${UPDATES}" -gt 1 ]; then
    log "üì¶ ${UPDATES} updates available"
    # Apply security updates only
    unattended-upgrade --dry-run
fi

# Certificate expiry check
if [ -f "/etc/spek/ssl/spek.crt" ]; then
    CERT_EXPIRES=$(openssl x509 -enddate -noout -in /etc/spek/ssl/spek.crt | cut -d= -f 2)
    EXPIRES_EPOCH=$(date -d "${CERT_EXPIRES}" +%s)
    CURRENT_EPOCH=$(date +%s)
    DAYS_LEFT=$(( (EXPIRES_EPOCH - CURRENT_EPOCH) / 86400 ))
    
    if [ "${DAYS_LEFT}" -lt 30 ]; then
        log "‚ö†Ô∏è  SSL certificate expires in ${DAYS_LEFT} days"
    fi
fi

# Performance baseline update
log "üìä Updating performance baselines..."
python3 /opt/spek/scripts/update_baselines.py
log "‚úÖ Performance baselines updated"

log "‚úÖ Weekly maintenance completed"
```

### Emergency Procedures

#### Emergency Response Script

```bash
#!/bin/bash
# Emergency response script for SPEK

set -e

INCIDENT_TYPE="$1"
SEVERITY="$2"

if [ $# -lt 2 ]; then
    echo "Usage: $0 <incident_type> <severity>"
    echo "Incident types: service_down, high_cpu, high_memory, disk_full, security_breach"
    echo "Severity: low, medium, high, critical"
    exit 1
fi

LOG_FILE="/var/log/spek/incident_$(date +%Y%m%d_%H%M%S).log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

alert() {
    log "üö® ALERT: $1"
    # Send alert notification
    if [ -n "${ALERT_WEBHOOK_URL}" ]; then
        curl -X POST "${ALERT_WEBHOOK_URL}" \
            -H "Content-Type: application/json" \
            -d "{\"text\":\"SPEK Emergency: $1\",\"severity\":\"${SEVERITY}\"}" \
            > /dev/null 2>&1 || true
    fi
}

log "üö® Emergency response initiated: ${INCIDENT_TYPE} (${SEVERITY})"

case "${INCIDENT_TYPE}" in
    service_down)
        log "üîÑ Attempting to restart SPEK service..."
        systemctl restart spek
        sleep 10
        
        if systemctl is-active --quiet spek; then
            log "‚úÖ Service restart successful"
        else
            alert "Service restart failed"
            log "‚ùå Service restart failed, checking logs..."
            journalctl -u spek --no-pager -l -n 50 >> "${LOG_FILE}"
        fi
        ;;
        
    high_cpu)
        log "üìä Investigating high CPU usage..."
        ps aux --sort=-%cpu | head -20 >> "${LOG_FILE}"
        
        # Reduce workers if CPU critical
        if [ "${SEVERITY}" = "critical" ]; then
            log "‚ö° Reducing worker count to 2..."
            # Update configuration temporarily
            sed -i 's/max_workers: [0-9]*/max_workers: 2/' /etc/spek/production.yaml
            systemctl reload spek
        fi
        ;;
        
    high_memory)
        log "üìä Investigating high memory usage..."
        ps aux --sort=-%mem | head -20 >> "${LOG_FILE}"
        
        # Clear cache if memory critical
        if [ "${SEVERITY}" = "critical" ]; then
            log "üßπ Clearing cache..."
            redis-cli -p 6379 FLUSHALL > /dev/null 2>&1 || true
        fi
        ;;
        
    disk_full)
        log "üíæ Investigating disk usage..."
        df -h >> "${LOG_FILE}"
        
        # Emergency cleanup
        log "üßπ Emergency disk cleanup..."
        find /tmp/spek -type f -mtime +0 -delete 2>/dev/null || true
        find /opt/spek/cache -type f -mtime +1 -delete 2>/dev/null || true
        find /var/log/spek -name "*.log" -mtime +7 -delete 2>/dev/null || true
        ;;
        
    security_breach)
        alert "SECURITY BREACH DETECTED"
        log "üîí Implementing security lockdown..."
        
        # Block external access
        ufw --force reset > /dev/null 2>&1
        ufw --force enable > /dev/null 2>&1
        ufw default deny incoming > /dev/null 2>&1
        
        # Stop service if critical
        if [ "${SEVERITY}" = "critical" ]; then
            systemctl stop spek
            log "üõë Service stopped due to security breach"
        fi
        ;;
        
    *)
        log "‚ùì Unknown incident type: ${INCIDENT_TYPE}"
        ;;
esac

log "üîÑ Emergency response completed"
log "üìã Incident log: ${LOG_FILE}"
```

---

## Summary

This deployment manual provides:

‚úÖ **Complete Infrastructure** - From bare metal to cloud deployment  
‚úÖ **Production Configuration** - Optimized for defense industry requirements  
‚úÖ **Security Hardening** - NATO/Defense grade security implementation  
‚úÖ **Monitoring & Alerting** - Comprehensive observability stack  
‚úÖ **Performance Tuning** - 58.3% improvement target optimization  
‚úÖ **Disaster Recovery** - Backup and recovery procedures  
‚úÖ **Maintenance Procedures** - Daily, weekly, and emergency procedures  
‚úÖ **Container Support** - Docker and Kubernetes deployment options  
‚úÖ **Cloud Integration** - AWS, Azure, GCP deployment templates  

The deployment maintains SPEK's core capabilities:
- **58.3% Performance Improvement**
- **95% NASA POT10 Compliance**
- **Defense Industry Ready**
- **High Availability**
- **Enterprise Security**

For additional support and advanced deployment scenarios, consult the [User Guide](./USER-GUIDE.md) and [API Reference Manual](./API-REFERENCE-MANUAL.md).